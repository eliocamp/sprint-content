[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OpenSciency Introductory Resources on Open Science",
    "section": "",
    "text": "Opensciency - A core open science curriculum by and for the research community.\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nOpensciency is core open science curriculum material, drafted to introduce those beginning their open science journey to important definitions, tools, and resources; and provide for participants at all levels recommended practices. The material is made available under a CC-BY 4.0 International license and is structured into five modules:"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "OpenSciency Introductory Resources on Open Science",
    "section": "Citation",
    "text": "Citation\nAll versions can be found and referenced to this DOI: 10.5281/zenodo.7392118.\nTo credit and cite the material, use the following citation - where possible, please include all authors name as listed in the CITATION file:\n\nOpenSciency Contributors (2023, February 22). Opensciency - A core open science curriculum by and for the research community. Zenodo. https://doi.org/10.5281/zenodo.7392118\n\nShared under the CC-BY 4.0 License, all materials remain open for anyone to build open science curriculums or reuse for other purposes. Please include all author names where possible from the GitHub README contributors table."
  },
  {
    "objectID": "index.html#details",
    "href": "index.html#details",
    "title": "OpenSciency Introductory Resources on Open Science",
    "section": "Details",
    "text": "Details\nOpensciency is a result of the work of more than 40 open science experts and practitioners from across the world and from different disciplines. The first draft of the curriculum material was developed from June 27 - July 1, 2022 as part of the Transform to Open Science (TOPS) OpenCore sprint. More information about the NASA TOPS initiative is available via their website. After the TOPS Community Panel on October 6, 2022, the original contributors created the Opensciency repository to allow all contributors to further engage with the curriculum and invite review on the initial draft material from the wider research community.\nWe encourage the wider community to reuse the material, and we are especially interested in creative approaches to displaying the material. An example we like is Elements of AI.\nLet us know if you have a creative approach to displaying and reusing the material by submitting an issue. Please provide your contact details so we can add you to the contributors list."
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "OpenSciency Introductory Resources on Open Science",
    "section": "Contributors ✨",
    "text": "Contributors ✨\nThanks goes to these wonderful people (emoji key):\n\n\n\n\n\n\n\n\nYo Yehudi🧑‍🏫\n\n\nNatasha Batalha🧑‍🏫\n\n\nShilaan Alzahawi🧑‍🏫\n\n\nSara🧑‍🏫\n\n\nCameron🧑‍🏫\n\n\nJames Powell🧑‍🏫\n\n\nDaniela Saderi🖋\n\n\n\n\nsmhall97🖋\n\n\nJannatul Ferdush🖋\n\n\nFlavio Azevedo🖋\n\n\nChris Erdmann🧑‍🏫\n\n\nYuhan (Douglas) Rao🖋\n\n\nBatool Almarzouq🖋\n\n\nEsther Plomp🖋\n\n\n\n\nTomoCoral🖋\n\n\nMelissa Black🖋\n\n\nMalvika Sharan🖋\n\n\nSaranjeet Kaur🖋\n\n\nMichel Lacerda🖋\n\n\nIsmael-KG🖋\n\n\nandreamedinasmith🖋\n\n\n\n\naosman12🖋\n\n\nElio Campitelli🖋\n\n\nStephen Klusza🖋\n\n\nMariana Meireles🖋\n\n\nPauline Karega🖋\n\n\nAnne Fouilloux🖋\n\n\nReina Camacho Toro🖋\n\n\n\n\nSierra V. Brown🖋\n\n\nShamsudddeen Hassan Muhammad🖋\n\n\nJohanna Bayer🖋\n\n\nHugh Shanahan🖋\n\n\nMiguelSilan🖋\n\n\nElli Papadopoulou🖋\n\n\ndunldj🖋\n\n\n\n\nAna Vaz🖋\n\n\nTyson L. Swetnam🖋\n\n\nBabatunde Valentine Onabajo🖋\n\n\nTaher Chegini🖋\n\n\nee2110🖋\n\n\nrebeccaringuette🖋\n\n\nMayya🖋\n\n\n\n\n\n\n\n\nThis project follows the all-contributors specification. Contributions of any kind welcome!"
  },
  {
    "objectID": "ethos-of-open/lesson1-intro-to-open-science.html#introduction",
    "href": "ethos-of-open/lesson1-intro-to-open-science.html#introduction",
    "title": "Ethos of Open Science",
    "section": "Introduction",
    "text": "Introduction\nThis is the first lesson in the module on the Ethos of Open Science. We’ll start explaining what we mean by the word, “ethos”. Ethos is defined by Merriam-Webster as “the distinguishing character, sentiment, moral nature, or guiding beliefs of a person, group, or institution”. So this lesson is about what makes Open Science, as an approach to knowledge-production, unique or distinguishable from other scientific methods.\nNote that “ethos” is not exactly “ethics”, but it is a broad enough term to include the moral attitudes held by the individuals or institutions practicing open science. To make it clear that there is a moral element to this discussion, we speak of “responsible Open Science” going forward.\nThe lesson introduces the concept of open science as a whole, by explaining the history underpinning open science, what open science is, and how it works. It then discusses different components of open science and the pillars that make them up. At the end of the lesson, students will have an understanding of the brief history of open science and its definition.\nOpen science goes beyond publishing– it is a redefinition of scientific collaboration and output. It is a culture intended to promote science and its social impact. Open science creates new opportunities for different stakeholders including researchers, decision makers, and public participants. Open science increases study transparency, repeatability, reproducibility, and confirmation. We expand what these terms mean and why they matter throughout this module and later OpenCore modules."
  },
  {
    "objectID": "ethos-of-open/lesson1-intro-to-open-science.html#context-and-definition",
    "href": "ethos-of-open/lesson1-intro-to-open-science.html#context-and-definition",
    "title": "Ethos of Open Science",
    "section": "Context and Definition",
    "text": "Context and Definition\nScience evolves through collaborative development of theories and practices that are open for others to learn and build on. Throughout the ages - whilst in some cases, education and science was out of reach for the general populace and may have been kept for a privileged few, there have been other educational and scientific resources that were purposefully made available for others to re-use. Think of how dictionaries and encyclopedias have been around for centuries specifically to share standards of knowledge. (The first “dictionary” dates back over 3,000 years!) Libraries, in turn, have existed for millennia to serve as repositories of knowledge in diverse formats, from ancient tablets and scrolls, to the books we expect to see today. Public museums have also been around for some time and play the role of educating people, as well as maintaining archives for researchers to gain further insights from.\nInstitutions and practices throughout the ages have facilitated humanity’s endless desire for knowledge. As far back as the Medieval era, we already find physicians being encouraged to review one another’s work to ensure it was carried out appropriately (Rogers, 2021). Today, we call this practice “peer review”. And, during the Enlightenment, scientists formed networks with whom they shared their theories via hand-written letters, and the adoption of the printer allowed for the emergence of scientific institutes and journals (Green, 2017; see Kherroubi Garcia et al., 2022).\nHowever, open science has only become a distinct set of practices in recent decades. We can see open science as both being encouraged by social and technological developments, and responding to problems in the scientific process. The emergence of the internet and other digital technologies have more recently allowed for science to be conducted even more collaboratively. In 1971, Project Gutenberg started making books in the 📖public domain📖 available online. In 1987, we saw the first open access 📖journal📖 being published. In 1991 the central storage platform arXiv was launched for the exchange of manuscripts in physics (though without 📖peer review📖) (Ginsparg, 2021).\nHowever, these endeavors do not amount to open science in the sense we discuss it today. In recent years, we have learned of various issues in the scientific process that necessitate specific responses. Two such issues are the 📖replication crisis📖 (Fidler & Gordon, 2013; Elsherif et al., 2021a) and 📖publication bias📖 (Joober, et al., 2012; Elsherif et al., 2021b). The replication crisis refers to scientific findings not being validated by other scientists’ efforts to replicate them. The publication bias amounts to the greater ease to publish scientific findings that only “very clearly” confirm or disprove hypotheses.\nThus, open science captures both the spirit of making knowledge more accessible and responding to poor scientific practices. We will discuss more reasons why open science is important, both the personal benefits and as a public good, in 🔗Lesson 2 of this module, “Benefits and Challenges of responsible Open Science: Why does it matter?”🔗"
  },
  {
    "objectID": "ethos-of-open/lesson1-intro-to-open-science.html#definitions-of-open-science-and-responsible-open-science",
    "href": "ethos-of-open/lesson1-intro-to-open-science.html#definitions-of-open-science-and-responsible-open-science",
    "title": "Ethos of Open Science",
    "section": "Definitions of Open Science and responsible Open Science",
    "text": "Definitions of Open Science and responsible Open Science\nFormal definitions and governance mechanisms to ensure best practices in open science have emerged alongside the open science movement.\n\nIn 1997, COPE was established and has since supported the fostering of responsible publishing culture.\nThe 2001 Budapest Open Access Initiative provided a clear working definition of open access, one of the components of open science (as we will see shortly).\nIn 2012, the Contributor Role Taxonomy was developed so that more diverse collaborators in research can be adequately credited for their work.\nThe 2013 Declaration on Research Assessment then outlined best practices in the assessment of research.\nIn 2014, the Open and Collaborative Science in Development Network was established to enable open science approaches to developmental research for the Global South.\n2014 also saw the launch of the Data Citation Principles, which advocate for – amongst other things – making data independently citable.\nThe 2016 FAIR principles emerged as a way to guide practices in open science, and enabled the implementation of the Data Citation Principles.\nThe 2018 CARE principles established data governance practices for indigenous data and practices.\n\nIn this complex context, we can draw on a few definitions of Open Science:\n“Open Science is transparent and accessible knowledge that is shared and developed through collaborative networks” (Vicente-Saez & Martinez-Fuentes, 2018).\n“Open science is […] an inclusive construct that combines various movements and practices aiming to make multilingual scientific knowledge openly available, accessible and reusable for everyone, to increase scientific collaborations and sharing of information for the benefits of science and society, and to open the processes of scientific knowledge creation, evaluation and communication to societal actors beyond the traditional scientific community. It comprises all scientific disciplines and aspects of scholarly practices, including basic and applied sciences, natural and social sciences and the humanities, and it builds on the following key pillars: open scientific knowledge, open science infrastructures, science communication, open engagement of societal actors and open dialogue with other knowledge systems (UNESCO, 2021).\nGlobally, Open Science is being valued and given importance as it recognizes disparities and regional differences, providing a framework to handle challenges and contribute to minimize knowledge, technological and digital differences between countries. For instance, when different researchers from across the globe are invited to research collaboratively, trust and novelty increases and as a result it improves quality, efficacy and responsiveness in research as being the benefits of Open Science.\nHere are some other definitions of Open Science. Are there any more you would add?\nOpen Science is a practice for increasing the accessibility and transparency of scientific research. The concept of Open Science is built around shared principles such as inclusion, fairness, equity, & sharing (Zee & Reich, 2018).\nAn umbrella term reflecting the idea that scientific knowledge of all kinds, where appropriate, should be openly accessible, transparent, rigorous, reproducible, replicable, accumulative, and inclusive, all which are considered fundamental features of the scientific endeavor. Open science consists of principles and behaviors that promote transparent, credible, reproducible, and accessible science. Open science has six major aspects: open data, open methodology, open source, open access, open peer review, and open educational resources. (FORRT open science glossary, https://forrt.org/glossary/open-science/)"
  },
  {
    "objectID": "ethos-of-open/lesson1-intro-to-open-science.html#open-science-aspects",
    "href": "ethos-of-open/lesson1-intro-to-open-science.html#open-science-aspects",
    "title": "Ethos of Open Science",
    "section": "Open Science aspects",
    "text": "Open Science aspects\nOpen science has various components: open access, open access journals, open peer review, open research data, open source, open science policies, with use of open licensing, open software for reproducible research, among others (Open Science Basics, retrieved from https://open-science-training-handbook.gitbook.io/book/open-science-basics, 2022).\nThe below image from Robinson (2018) captures some of the components of open science, although the list differs depending on who you ask (see Pontika et al., 2015).\n\n\n\nOpen Sholarship umbrella contains Open Educational resources, EDI, community science, open data, open science, open access, open source.\n\n\n(Image from Robinson, 2018; needs adapting in light of the list below)\nOpen Science is an umbrella term that captures eight components. The below list helps us reflect on the ambition that drives the open science movement. In short, open science is not limited to a discipline or a particular aspect of scholarly practice. Rather, open science seeps into every practice of scholarly work.\n\nOpen Access refers to making research methods, data and outputs accessible by default, where advisable; this is touched on in lesson five below.\nOpen Data relates to making data used in science accessible for others to study, re-usable for other pertinent projects, and available for redistribution. More on this topic will be discussed in the module Open Data.\nOpen Software is about making the source code of software transparent, allowing people to collaborate on its improvement; more will be said in the module Open Software.\nOpen Tools & Resources are those that have been developed precisely to facilitate open science practices, from open hardware and online toolkits to behavioral guidelines; learn more in the module Open Tools & Resources.\nOpen Results is a broad term capturing open access, open data and open software, as it is about making results from all stages of a research lifecycle open, including their evaluation, which should not be limited to traditional peer review; learn more in the module Open Results.\nOpen Educational Resources are learning and teaching materials made available through 📖open licenses📖 that permit no-cost access, re-use, re-purpose, adaptation and redistribution by others (see UNESCO’s explainer); note that the present TOPS OpenCore is an example of such a resource!\nEquity, Diversity, Accessibility and Inclusion are crucial values for the growth and sustainability of open science practices, as they foster the wellbeing of open science practitioners and communities. Shared principles about responsible scientific outputs also shape the behaviors of open science communities, with codes of conduct as a mechanism to ensure inclusive practices (see the following component of open science).\nOpen Community Practices refers to the fact that open science is conducted by communities of practitioners that foster collaborative working environments, beyond disciplinary boundaries and professions; this is touched on when discussing stakeholders in lesson three of this module."
  },
  {
    "objectID": "ethos-of-open/lesson1-intro-to-open-science.html#there-is-no-one-ethos",
    "href": "ethos-of-open/lesson1-intro-to-open-science.html#there-is-no-one-ethos",
    "title": "Ethos of Open Science",
    "section": "There is no one ethos",
    "text": "There is no one ethos\nIt is important to note that there is no one unique way of practicing or conducting open science. The outlined categories show us the diversity of practices involved in open science. Research has also shown that there are at least five schools of thought in open science, each one holding different assumptions and striving for different goals (Fecher & Friesike, 2013):\n\n\n\nFive chools of open science: infrastructure, pragmatic, democrratic, measurement, public school. Visit the paper for more details on each.\n\n\nDiverse practices, assumptions and goals are just part of the complexity of open science. There are also divergent moral principles guiding open science communities. Such principles are captured in 📖codes of conduct📖. A code of conduct is a community governance mechanism that outlines the principles and practices expected of a given research community’s members, as well as the process for investigating and reprimanding those in violation of the code.\nIn a sense, a code of conduct constitutes the moral backbone of a research community. However, as with the numerous schools of thought, there are similarly many codes of conduct. In other words, there is no one set of universal principles that all open science practitioners abide by. For example, consider how OLS, INOSC, allea, AGU and Ethical Source all have different codes of conducts and guiding principles.\nThis great diversity responds to the growing proliferation of open science initiatives and the great use we can make of open science approaches to knowledge.\nOne of the biggest driving forces is the effect of open science on the research performance. Indeed, some studies have even found that the best-performing universities are those that conduct science following open practices (see Huang et al., 2020). More will be said in the following lesson about the benefits of open science and different stakeholders.\nFor now, consider some of the regional policies encouraging open science:\n\nThe European Commission (2017) has outlined the skills and competencies researchers need to practise open science;\nThe National Academies of Sciences, Engineering and Medicine (2018) promotes open science by design as a vision for 21st century research;\nUNESCO (2021) has developed a series of recommendations to ensure best open science practices, which are conducive to the United Nations’ Sustainable Development Goals;\nThe European Open Science Cloud (EOSC) for finding and re-using data, and the Open Research Europe (ORE) publishing platform (European Commission, 2021).\n\nUltimately, open science practices guide approaches to knowledge-creation that best help confront the challenges of our era. Through this module and the wider TOPS curriculum, you can become a part of this impactful movement."
  },
  {
    "objectID": "ethos-of-open/lesson1-intro-to-open-science.html#performing-open-science-responsibly",
    "href": "ethos-of-open/lesson1-intro-to-open-science.html#performing-open-science-responsibly",
    "title": "Ethos of Open Science",
    "section": "Performing open science responsibly:",
    "text": "Performing open science responsibly:\nResponsible Open Science is a term we use through the rest of the module. We define it as: considering open science as the core of your science project and maximizing ethical actions for open science to minimize current challenges (e.g. data sharing, inclusion, and accessibility). In responsible Open Science, the best possible and practical practices should be explored at the early stage of your science project.\nHere we share with you following rules of thumb:\n\nUsing best practices where possible\nBeing practical and realistic about resources available and pressures on open science practitioners\nNot sharing things that shouldn’t be shared\nBeing inclusive of all people"
  },
  {
    "objectID": "ethos-of-open/lesson1-intro-to-open-science.html#summary",
    "href": "ethos-of-open/lesson1-intro-to-open-science.html#summary",
    "title": "Ethos of Open Science",
    "section": "Summary",
    "text": "Summary\nIn this lesson, we have learned a brief history of open science, its definition, and the ethos of open science and definition of responsible Open Science. Open science practices provide significant advantages relative to more traditional closed practices. However, there are still problems that must be addressed, which many view as obstacles to open science. In the next lesson, we will talk about the benefits of open science and its challenges."
  },
  {
    "objectID": "ethos-of-open/lesson1-intro-to-open-science.html#further-reading",
    "href": "ethos-of-open/lesson1-intro-to-open-science.html#further-reading",
    "title": "Ethos of Open Science",
    "section": "Further Reading:",
    "text": "Further Reading:\nBelow are some further readings regarding this module:\n\nOpen Science : One Term, Five Schools of Thought\nHow open science helps researchers succeed\nDeveloping a Toolkit for Fostering Open Science Practices: Proceedings of a Workshop\n\nNational Academies of Sciences, Engineering, and Medicine. 2021.\n\nReproducibility and Replicability in Science. Washington, DC: The National Academies Press. https://doi.org/10.17226/25303 .\nOpen Science and Radical Solutions for Diversity, Equity and Quality in Research: A Literature Review of Different Research Schools, Philosophies and Frameworks and Their Potential Impact on Science and EducationGong, “Open Science.”https://doi.org/10.1177/20966083221091867\nBook by Miedema, Open Science. https://doi.org/10.1007/978-94-024-2115-6\n\nFurther reading on terms and definitions:\n\nOpen Science glossary from the FORRT (Framework for Open and Reproducible Research Training) https://forrt.org/glossary/open-science/\n\n\nQuestions/Reflection:\n\nQuestions for students of the course:\n\nHow has research practice changed over the past few decades ?\nAs a researcher how do different components of responsible Open Science transform knowledge contribution?\nWe learned that there is “no one ethos” in this lesson. Can you explain what this means, and why?"
  },
  {
    "objectID": "ethos-of-open/contributors.html",
    "href": "ethos-of-open/contributors.html",
    "title": "OpenSciency Ethos of Open Science: Authors",
    "section": "",
    "text": "Tomoko Tomo Bell\nUniversity of Guam\nhttps://orcid.org/0000-0003-4606-6307\nhttps://github.com/TomoCoral\nIsmael Kherroubi Garcia\nOpen Life Science and Royal Society of Arts, Manufactures and Commerce\nhttps://orcid.org/0000-0002-6850-8375\nhttps://github.com/Ismael-KG\nhttps://twitter.com/hermeneuticist\nAmber Osma\nDOAJ\nhttps://orcid.org/0000-0003-1198-7843\nhttps://github.com/aosman12\nhttps://twitter.com/amb3r12\nMiguel Silan\nAnnecy Behavioral Science Lab; Université Lumière Lyon 2\nhttps://orcid.org/0000-0002-7480-3661\nhttps://github.com/miguelsilan\nhttps://twitter.com/MetaMethodsPH\nYo Yehudi\nOpen Life Science\nhttps://orcid.org/0000-0003-2705-1724\nhttps://github.com/yochannah\nhttps://twitter.com/yoyehudi\nShamsuddeen Muhammad\nBayero University, Kano\nhttps://orcid.org/0000-0001-7708-0799\nhttps://github.com/shmuhammad2004\nhttps://twitter.com/shmuhammadd"
  },
  {
    "objectID": "open-software/lesson0-preamble.html",
    "href": "open-software/lesson0-preamble.html",
    "title": "Open Software",
    "section": "",
    "text": "Have you ever marveled at mesmerizing scientific visualizations and wondered how they were generated and whether you can recreate them or even maybe tweak them to produce new results? These types of images have been created by researchers using research software. These software products and sometimes their source codes are freely available to the public. Reproducing such results and using them to advance the knowledge produced by these types of research software products are among the pillars of open science. For example, Figure 1, is generated using E3SM, an Earth System model, the source code of which is available on GitHub.\n\n\n\n\n\n\n\n\n\n\n\nFigure 1. Global E3SM simulation showing eddy activity, credits M. Petersen, P. Wolfram and T. Ringler\n\n\n\nNow, let’s say that you are intrigued by the idea of recreating Figure 1 and tweaking the E3SM’s source code. We should start with obtaining the source code. Someone might ask since this project already has a fancy website why is the source code on GitHub? Let’s assume that we successfully got the source code and want to start recreating the figure. Naturally, the next question is how do we install it since there is no executable file in the source code? Maybe you are used to installing software packages using installation wizards, or maybe you are comfortable working from command line. Which one is possible or preferable for installing this software? The next step after installation is running the software and visualizing the results. So, the question is, for generating the desired outputs, how do we configure the software, what are the required input data, and how do we get them? Let’s take it a step further and say that you have some brilliant new ideas and want to implement in the source code, analyze the outputs, publish the results, and make your code publicly available. Therefore, the questions become: How do we facilitate navigating this seemingly complicated source code? After making modifications, are we allowed to share and republish the modified source code, and if so, how do go about it? How do we ensure that the republished code is findable and other researchers can reuse and build upon it?\nThe purpose of this module is to answer these questions, provide guidance for streamlining the workflow and ensuring that we give/get proper credits, and last but not least, draw your attention to and promote the importance of contributing and giving back to the Open Science community."
  },
  {
    "objectID": "open-software/contributors.html",
    "href": "open-software/contributors.html",
    "title": "OpenSciency Open Software: Authors",
    "section": "",
    "text": "Bayer, Johanna\nUniversity of Melbourne\nhttps://orcid.org/0000-0003-4891-6256\nhttps://github.com/likeajumprope\nhttps://twitter.com/likeajumprope\nBrown, Sierra\nMillion Concepts, LLC\nhttps://orcid.org/0000-0001-6065-5461\nhttps://github.com/Sierra-MC\nChegini, Taher\nUniversity of Houston\nhttps://orcid.org/0000-0002-5430-6000\nhttps://github.com/cheginit\nhttps://twitter.com/taher\nKeat, Yeo\nUniversity of Putra Malaysia\nhttps://orcid.org/0000-0001-6935-3101\nhttps://github.com/ee2110\nhttps://twitter.com/EeYeoKeat\nOnabajo, Babatunde\nChurchMapped Limited\nhttps://orcid.org/0000-0001-6118-9255\nhttps://github.com/BabatundeOnabajo\nhttps://twitter.com/babatundeonabaj\nPowell, James\nhttps://github.com/CRiddler\nhttps://twitter.com/dontusethiscode\nRiddell, Cameron\nhttps://github.com/dutc\nhttps://mobile.twitter.com/riddlemecam\nVaz, Ana\nUniversity of Miami\nhttps://orcid.org/0000-0003-0336-5227\nhttps://github.com/AnaVaz-NOAA\nhttps://github.com/anacarolvaz\nhttps://twitter.com/anacarolvaz"
  },
  {
    "objectID": "open-data/Lesson1-WhatIsOpenData.html#introduction",
    "href": "open-data/Lesson1-WhatIsOpenData.html#introduction",
    "title": "Open Data",
    "section": "Introduction",
    "text": "Introduction\nAs mentioned earlier, data is a major part of scientific research, and why wouldn’t it be? It is evident that data permeates many aspects of our daily life with significant consequences.\nFor instance, it has become all the more common to see news articles discussing how data and efforts like Open Street Map are critical in supporting the disaster emergency responses all over the world 1. This is only an example among many others demonstrating the value of data, particularly open and public data, in our daily life and for public good.\nSimilarly, data shared openly in scientific research brings tremendous value which is not limited to the scientific community but extends to communities at large from indigenous communities to urban populations! Before we look further into this, let’s first look at what is data in scientific fields? What is open data? What are the key characteristics of open data?\n\nWhat is Data?\nData is any type of information, recordable or observable facts. Research data is thus data collected in order to answer the research questions of a project.\nResearch data can be numbers, texts, measurements, images, model output, and more. Research data is collected in different ways, and formats. Generally speaking it can be grouped in different ways, for example:\n\nQualitative data describing information in words\nQuantitative data with defined numerical information, e.g. from measurements\nGrouped versus ungrouped data; grouped data being data that has been put into classes for next steps such as interpretation and ungrouped data referring to the raw data 2\nStructured versus unstructured data: unstructured data referring to data in its raw format, and structured data referring to data formatted for storage in files or records such as relational databases 3\n\nIn the next section we will introduce the different types of data most commonly generated/found in research. This will provide an understanding of how different data should be handled and what considerations to keep in mind when sharing it openly. More on this can be found in lessons 3 (Responsible Open Data) & 4 (CARE and FAIR Principles). We will also highlight one particular type of data (metadata, described below) and its role in supporting the development of Open Data and Open Science initiatives.\n\nPrimary (raw) data\nPrimary data refers to data that is directly collected or created by researchers. Examples include surveys, questionnaires, interviews, physical samples, specimens, output from models, remote sensing data (spectral/photons), etc. Research questions guide the collection of the data. Typically, a researcher will formulate a question, develop a methodology and start collecting the data. Some examples of primary data include:\nResponses to Interviews, questionnaires, and surveys.\nTypically, interviews generate data, in the form of recorded audio ﬁles, transcripts, and notes and other observational data. Interviews can address a broad range of quantitative or qualitative oriented research questions, and may be used on their own or as part of a mixed methods approach. In behavioral and social sciences, these data collection methods are often used to collect self-reported data. A researcher designs these questions to collect data from participants that are necessary for the research. In most cases, this type of data can be openly shared under certain conditions or considerations e.g. if they are de-identified, and if the participants consent about the data being shared, more on that in lesson 2 and 3.\nData acquired from recorded measurements, including remote sensing data.\nIn many cases, the raw primary measurements from an instrument are processed in various ways such that what is typically stored and reported is based on a variety of calibration, normalization, and even compression steps that are ideally well defined and described by a discipline or measurement protocol. For example, satellite captured imagery is often used in online map services and navigation (e.g., Google Maps). These satellite imagery is often captured by various sensors onboard space-borne satellites (e.g., NASA Earth Observing System) or airborne measuring platforms (e.g., uncrewed drones or planes) [4]. These data often need careful calibration and correction including the values recorded by the sensors and the geospatial location of the imagery before it can be used appropriately for research and application. After the calibration and corrections, remote sensing imagery are often used to create products that can help us understand the environment that we live in and useful for societal benefits (e.g., studying air quality impact on community health).\nData acquired from physical samples and specimens form the base of many studies.\nTests and analyses are conducted on these resources, such as biological specimens, rocks and minerals, soils and sediments, plants and seeds, water samples, archaeological artifacts, or DNA and human tissue samples (Research Data Alliance Interest Group on Physical Samples) [5]. While it may be more difficult to share these types of physical resources, information about the samples and as well as data derived from using them, can be shared via thorough description, such as in the case of BioBanks, IGSN (a persistent identifier specifically for physical samples), and iSamples [6] [7]. For more information about how to manage physical samples, check out the 23 Things Physical Samples [8].\nData generated from models and simulations.\nNot all primary data are observations collected by people or instruments. We also build mathematical models either based on physical laws or empirical relationships to understand a subject or system. The model can produce a suite of simulations driven by various input scenarios or initial conditions. For example, Coupled Model Intercomparison Project (CMIP) is an international project with participation from more than 20 earth system modeling centers to generate the historical simulation and future projections of the earth system under different greenhouse gas emission scenarios [9]. The Open Data generated in the most recent phase of CMIP (CMIP6) allows researchers to understand the impact of the changing climate to the ecosystem and our society. The understanding derived from CMIP6 data can then be used to inform climate policies and adaptation strategies. Model data are valuable assets because it can provide data that can be hard or sometimes impossible to collect in real world [10].\n\n\nProcessed data\nProcessed data typically refers to data that is created or collected by someone else and used by others.\nExamples include data from literature, academic publications, generated statistics such as government statistics, transcripts of recordings, and a variety of streaming environmental and biological data that are deposited and made available in databases and repositories.\nThis type of data is oftentimes used for a different purpose than originally intended, for example, from a previous experiment or from another research project or a different discipline.\nIt is very common in the era of digital scientific research to see new primary datasets created or produced by collecting and repurposing secondary data and/or mixing them with new primary data. This kind of research practice is made possible by the promotion of Open Data. Data sharing provides opportunities for all researchers, even the novice and/or unfunded, therefore leveling the playing field [11]. More on the benefits of Open Data in lesson 2.\n\n\nMetadata\nMetadata is a special type of data that describes other data or objects (e.g. samples). It is often used to provide a standard set of information about a dataset to enable easy use and interpretation of the data.\nIt can facilitate assessment of dataset quality, by answering key questions, such as including key information on:\n\nHow the data was collected (e.g. which equipment/instruments were used)\nWhich variables/parameters are included in this dataset\nWho or which organization created or collected the data\nWhen the data was collected and deposited\nWhere to find the data (e.g. DOI) and how to cite it\nWhich geographic region the dataset covers\nWho can use the data and how\nWhich version is the dataset\nWhat is the format of the data\nWhether the dataset follows any community or international standards or guidelines\n\nIn addition, metadata allows cataloging and data discovery specially, if it follows leading practices allowing them to be indexed by search engines (The Turing Way, 2019) [12]. In other words, it enhances searchability and findability of the data by allowing other machines to read and interpret datasets (see the concept Findable in lesson 4 - CARE and FAIR principles)\nIn later lessons, we will describe how to create metadata and where to find help (e.g. repositories)\nThere are different types/categories of metadata addressing different purposes:\n\nDescriptive metadata can contain information about the context and content of your data; such as, abstract, title, subject keywords.\nStructural metadata is used to describe the structure of the data (e.g., file format, the dataset hierarchy).\nAdministrative metadata explaining the information that is used to manage the data (e.g., when and how it was created, which software and the version of the software used in data creation).\n\n\n\n\n1.2 What is Open Data?\nThe term “Open Data” is relatively new with the first appearance in 1995 in an article in Paris Tech Review describing the need of sharing Earth and environmental data because “our atmosphere, oceans and biosphere form an integrated whole that transcends borders.” [13]\nIn this lesson, we are adopting the definition of “Open Data” as defined in the Open Data Handbook from the Open Knowledge Foundation [14] [15].\n\n“Open data is data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and sharealike.” Open Data is defined by a set of key attributes, but keep in mind that not all aspects can or will be present at all times as there might be some considerations or restrictions to take into account. This could be partly due to the fact that Open Data does not necessarily mean Open for ALL, but rather Open for the specific individuals and/or communities, more on this in lessons 3 (Responsible Open Data) & 4 (CARE & FAIR Principles) .\n\n\nAvailability and accessibility\nOpen data is characterized by being available and accessible, meaning that it is published on a publicly available platform and accessible to download over the internet allowing others to find it and use it.\nIdeally, scientific research outputs including; research data, metadata, manuscripts, open educational resources, software, hardware and source code are published and made available in both human and machine readable.\nGenerally, Open Data does not require a payment. Nevertheless, in some cases infrastructure costs might be required which can be covered by societies, institutes, organizations etc. More on this in lesson 6 (Sharing Open Data).\n\n\nReusability\nFor Open Data to be useful, it has to be reusable. Without the capacity to reuse it, we are creating “data tombs” where the data is hosted (lives) but is of no value to others [16].\nThere are essential factors that need to be addressed in order for the data to be in good enough shape for others to use it .For instance, researchers and data reusers are mostly looking for data which is “comprehensive, easy to obtain, easy to manipulate, and believable”. For these criteria to be fulfilled the data needs to:\n\nSufficiently described with appropriate metadata, which greatly affects open data reusability. There is no one size fits all for metadata as its collection is guided by your data. More on metadata generation in lesson 5 (Planning for Open Data)\nHas appropriate license, copyright and citation information. See lesson 6 (Sharing Open Data)\nHas appropriate access information. Learn more in lesson 6 (Sharing Open Data)\nFindable in an accredited or trustworthy resource. Learn more in lesson 6 (Sharing Open Data)\nMaintained on a regular basis, addressing feedback from different levels of users\nAccompanied with history of changes and versioning (see definitions) allowing users to point to the exact state of data when they decided to use it.\nFor processed data it is also important to include details of all processing steps. For instance in the case for large data, e.g., it is not common practice for raw genomic reads to be preserved. In most cases processed genomic data are reported, and archived. Hence, some case sensitive data should contain information about processing steps (e.g., calibration, normalization) depending on varying instances.\n\n\n\nInclusivity\nData inclusivity refers to making the data truly open and available for all independent of nationality, location, race, age, gender, sexual orientation, religion, income, socio-economic circumstances, career stage, discipline, language and culture, ability and disability, political ideology, ethnicity or immigration status or any other grounds.\nOpen Data is free from all types of organizational, cultural, political and/or commercial restrictions. A good example of open data transcend national boundary is the world bank poverty headcount data, which is anonymously developed from primary household survey data of different government statistical agencies and World Bank country departments [17].\nThe inclusiveness of open data brings many benefits (Lesson 2 - Benefits of Open Data). However, there are situations when it is not ethical or appropriate to share certain data, or there are considerations to implement additional steps and policies to ensure the proper use of open data (Lesson 3 - Responsible Open Data)."
  },
  {
    "objectID": "open-data/Lesson1-WhatIsOpenData.html#summary",
    "href": "open-data/Lesson1-WhatIsOpenData.html#summary",
    "title": "Open Data",
    "section": "Summary",
    "text": "Summary\nIn this lesson, you learned about different types of data, the definition and key characteristics of open data. You might already have some great examples about open data that you are interested in learning more. In the next lesson, you will be exposed to various benefits and challenges of open data."
  },
  {
    "objectID": "open-data/Lesson1-WhatIsOpenData.html#assessment",
    "href": "open-data/Lesson1-WhatIsOpenData.html#assessment",
    "title": "Open Data",
    "section": "Assessment",
    "text": "Assessment\nSelf Assessment: Do you know the difference between different types of data?\nA researcher needs data on trauma for an ongoing project.\nScenario 1: They visit a trauma center and ask questions to patients in the trauma center. What type of data was collected?\nSenario 2: In the trauma center, they are referred to a database where they can find responses from patients. What type of data was collected? Footer"
  },
  {
    "objectID": "open-data/Lesson1-WhatIsOpenData.html#references",
    "href": "open-data/Lesson1-WhatIsOpenData.html#references",
    "title": "Open Data",
    "section": "References",
    "text": "References\n\nhttps://www.openstreetmap.us/\nhttps://keydifferences.com/difference-between-ungrouped-data-and-grouped-data.html\nhttps://www.datamation.com/big-data/structured-vs-unstructured-data/\nhttps://eospso.gsfc.nasa.gov\nhttps://www.rd-alliance.org/groups/physical-samples-and-collections-research-data-ecosystem-ig\nhttps://www.igsn.org/\nhttps://isamplesorg.github.io/home/\nhttps://zenodo.org/record/6818076#.YtgQhITMK3B\nhttps://www.wcrp-climate.org/wgcm-cmip\nhttps://www.climateurope.eu/a-short-introduction-to-climate-models-cmip-cmip6/\nhttps://www.sciencedirect.com/science/article/abs/pii/S0023969001910987?via%3Dihub\nhttps://the-turing-way.netlify.app/reproducible-research/reproducible-research.html\nhttps://www.paristechreview.com/2013/03/29/brief-history-open-data/\nhttps://opendatahandbook.org/\nhttps://okfn.org/\nhttps://doi.org/10.1093/bioinformatics/btn464\n\nhttps://data.worldbank.org/indicator/SI.POV.DDAY?locations=1W&start=1981&end=2015&view=chart"
  },
  {
    "objectID": "open-tools-resources/contributors.html",
    "href": "open-tools-resources/contributors.html",
    "title": "OpenSciency Open Science Tools: Authors",
    "section": "",
    "text": "Flavio Azevedo\nFORRT & University of Cambridge\nhttps://orcid.org/0000-0001-9000-8513\nhttps://github.com/flavioazevedo\nhttps://twitter.com/Flavio_Azevedo_\nTyson Swetnam\nUniversity of Arizona\nhttps://orcid.org/0000-0002-6639-7181\nhttps://github.com/tyson-swetnam\nhttps://twitter.com/tswetnam\nBatool Almarzouq\nOSCSA, KAIMRC, UoL\nhttps://orcid.org/0000-0002-3905-2751\nhttps://github.com/BatoolMM\nhttps://twitter.com/batool664\nSaranjeet Kaur\nRSE Asia Association\nhttps://orcid.org/0000-0002-7038-1457\nhttps://github.com/SaranjeetKaur\nhttps://twitter.com/qwertyquesting\nMelissa Black\nMetaDocencia\nhttps://orcid.org/0000-0002-5406-2982\nhttps://github.com/melibleq\nhttps://twitter.com/melissablck\nRebecca Ringuette\nNASA Goddard Space Flight Center\nhttps://orcid.org/0000-0003-0875-2023\nhttps://github.com/rebeccaringuette\nElli Papadopoulou\nAthena Research Center / OpenAIRE\nhttps://orcid.org/0000-0002-0893-8509\nhttps://github.com/elpapado\nhttps://twitter.com/elli_lib"
  },
  {
    "objectID": "open-results/README.html#objectives",
    "href": "open-results/README.html#objectives",
    "title": "Open Results",
    "section": "Objectives:",
    "text": "Objectives:\n\nIdentify research stages and elements of research objects that can be considered results\nIdentify the guiding practices and principles related to open results and the advantages of implementing them across stages of a research process\nIdentify paths for publicly communicating results\nCreate open results contributor guidelines and opportunities for open and equitable collaborations\nGive credit to contributors in open results\nContribute and provide constructive feedback to others’ results\nApply open result principles to new and ongoing research projects"
  },
  {
    "objectID": "open-results/README.html#overview-and-key-messages",
    "href": "open-results/README.html#overview-and-key-messages",
    "title": "Open Results",
    "section": "Overview and key messages",
    "text": "Overview and key messages\nThis module addresses different questions discussed systematically across the following four lessons:\nLesson 1: The Research Process and Its Results\n\nWhat are the different stages of the research process?\nWhat are “Research Objects”?\n\nLesson 2: Results in the Context of Open Science\n\nWhat are the advantages of making results open throughout the research process?\nWhat resources are available to help make results open?\nWhat are the guiding principles to turn a research result into an open result?\n\nLesson 3: Applying Open Result Framework to your Research\n\nHow can you apply an open framework across different research objects?\nHow can you share your results, and select **tools**that support open science?\nUsing a checklist to achieve open results\n\nLesson 4: Providing Equitable Opportunities and Credit for Contributors to Results\n\nHow can you define contributors to each digital research object and determine their suitable form of recognition?\nHow can you create contributor guidelines that ensure equity, access, inclusion, and diversity?\nHow can you ensure your open results are properly attributed and cited by others?"
  },
  {
    "objectID": "open-results/contributors.html",
    "href": "open-results/contributors.html",
    "title": "OpenSciency Open Results: Authors",
    "section": "",
    "text": "Batalha, Natasha\nNASA Ames Research Center\nhttps://orcid.org/0000-0003-1240-6844\nhttps://github.com/natashabatalha\nhttps://twitter.com/natashabatalha\nCamacho Toro, Reina\nCERN/CNRS, LA-CoNGA physics\nhttps://orcid.org/0000-0002-9192-8028\nhttps://github.com/camachoreina\nhttps://twitter.com/rcamachotoro\nCampitelli, Elio\nUniversity of Buenos Aires\nhttps://orcid.org/0000-0002-7742-9230\nhttps://github.com/eliocamp\nhttps://twitter.com/d_olivaw\nDunleavy, Daniel\nFlorida State University\nhttps://orcid.org/0000-0002-3597-7714\nhttps://github.com/dunldj\nhttps://twitter.com/Dunleavy_Daniel\nErdmann, Christopher\nMichael J. Fox Foundation\nhttps://orcid.org/0000-0003-2554-180X\nhttps://github.com/libcce\nhttps://twitter.com/libcce\nFouilloux, Anne\nUniversity of Oslo, Norway\nhttps://orcid.org/0000-0002-1784-2920\nhttps://github.com/annefou\nLacerda, Michel\nGeorgia Institute of Technology\nhttps://orcid.org/0000-0002-8433-6964\nhttps://github.com/michelusp\nSaderi, Daniela\nPREreview, Code for Science & Society\nhttps://orcid.org/0000-0002-6109-0367\nhttps://github.com/dasaderi\nhttps://twitter.com/Neurosarda\nSharan, Malvika\nThe Alan Turing Institute and Open Life Sciences\nhttps://orcid.org/0000-0001-6619-7369\nhttps://github.com/malvikasharan\nhttps://twitter.com/malvikasharan"
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#introduction",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#introduction",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "Introduction",
    "text": "Introduction\nIn the previous lesson, we learned about foundational concepts that define Open Science. In this lesson, we address some benefits and challenges of working in the open.\nHere we aim to present a take on the development of science that’s not only focused on scientific results but also on the process of creation, and the stakeholders that constitute the community.\nStakeholders can be individuals producing scientific knowledge (i.e, researchers themselves), individuals consuming, applying and regulating scientific research (i.e., practitioners, general public, policy-makers, organizations, communities, etc.), and the larger scientific ecosystem (i.e., scientific journals, repositories, archives, etc.). We discuss more about the people who perform and benefit from open science - and how to support them - in Lesson 3.\nIn this lesson, we highlight the various benefits of open science across multiple stakeholders, providing some examples that can be explored further. Further, challenges in adopting open science practices are explored."
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#benefits-of-open-science",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#benefits-of-open-science",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "Benefits of Open Science",
    "text": "Benefits of Open Science\n\nQuality of research\nFor researchers, a primary benefit of increased transparency and verifiability is that it allows readers and stakeholders to judge whether results presented are accurate (Chambers, & Tzavella, 2022) and, importantly, that the results are not produced by questionable research practices that lead to misleading or unreliable results (John et al., 2012). Open science practices assure that various statistical estimates of a study (e.g., p-values, effect sizes) can meaningfully be interpreted (Mayo, 2017; Cummings et al., 2016). And allows others to scrutinize the analytic decisions of the researchers, such as whether the analysis was planned before or after observing the data (Nosek et al., 2018). This allows others to check if they can arrive at the same conclusion as the original research team, and facilitates stronger public trust and support (UNESCO, 2021).\n\n\nReal world implications of non-transparent science\nThe Free Software Foundation Europe (FSFE) provides a compelling position paper explaining why transparency is important for science. When computers are used to produce scientific research, the code is considered a “method”, much like in a lab research setting, a set of instructions for working with cells or agar plates might be a method. Peer-reviewed methods are an essential step in the scientific process. When these steps are not shared, no-one else can reproduce the work, or build upon it for future scientific endeavors. It also allows people to judge whether or not the methods are trustworthy.\nIn this case study, the FSFE reminds us of a time when closed methods were not trustworthy. Volkswagen revealed it intentionally programmed its diesel engines to cheat during laboratory emissions testing. This meant that people drove these cars thinking they were trustworthy and safer for the environment than they actually were. In this case, the real emissions from the engines were more than 40 times over the legal limit in the USA! Had the code for the diesel engines - the “scientific methods” - been open, it is possible that this untrustworthy behavior would have been picked up on much earlier. (Gkotsopoulou et al., 2017).\n\n\nQuality and diversity of scholarly communications\nFurthermore, open science improves the state of scientific literature. Scientific journals have traditionally faced the severe issue of publication bias, where journal articles overwhelmingly feature novel and positive results (Devito & Goldacre, 2018). This results in a state where scientific results in certain disciplines published scientific results may have a number of exaggerated effects, or even be “false positives” (wrongly claiming that an effect exists), making it difficult to evaluate the trustworthiness of published results (Simmons et al., 2011; Nissen et al., 2016). Open science practices such as registered reports mitigate publication bias, and improve the trustworthiness of the scientific literature. Registered reports are journal publication formats that peer-review and accept articles before data collection is undertaken, eliminating the pressure to distort results (Chambers, & Tzavella, 2022). Other open science practices, such as 📖pre-registration📖 also allows allows a partial look into projects that for various reasons (such as lack of funding, logistical issues or shifts in organizational priorities) have not been completed or disseminated (Evans et al., 2021) giving these projects a publicly available output that can help inform about the current state of the field.\n\n\nNot everything should be pre-registered\nPre-registration is the practice of registering your scientific study/experiment plans before you start the study. This helps to ensure that the experiment isn’t changed part-way through if the results aren’t the conclusion the researchers had hoped for, and can help ensure publication of “null results” which otherwise might not be published.\nPre-registration is a good tool for hypothesis-driven science, when a researcher starts with a hypothesis, then proceeds to define steps (methods) to prove or disprove the hypothesis. Not all science is hypothesis-driven, though. Discovery driven science is more exploratory and doesn’t usually start with a hypothesis. It may instead involve looking at existing data, or collecting more data, and trying to form conclusions based on the available evidence. Many domains perform discovery science, and generally these experiments and studies aren’t suitable for pre-registration, since the exact direction of study may not be clear at the start of the research.\nOpen Science is also a valuable tool to be used in the public sector. Movements like Public Money Public Code were started by people who believe in the value of having open research and data freely available to the population. Remarkable advances on the way we exerce democracy are also being empowered by science made on the open, software like Polis which leverages the concepts of Computational Democracy, empowers scientists to run statistics and machine learning technologies on opinions of millions of citizens. In other words, open science facilitates 📖citizen science📖.\nResponse to societal challenges\nAs science tackles consequential topics (climate change, pandemics and global health, democracy and misinformation), the transparency and verifiability of science is more important than ever. This is highlighted during the pandemic, where the creation of life-saving vaccines were spurred because the genomic sequence of SARS-CoV-2 was placed in GenBank, an open access database (Zastrow, 2020). Open science allows for rapid, global access and action especially for shared problems too difficult to solve by any one team alone.\nResponsible Open Science is not only beneficial - it can also be characterized as an ethical imperative, especially for publicly funded projects. UNESCO (2021), for example, writes “​​so as to ensure the human right to share in scientific advancement and its benefits, member states should establish and facilitate mechanisms for collaborative open science and facilitate sharing of scientific knowledge while ensuring other rights are respected”\nThe recent years have shown the great momentum of open science, with a number of funders, regulatory organizations and governing bodies mandating open science practices across various disciplines across the globe (e.g. European Commission; UNESCO, 2021; National Academies of Sciences, Engineering, and Medicine. 2018 ), with more details about it in Lesson 4 . The practicing scientist of today and especially of the future needs to learn about open science and start applying it into everyday practice.\n\n\nLess unnecessary repetition is better for study participants\nOpen science, in a way, also gives back to the communities that scientists hope to serve. Through open science practices, research waste can be avoided, such as unintentional and costly repetition of previous studies (Lusoli and Glenos 2020). In the human sciences, this also reduces participant fatigue in the long term. By maximizing what is learned from publicly available data, one does not need to test repeatedly especially on already vulnerable communities. By “giving away” science, individuals, communities and organizations can more easily adopt research results to inform interventions for their own needs without the knowledge being gatekept by the original researchers and organizations involved. In this way, open science can facilitate strengthening the social and economic impacts of scientific results.\n\n\nPersonal/career benefits\nAside from accuracy, adhering to open science practices potentially offers personal career benefits to researchers themselves. Openly published research has a potential for greater visibility and impact by reaching larger audiences across the internet, leading to more citations and more like-minded collaborators and career/funding opportunities. (McKiernan et al., 2016).\nOpen science practices can also enable stronger collaborations, both within and between disciplines (Hormia-Poutanen, & Forsström, 2016). The ease of access to open data brings new agents to the landscape allowing for broader and more diverse participation. Through open science practices, such as pre-registration, one allows for a stronger research design because feedback from various collaborators and stakeholders can be solicited before data collection begins. Similarly, preprints allow for speedier feedback on conclusions drawn from the data once it is collected.\nCase study of a successful collaboration:\nMozilla, an organization famous for the web browser Firefox, also runs a community-driven project called Common Voice. Common voice is an open crowd-sourced dataset of different voices and speech patterns, covering many different languages, accents, countries, and speech patterns. By making this data open and facilitating contributions from volunteers worldwide, speech recognition technology and text-to-speech technology is democratized and represents the members of the populace more equitably.\nPracticing open science with transparency, collegiality, and research integrity do require development of a whole set of technical and transferable “soft” skills, which would be extremely useful for researchers in their careers both in academic or non-academic sector. Some examples include digital content creation; information, publication, data literacy; communication and collaboration skills - we will come back to it in the bonus section of lesson 5. Therefore, It is important to have the training and mentoring widely offered to the researchers.\nShort on time? Make sure to read the top-ten reasons to do open science at the end of this lesson for a quick TL;DR summary."
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#challenges-in-open-science",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#challenges-in-open-science",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "Challenges in Open Science",
    "text": "Challenges in Open Science\nHowever, open science also comes with its challenges. Doing open science requires some extra effort from researchers to start and maintain, but its long-term benefits include a great overall increase in research efficiency, integrity, and public trust. For example, putting your code in the open will probably mean that some adjustments must be made, and sharing it with a community will demand that you choose how your contributions can be used by others. Sharing data can imply extra work and planning; however this organization and widespread discovery can greatly improve science and confidence in it. We will see more details on code sharing and licensing in the “How” lesson 5.\nIn this lesson we focus on the challenges of your work, and the consequences of sharing - and in some cases, oversharing.\n\nNot everything should be open - don’t overshare without consent!\nIn order to practice responsible Open Science, careful attention should be given to how data is anonymized and how sensitive information is removed from it in order to safeguard people’s identity and to prevent various harms stemming from breach of privacy. In recent history, we have seen many cases of how the misuse of data and illicit means to collect it is harmful to the population. Scandals like the Facebook–Cambridge Analytica, and outrageous services selling very personal parts of users’ lives without their knowledge and full consent are far too common. Preparing documentation, using standards, and creating metadata takes time and effort\nAdditionally to treating users’ data ethically, often further work is required to make research outputs not only publicly available but also understandable and accessible to various stakeholders. This means for example, that codes to be shared are understandable and properly documented. This might mean to have a testing system in place, make use of a distributed version control software and a CI/CD pipeline. If you’re unfamiliar with any of these terms, don’t worry! They will be covered in the “Open Software” module. (Maybe this last sentence is a cute little character with a balloon)\nBesides caring about code, if the project utilizes data and that’s being open sourced, it might be necessary to also have documentation that adequately describes the data set’s contents, nature and layout. This type of “data about data” is known as “📖metadata📖”. It might also mean to tweak the formatting of the dataset to fit a specific pattern agreed by the broader community - this is known as using community-agreed data standards."
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#open-community-members-dont-always-agree-with-each-other",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#open-community-members-dont-always-agree-with-each-other",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "Open community members don’t always agree with each other",
    "text": "Open community members don’t always agree with each other\nOther than the more technical aspects of producing Open Science it’s also important to keep in mind the societal aspects of the project. While interacting with the community can be one of the most fulfilling things about Open Science, it might also be a source of disagreements about the direction of the project or how it should be used. That’s where licenses and codes of conduct come into place. By explicitly setting out rules for the community interactions and use of resources, licenses and codes of conduct are useful to both protect the maintainers and their vision of what the original project and the 📖forked📖 projects should comply with."
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#case-scenarios-in-open-communities",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#case-scenarios-in-open-communities",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "Case scenarios in open communities",
    "text": "Case scenarios in open communities\nAs you saw in the last lesson the story of Open Software (which builds the foundation for Open Science) is vast and at times different open values can conflict deeply. Two particularly relevant movements that helped to shape our ideas and actions in Open Science today are the Open Source and the Free Software movement.\nThe Open Source Initiative, an organization that advocates for Open Source, argues that Open Source code can’t “discriminate against persons, groups, fields or endeavors”, the Free Software movement affirms that “everyone should have the freedom to run the program as they wish, for any purpose”. Even though these maxims might sound very encompassing and welcoming there are several critics of the carelessness that these movements have been treating both maintainers and users of Open Source, as well as their gullible negligence on how powerful a tool code is and how it can be used to do evil.\nSpeaking about doing evil, the Open Source Initiative addresses this problem with these exact words “Giving everyone freedom means giving evil people freedom, too”. Recent movements like the Ethical Source and the First Do No Harm movements have been questioning the broadness of paradigms in which open resources are allowed to act, imposing ethical restrictions to the use of software through the use of licenses. There are also cases where the project maintainers took the lead and made their own licenses, such as for the data format JSON.\nExamples of open science and open source that have been used for unintended purposes.\n\nICE uses Chef-sugar (an open source project) [1] - an open source project being used by immigration enforcement authorities Illegal use of Elasticsearch branding by Amazon [2][3]\nAll the “what’s bad” essays on Stallman’s website\n📖Data Sovereignty📖, indigenous rights, and parachute/helicopter research: when marginalized people share their data, sometimes privileged researchers re-use the data without fair credit or funding reaching the original data creators.\n\nFurther, science that is just “open” does not necessarily mean that it is of high quality. However, the transparency and verifiability that open science affords, makes readers and various stakeholders able to independently judge the trustworthiness of research products."
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#cultural-barriers-not-everyone-wants-to-change-and-institutions-often-move-slowly",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#cultural-barriers-not-everyone-wants-to-change-and-institutions-often-move-slowly",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "Cultural barriers: not everyone wants to change, and institutions often move slowly",
    "text": "Cultural barriers: not everyone wants to change, and institutions often move slowly\nA further challenge of adopting open science practices are institutional barriers to the researcher or practitioner. While one might be interested in adopting open science practices, they might lack support from their department or project supervisors and open science practices might not be given the budget, resources or time in a project cycle. Institutions might also not recognize open science practices in recruiting, training or promoting in the organization. These lack of incentives within organizations present difficult barriers to the adoption of open science.\nWhile there are many challenges to the adoption of open science, we believe that its various benefits and its ethical imperative to the self and to the scientific communities, citizens and policy-makers outweighs the cost of barriers. In addition, recognising the barriers and places where caution needs to be taken provides a first step towards resolving them."
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#summary",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#summary",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "Summary",
    "text": "Summary\nOpen Science provides benefits not only to society but also to the individuals who perform it. Walking the line between responsible appropriate sharing and irresponsible oversharing requires diligence but the path and the results of science made in the open are very rewarding to all its stakeholders."
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#reasons-to-practice-open-science-responsibly",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#reasons-to-practice-open-science-responsibly",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "10 Reasons to practice open science responsibly:",
    "text": "10 Reasons to practice open science responsibly:\n\nresponsible Open Science…\n\n… (including availability of data, code, materials, and early results) accelerates research broadly and greatly.\n… generates transparency and public trust and support\n… fosters working across and engaging multiple disciplines, or “convergent” science.\n… brings innovation through using big and aggregated data and information\n… supports public and community uses of science: also known as community science, participatory science, or citizen science.\n… helps fight misinformation and disinformation\n… is intentionally and thoughtfully inclusive practice\n… supports the key role of science in addressing major societal challenges in the 21st century (including climate change, sustainability)\n… makes your research more efficient and impactful and provides credit broadly responsible Open Science is the new normal,and regulatory and governing bodies are reaching a consensus toward pushing it)."
  },
  {
    "objectID": "ethos-of-open/lesson2-benefits-challenges-of-open.html#questionsreflection",
    "href": "ethos-of-open/lesson2-benefits-challenges-of-open.html#questionsreflection",
    "title": "Benefits and Challenges of responsible Open Science: Why does it matter?",
    "section": "Questions/Reflection:",
    "text": "Questions/Reflection:\n\nWhy are responsible Open Science practices important to a researcher’s profile?\nHow can a researcher benefit from responsible Open Science practices?\nHow does society benefit from responsible Open Science?\nIn this lesson, we learned that responsible Open Science often takes time and requires diligence and dedication of researchers. Can you explain how and why?"
  },
  {
    "objectID": "ethos-of-open/lesson3-open-stakeholders.html#introduction",
    "href": "ethos-of-open/lesson3-open-stakeholders.html#introduction",
    "title": "Stakeholders of Open Science: Who practices responsible Open Science and for whom?",
    "section": "Introduction",
    "text": "Introduction\nIn previous lessons, we learned about the concept and motivation and aspiration of open science. Now let’s think about “who” is practicing open science and for whom. In the first section of this lesson we dive deeper into understanding who the stakeholders for Open Science are. In the second part we cover essential topics about barriers to participation, and to include diverse stakeholders in open science communities and ways to overcome them.\nIn this module we offer you a person-centered approach to making open science happen. Our intention is to prevent harmful consequences of science’s misuse (even unintentional misuses) and to increase the impact of science, by leveraging other researchers’ works and improving society."
  },
  {
    "objectID": "ethos-of-open/lesson3-open-stakeholders.html#who-performs-and-benefits-from-open-science-stakeholders-partaking-in-open-science",
    "href": "ethos-of-open/lesson3-open-stakeholders.html#who-performs-and-benefits-from-open-science-stakeholders-partaking-in-open-science",
    "title": "Stakeholders of Open Science: Who practices responsible Open Science and for whom?",
    "section": "Who performs and benefits from open science? Stakeholders partaking in open science",
    "text": "Who performs and benefits from open science? Stakeholders partaking in open science\nAs briefly discussed in previous lessons, Open science doesn’t only concern researchers; many other stakeholders are affected by the outcomes of open science as well. Stakeholders are any individuals who can affect or be affected by open science projects. Although there are different ways to categorize stakeholders depending on your science projects, mainly there are three large groups; 1. Researchers, 2. Public, and 3. Policy-makers.\n\nResearchers\nOrganizations\nResearch Teams\nGeneral public\nDecision Makers (regulatory, funding bodies, etc)\nGovernment\n\n\nResearchers\nIndividuals engaged in creating new knowledge (e.g. researchers, students, faculty staff at universities, researcher centers, researchers at libraries). Responsible for creating an open science environment as well as open outputs and processes.\n\n\nPublic\nLay people who can drive/improve/conduct science (i.e. people who may not have an academic background or research experience). This may also be referred to as “citizen science”, but you do not have to be a citizen of any particular country in order to participate in science!\n\n\nPolicy-makers\nThose with decision-making power (e.g. government, regulatory bodies)"
  },
  {
    "objectID": "ethos-of-open/lesson3-open-stakeholders.html#how-each-group-contributes-to-open-science",
    "href": "ethos-of-open/lesson3-open-stakeholders.html#how-each-group-contributes-to-open-science",
    "title": "Stakeholders of Open Science: Who practices responsible Open Science and for whom?",
    "section": "How each group contributes to Open Science",
    "text": "How each group contributes to Open Science\nLet’s take a look at these groups, how they can contribute to open science (input) and what benefits they experience from open science (this was also discussed in Lesson 2). Note that overlap among researchers, the general public, and policy-makers can happen.\nResearchers’ contribution to open science manifests by sharing and communication their research via open access publications (more about it in the Lesson How and Module Open Results) As a result, community of researchers benefits from increased visibility and credit, reproducibility, access to more data and attraction of funding, reduced work’s duplication, conservation of resources and increased accessibility\nThe general public contributes to open science research by above mentioned “citizen science” projects, as e.g. as volunteers to collect or manage (e.g. categorize) some type of data.\nAs a result, individuals boost their understanding of science and feel empowered by having opportunities to exert influence. Disinformation in the public arena is decreased, and the routes of access to trustworthy sources of information are strengthened.\nPolicy-makers play important role in ensuring and facilitating open science by setting data management processes, open access legislation, developing ethical guidelines for experiments As a result, higher quality of research done with open science principles and efficient communication between stakeholders leads to better-informed decisions\nThis figure briefly shows how three groups of stakeholders interact with each other. Healthy interactions will foster respect and overcome power dynamics. Each group should focus on empowering other groups and be aware that open science cannot exist without the others. Resources and tools for interactions are described in greater detail in Lesson 5, (and in the tools and results modules)."
  },
  {
    "objectID": "ethos-of-open/lesson3-open-stakeholders.html#case-scenarios",
    "href": "ethos-of-open/lesson3-open-stakeholders.html#case-scenarios",
    "title": "Stakeholders of Open Science: Who practices responsible Open Science and for whom?",
    "section": "Case scenarios",
    "text": "Case scenarios\nNow let’s take a look at examples of successful interactions around the world!\n\nCase Scenario #1: Trend: Public —> Policy-makers\nThe public has many opportunities to join research projects and can play prominent roles in science. There are more than 30 ways to define Citizen Science (Haklay et al., 2021), and the principle is “active public involvement in scientific research” (Irwin, 2018). Citizen Science contributes to policy making at various stages of the policy cycle, including policy preparation, formulation, implementation, monitoring, and evaluation Scade et al (2021). That is to say, citizens are capable of setting trends and informing the directions in policy making.\nIn 2015, the United Nations adopted the 2030 Agenda for Sustainable Development for peace and prosperity for people and the planet, now and into the future (United Nations, 2021). This agenda has 17 specific goals that require a large amount of data. Citizens have been contributing by providing the water and air quality, marine litter, biodiversity, health, and gender issues data (Fritz et al, 2019), and Scade (2021) describe this as ” a source of information for policy making.” This is a powerful example of citizens influencing global policy trends.\n\n\nCase Scenario #2: Officialize: Policy-makers—> Researchers/Public\nPolicy-makers can implement new regulations for both researchers and the public. Bothwell and Smith (2017) reported that policy can shape knowledge. For example, policies such as dispersion of research funding (i.e. which science disciplines including Citizen Science receive the most funding), and data management plans for the public can impact the amount of knowledge produced.\nMost importantly, policy-makers are mindful that researchers and citizen scientists conduct science projects safely and ethically. National Institute of Health (2022) states that policy sometimes sets the rules of the road for conducting research, helping ensure that scientific investigations are carried out safely, securely, adhering to the highest standards of research integrity, and in a way that addresses evolving ethical concerns. We can find these ethical policies, for example, NIH Guidelines for Human Stem Cell Research. Some countries have legislation requiring research to be published openly, such as Spain’s open access legislature. Policies on open access for European countries are monitored and reported by corresponding OpenAire National Open Access Desks.\n\n\nCase Scenario #3: Participate: Public —>Researchers\nCurrently, NASA has 28 Citizen Science projects that are open to people around the world (NASA, 2022). According to NASA Citizen Science policy, Citizen Science is defined as a form of open collaboration in which individuals or organizations participate voluntarily in the scientific process in various ways. The projects vary from Earth and planetary science to biological science such as researching meteorites, mosquitos, and the surface of Mars.\nOne of the evaluation criteria for NASA Citizen Science is; two-way communication between volunteers and NASA scientists and including diverse citizen scientists, with scientists giving feedback to and receiving feedback from the volunteers (NASA SMD Policy Document SPD-33, 2018). Also NASA creates opportunities for citizen scientists to be co-authors for publications and 191 NASA Citizen Scientists joined scientific publications since 2011 (NASA, 2022).\nIn addition to citizen science, there is an emerging concept called community science and co creation. Community science refers to science projects that honor community priorities. They can be initiated by a science practitioner or a community member, but they must become a collaborative endeavor (ASTC, 2021). Co-creation in science refers to the collaboration between a variety of actors (people from different societal roles) actively joining forces to tackle jointly defined challenges (Stier and Smit, 2021). We can also state that community science, which prioritizes community needs, succeeds through efforts of co-creation.\nCharles et al (2020) introduced a successful case of community science. One example is protecting one of the remote islands in Canada that is facing the threats of sea level changes (e.g. salt water intrusion to groundwater and losing archaeological sites). As a result of community science and co-creation through public, universities, and policy makers, now climate-related mapping and visualization techniques for vulnerability assessments are available for use within the community. This provides opportunity for all the residents to explore adaptation options to ongoing sea level changes. The community was also able to work with archaeologists on preservation initiatives.\n\n\nCase Scenario #4: Share: Researchers —>Policy-makers/Public\nAbout 2,000 researchers work together to create a report for the Intergovernmental Panel on Climate Change on the current situation, which is a technical report that most people would have trouble understanding (Woolston, 2016). Some climate researchers break down their results to explain to policy-makers and citizens. Policy makers can utilize the results to officialize the restriction of CO2 emission level (e.g. Paris Agreement) and the public can be aware about what they can do in their daily lives to achieve the CO2 emission goal. This shows that each group is playing a significant role in addressing the climate science project, which is considered as one of the critical issues that our generation is facing."
  },
  {
    "objectID": "ethos-of-open/lesson3-open-stakeholders.html#how-diverse-stakeholders-are-included-in-open-science",
    "href": "ethos-of-open/lesson3-open-stakeholders.html#how-diverse-stakeholders-are-included-in-open-science",
    "title": "Stakeholders of Open Science: Who practices responsible Open Science and for whom?",
    "section": "How diverse stakeholders are included in open science:",
    "text": "How diverse stakeholders are included in open science:\nStakeholders are incredibly diverse in terms of culture, communication, and ability. To make science truly open, we must ensure that open science is accessible to everyone, so that we can all fully participate and benefit from the work. The best way to include stakeholders is to remove existing barriers and design for inclusion.\nCreating a more inclusive environment will both increase the amount of people who feel welcomed to contribute back to your research and will broaden the scope of people that can comprehend and interact with the products of the research. Small actions towards conforming to accessibility and diversity guidelines will go a long way towards making your work truly open to all, maximize the visibility and impact of research..\nLet’s look at some factors and potential barriers for participation in the open science, with possible solutions:\n\nSocioeconomic status:\nInstabilities in the electric, electronic and internet access (e.g. load-shedding, internet speed, electronic device performance)\nPossible solution(s): open science materials and communication channels should require less resources whenever possible\n\n\nNeurodivergence:\nDiversity of neural architecture leads to different learning and socialization styles\nPossible solution(s): employ multimodal communication strategies using different visual and audio outputs, varied pace of events and conversations\n\n\nDisability/impairments\n\nSensory - e.g. colorblind, blind, deaf, auditory and/or visual processing conditions\nPhysical - e.g. conditions that affect energy levels, neuromuscular coordination conditions\nMental - conditions that affect mental health (e.g. depression, schizophrenia, etc)\n\nPossible solution(s): employ multimodal strategies and universal design to provide proactive accommodations for as many as possible - captions, transcripts, colorblind-friendly palette, document formatting that are compatible with screen readers, normalizing flexible work schedules and rolling deadlines with collaboration\n\n\nIntersecting Identities and intersectionality\nEpistemic oppression - e.g. dominance of English as the international language for all science. Non-native English speakers are disadvantaged by default.\nPossible solution(s): Proactive translation of open science results/communications in other languages\n\n\nMicroaggressions/macroaggressions:\nUse of words with negative connotations towards individuals and groups and negative behavior/ostracization\nPossible solution(s): Employ language and communication with neutral connotations that do not use pejorative terms or vilify a group (example) in biology, we use males to identify the parent with testes and the female with ovaries; should change language to “parents with testes/ovaries” etc) Gender Inclusive Biology for more detail\n⚠️ Caution: Full participation in open science requires respect of an individual’s identity, autonomy, and lived experiences. Microaggressions, macroaggressions, and epistemic oppression are identity barriers to open science.\nThis list is not comprehensive, but is meant to be a starting point in preparing your work in open science for diverse stakeholders."
  },
  {
    "objectID": "ethos-of-open/lesson3-open-stakeholders.html#activityexercise",
    "href": "ethos-of-open/lesson3-open-stakeholders.html#activityexercise",
    "title": "Stakeholders of Open Science: Who practices responsible Open Science and for whom?",
    "section": "Activity/exercise",
    "text": "Activity/exercise\nNow let’s practice by looking at some typical case scenarios and solutions, reflecting on things you could do for inclusion:\n\nCase Scenario #1: Accessible figures and writing\nYou have finished your project and are busy typing your paper to submit to an open science preprint journal. In your paper, you have several figures that use multiple colors at once - red, green, and blue. In addition, you have formatted your paper to use a serif font at size 10. You want to make sure that your paper is easily readable for everyone. What are some things you can do?\n\nColorblind people have high difficulty with red, green, and blue colors. You can check your figures by running a color blind simulator, e.g. open source RGBind. Consider using colorblind-friendly palettes with colors such as green, magenta, and others. Avoid using color hues to convey information if at all possible.\nLegally blind and dyslexic people have difficulty with font size and font types. Consider using a font size of 12 or higher, and use a ‘Sans-Serif font’ such as Arial or Verdana to assist people with dyslexia in reading your manuscript.\n\nBonus question: What should you do if a journal insists on using a font size and font type that is inaccessible to some people?\n\n\nCase Scenario #2: Organizing an inclusive physical event\nYou are the head organizer for an open source code hackathon for your organization. Your boss initially suggests using the large seminar room with one projector and screen that is hard to see from the back of the room. When starting the hackathon, you find out that a couple of attendees are deaf and a couple of other attendees have visual difficulties. What are some quick things you could do to help them fully participate in the hackathon?\n\nIf doing a presentation on Powerpoint, you can turn on ‘Always use subtitles’ for live transcription. Check if your font size on your presentation is large enough to comfortably see at the back of the room.\nIf possible, consider simulcasting the presentation on Zoom or other virtual platform with captions/transcription.\nUse text for communicating with deaf attendees.\n\n\n\nCase Scenario #3: Organizing an inclusive virtual meeting and preparing in advance\nYou are organizing a virtual open science meeting with established and prospective members from different countries. You are unsure of what the prospective members need in order to participate fully, and no one emailed you to let you know about accommodations they need. What should you do?\nBeing proactive with small things you can do ahead of time by implementing some of the accommodations before the meeting (see possible solutions to barriers that we have just considered). While it is difficult to preconceive every possible accommodation that you might need to provide for your members, if you communicate your willingness to do everything you can to help members thrive, you are doing incredibly important work to not only recruit prospective members to open science, but also to retain them.\nBonus tip: Subtitles and closed captioning are not only for deaf/hard-of-hearing people, they are also very beneficial for non-native English speakers to understand the conversation fully. Consider using a third-party app such as otter.ai for accurate closed captioning and simultaneous transcripts that can be saved for members to read through.\nWhat are some other accommodations that could be useful for everyone in general?"
  },
  {
    "objectID": "ethos-of-open/lesson3-open-stakeholders.html#summary",
    "href": "ethos-of-open/lesson3-open-stakeholders.html#summary",
    "title": "Stakeholders of Open Science: Who practices responsible Open Science and for whom?",
    "section": "Summary",
    "text": "Summary\nIn the first part of this lesson, we learned about the types of stakeholders and how they can interact to empower each other. Successful examples were introduced, and you can reflect and analyze how to develop these interactions in your science projects. These arrangements may initially take time, but the outcome is essential to advance science, and is also rewarding.\nIn the second part of the lesson, we studied how diverse stakeholders can be included in open science with case scenarios designing for inclusion. Taking measures to maximize diversity, inclusion, and accessibility of your science project will enrich the project, boost its visibility and engagement of participants. Healthy interactions among stakeholders with diverse members creates the strength of science projects and rewarding results, and a diverse team drives innovation to success. Remember that what you learned here is not an optional choice but an integral part of responsible Open Science.\nTo learn more about joining, contributing to, and creating your own communities, consider visiting the Tools module."
  },
  {
    "objectID": "ethos-of-open/lesson3-open-stakeholders.html#questionsreflection",
    "href": "ethos-of-open/lesson3-open-stakeholders.html#questionsreflection",
    "title": "Stakeholders of Open Science: Who practices responsible Open Science and for whom?",
    "section": "Questions/Reflection:",
    "text": "Questions/Reflection:\n\nWhat steps can you take to make these open science resources more inclusive?\n\nWritten resources and images\nConferences - virtual, physical, or hybrid\n\nCommunication with the general public and policy makers should not be something that researchers only do when they have spare time, after the research is done and published. It should be treated as a critical part of a science project, to certain extent at all stages of development Explain multiple possible communication channels and strategies for researchers, and why each is important."
  },
  {
    "objectID": "ethos-of-open/lesson4-impact-of-open.html#introduction",
    "href": "ethos-of-open/lesson4-impact-of-open.html#introduction",
    "title": "Impact of Open Science on academia, communities and society as a whole: Where open science happens.",
    "section": "Introduction",
    "text": "Introduction\nWe have so far explored the fundamental parts of what Open Science is: why to pursue it and who the stakeholders of open research are. Where you are in the world when performing open science can have an impact on how you perform it, too. Laws across the world vary, and the advantage of open science means people from around the world can participate, co-create, and consume content together. This can affect your work from social and legal perspectives, and may present technical challenges as well.\nLegal frameworks that affect responsible Open Science Open Science promises to make research work more accessible, all-encompassing, participatory, understandable and re-usable for wider audiences. Keep in mind, making the process open does not in itself result in wide participation unless it’s partnered with sufficient financial resources, technological advancements, knowledge and skills. It’s important that all these are available across regions, institutions and socio-demographics (review by Hellauer et al. 2022)"
  },
  {
    "objectID": "ethos-of-open/lesson4-impact-of-open.html#data-protection-privacy-and-data-sovereignty",
    "href": "ethos-of-open/lesson4-impact-of-open.html#data-protection-privacy-and-data-sovereignty",
    "title": "Impact of Open Science on academia, communities and society as a whole: Where open science happens.",
    "section": "Data protection, privacy, and data sovereignty",
    "text": "Data protection, privacy, and data sovereignty\n⚠️Caution: To perform open science responsibly, it is important to consider not only what you should share, but also what not to share.\nIndividuals may have a right to privacy in their communications, for medical records, and for their physical locations. Similarly, certain countries, communities, and especially Indigenous peoples may historically have been exploited, and may wish to retain more rights over their knowledge to protect from further exploitation. Globally, there are laws around the world that may cover some of these issues, but not all countries and regions have equal levels of protection, and some have none at all.\nWe share some case studies:\n\nEuropean case: General Data Protection regulation\nThere are protective laws and legal frameworks in certain places around the globe that affect open science. European researchers have to abide by the General Data Protection regulation (GDPR) while making a data sharing statement stating the non-availability of data sharing. This hinders sharing particular data. Here, the scientific society should come forward to allow responsible Open Science data sharing possibilities in the global scientific space (Giske Ursin & Heidi Beate Bentzen, 2021)\n\n\nSouth African case: Protection of Personal Information Act (POPI Act) and Open Science\nThe POPI Act No. 4 of 2013 is regulation by the government of South Africa to safeguard the personal information of South African citizens, like the General Data Protection Regulation (GDPR) in Europe. The regulation states that if one is obtaining personal information of South African citizens through phones, focus groups, interviews, containing identifiers such as names, contact information then you have to be POPI Act compliant.\nIn the research context, one needs to make sure that if the personal identifiers are collected then they must not be shared with third parties and stored securely in an access-controlled location to prevent a data breach. The act doesn’t impede open data sharing, but personal identifiers should be removed from shared datasets. The POPI act affects the research process, in a way to make sure that storing of data of only de-identified datasets on cloud storage & onsite data storage is strictly controlled to specific designated individuals to ensure data safety (POPIA Code of Conduct for Research, 2021).\n\n\nUnited States case:\nIn the United States, there is no federal-level legislation similar to POPI or GDPR, but there are some state-level laws, such as the California Privacy Rights Act, and the Virginia Consumer Data Protection Act.\n📝 Exercise: Check what laws, if any, apply in your state.\n\n\nSummary: Working in a global society with varied data protection laws\nGiven the broad variation of data protection laws around the world, it may seem tricky to navigate. By practicing responsible Open Science, however, our response can get a little bit clearer. We can consider relevant legislation (if any) to be a bare minimum, and instead ensure that we are involving relevant stakeholders, as discussed in lesson 4, and listening to their needs respectfully, even if it means we are more cautious than local legislation may require."
  },
  {
    "objectID": "ethos-of-open/lesson4-impact-of-open.html#whose-laws-apply-to-my-community",
    "href": "ethos-of-open/lesson4-impact-of-open.html#whose-laws-apply-to-my-community",
    "title": "Impact of Open Science on academia, communities and society as a whole: Where open science happens.",
    "section": "Whose laws apply to my community?",
    "text": "Whose laws apply to my community?\nSocial, cultural, and legal norms will vary from country to country, and international communities. Avoiding culture clashes can be made more manageable by setting out explicit cultural norms for your community, such as may be specified in a code of conduct, which we discussed in lesson one of this module. Try to avoid assumptions that tie to a specific physical location or culture. Some examples why this is important:\n\nLaws are not uniform. If activity X is legal to do in one country, but not another, a code of conduct which says “obey the law” becomes impossible to interpret fairly or to enforce.\nHosting a conference in a country that doesn’t have strong human rights records might result in someone breaking the law by being LGBTQIA+, or by not wearing religious garb.\n“We plan to release this in the summer” might be clear if you’re all in the same country, but if your collaboration is spread across the northern and southern hemisphere, is summer in the middle of the year or the end of the year? Consider using a month name instead - “we plan to release this by March” is unambiguous."
  },
  {
    "objectID": "ethos-of-open/lesson4-impact-of-open.html#equity-and-open-science",
    "href": "ethos-of-open/lesson4-impact-of-open.html#equity-and-open-science",
    "title": "Impact of Open Science on academia, communities and society as a whole: Where open science happens.",
    "section": "Equity and Open Science",
    "text": "Equity and Open Science\nMany countries in Asia, Africa and Latin America face many challenges, including lack of funding, inadequate access to literature and poor infrastructure. Across these regions, young scientists are working to build practices for open science from bottom-up. The aim is that scientific communities will incorporate these principles as they grow but these communities’ needs differ from those that are part of mature research systems.\nThe reasons for falling behind are lack of funding, poor infrastructure, inadequate access to research resources. There are government policies, which want greater productivity at the expense of quality. The open science collaborations can bridge the gap for developing countries by providing new ways and provide researchers access that might be currently out of reach (Onie, S. 2020).\n\nEquitable terminology: what words should we use?\nWhen talking about equity from a global perspective, it can be very hard to choose appropriate language, and historically many phrases have come and gone as we learn more equitable ways to communicate. Common phrases you may see include “Higher Income Country” and “Lower or Middle Income Country”. These are terms defined by the World Bank. Some people prefer to use “Global North” when referring to more privileged / high income countries, and “Global South” for lower income / more exploited and marginalized countries - but some “Global South” countries are in the northern hemisphere, and vice versa! Other times, people use “minority” and “majority”, but again sometimes the phrase “minority” might be used for a populace that is not actually a minority! An older phrase is “first world country” or “third world country”. Many of these terms also have accidental or intentional negative connotations. For this module, we aim to use the phrases “marginalized” and “privileged” when referring to the inequitable distributions of resources and power amongst humanity.\nThe Global North have ascendency over authorship and synergies in research networks, which margins out the Global South (Cash-Gibson L et al 2018).\nIn richer regions, a compulsion for the goal of excellence nurtures cumulative benefit in funding allocation for the highest funded institutions (Noble P et al) Across many countries, very few women have higher positions, senior positions are given at a later age, given less grant funding and few have high-impact publications (Gesiarz F et al 2020) (Brown JVE et al 2020 ) These are the impartialities, which are the societal imbalances (Zuckerman H. (1988). The above stated societal imbalances, which Open Science is focused to minimize in order to elevate the underrepresented societies, groups and create avenues for Global South countries to come forward & contribute to the global science community.\nPrainsack & Lionello (2018) stated that open science is a political assignment greater than its technological part. The Open Science policy in Europe is shifting across nations, institutions & funding organizations. (Sveinsdottir T et al 2020). The emphasis on policies drive the incentive/reward structures and resource allocation and later helps in establishing strategies. Open Science started as a bottom-up approach by the researchers but has gone to the top-end level making it to the national and institutional policies setting wider goals like economic growth. The European Commission favors Open Science but in 2016 EU publication, the concern of Open Science perceived potential is being given that greater importance for fostering Europe’s competitive advantage in global markets (link to EU publication, 2016) Open Science positions to cover literature in languages other than English, supporting the value of 📖bibliodiversity📖. We see a diverse set of communities in organizations working for Open Science data, software, tools, resources together as multilingual teams’ covering different languages of the world. Research indicates that there is a demand for regionally focused titles, in regional languages (Snijder 2022).."
  },
  {
    "objectID": "ethos-of-open/lesson4-impact-of-open.html#a-global-perspective-on-open-science",
    "href": "ethos-of-open/lesson4-impact-of-open.html#a-global-perspective-on-open-science",
    "title": "Impact of Open Science on academia, communities and society as a whole: Where open science happens.",
    "section": "A global perspective on open science",
    "text": "A global perspective on open science\n\nUNESCO on Open Science Infrastructure\nUNESCO’s recommendation on Open Science states the potential of open science is in minimizing the present inequalities in Science, Technology and Innovation and pace towards SDGs 2030 implementation agenda, specifically in Africa, least developed countries, small island developing states and landlocked developing countries.\nOpen Science infrastructures are shared infrastructures (referred as virtual/physical, knowledge-based resources such as journals, collections, and open access publication platforms, archives, repositories, scientific data, present research informations systems, sets of instruments, open bibliometrics, scientometrics systems for assessing & analyzing scientific areas, open computational & data manipulation service infrastructures, multidisciplinary data analysis & digital infrastructures) where open science happens and serves the needs of diverse communities. Please see UNESCO Recommendation on Open Science\nUNESCO on Open Science policies clearly recommends monitoring Open Science through combining qualitative and quantitative methods to assess the efficacy and efficiency of Open Science as per the member states’ particular conditions, constitutional structures and constitutional provisions. Also, gathering & communicating progress, good practice, research work & innovation in open science and its outcomes with support of UNESCO and diverse stakeholders approach.\n\n\nOrganisation for Economic Co-operation and Development (OECD) and Open Science\nThe OECD’s recommendation regarding research data from public funding helped gain collaboration and global sharing of data as a policy priority, with the objective of making the global science system more effective and seamless. There has been progression in a number of OECD member states and partner economics, with 58 countries successfully delineating their policies for open data & research publications. - For IT infrastructure, academic institutions and data repositories, international networks have been established in the form of repository networks such as OpenAIRE. - “Science clouds” - national and international computational resources - are being initiated such as European Open Science Cloud, the Australian cloud NECTAR, the National Research Data Infrastructure in Germany, the National Institute of Health Data Commons in the USA & Research Center for Open Science and Data Platform in Japan."
  },
  {
    "objectID": "ethos-of-open/lesson4-impact-of-open.html#questionsreflection",
    "href": "ethos-of-open/lesson4-impact-of-open.html#questionsreflection",
    "title": "Impact of Open Science on academia, communities and society as a whole: Where open science happens.",
    "section": "Questions/Reflection:",
    "text": "Questions/Reflection:\n\nWhat strengths do marginalized communities bring to open science? What challenges may they face compared to privileged communities?\nName at least one data privacy law, and describe ways you can keep personal data safe. Do all countries have data privacy laws?\nBonus: You’re working on an open science consortium that gathers data in the Netherlands, Kenya, and India. You plan to use servers in the EU to store your data. What concerns should you take into account?"
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#plan-for-open-science-into-the-design",
    "href": "ethos-of-open/lesson5-how.html#plan-for-open-science-into-the-design",
    "title": "Not an afterthought",
    "section": "Plan for open science into the design",
    "text": "Plan for open science into the design\nPracticing responsible Open Science requires organizing your work and research, and your team, if you have one, around open science and planning for it from the inception, even designing the project with open science in mind. There are many resources and tools that make these easy, and indeed doing so will improve efficiency and the value and impact of your work, and help you focus on your research itself. We’ll provide a brief overview in this lesson, but you may wish to explore the later modules in this course too, which cover 🔗 Open Data, Open Results, Open Tools, and Open Software 🔗. Additional resources, and knowledge, may be available at your institution, including in your department or library or among your colleagues. An additional resource is a recent report from the U.S. National Academies “Open Science by Design.”\nIt is important to discuss responsible Open Science with your research team, lab, group or partners regularly. Much of responsible Open Science may seem to be related to outputs – such as data, software, and publications – but preparing and organizing work for these in advance is critical. It would be hard or impossible to follow leading practices for these at the end of research, in the “afterthought” mode. Responsible Open Science is both a mindset and culture.\nPlanning for outputs in advance includes: speaking about it and organizing with your research team; deciding which tools to use; thinking about authorship and credit; engaging with relevant stakeholders and research partners, for example, industry, around open science; identifying repositories for software and data; highlighting these approaches in your grant; and much more."
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#perks-of-digital-and-internet-age-for-responsible-open-science",
    "href": "ethos-of-open/lesson5-how.html#perks-of-digital-and-internet-age-for-responsible-open-science",
    "title": "Not an afterthought",
    "section": "Perks of digital and internet age for responsible Open Science:",
    "text": "Perks of digital and internet age for responsible Open Science:\nThe internet has made it very easy to share digital work. The popularization of Open Source computer code and the rise of Open Science has resulted in many outlets for public and free hosting of research and data.One key to open science, and why it is so empowering for 21st century science, is that we can now connect all the participants, stakeholders, and outputs of a research result together so that they are easy to discover.\nHere we present a non-exhaustive list of digital platforms and tools used with for open science:\n\nDigital Persistent identifiers - for objects and researchers (such as doi and ORCID)\n\nOpen Journal System: open source software for managing & publishing scholarly journals\n\nElectronic notebooks such as Jupyter and R Markdown\n\nData repositories: genetic sequence database Genbank, protein data bank (PDB), Dataverse, figshare, Zenodo and for wide search use https://www.re3data.org/ and/or https://datacite.org/\n\nSoftwares/Codes: Zenodo used with Github / mybinder\n\nMaterials: Addgene (for molecular biology)\n\nReference management tools: Zotero, Mendeley\n\nAcademic Social networks: Academia.edu, ResearchGate\n\nPeer Review: Publons, PreView\n\nProject management: Open Science framework\nGithub as a platform for collaborative work on training materials etc\n\nA variety of tools are emerging to help manage open science workflows, and to support global collaboration. These include spaces for project management, such as the Open Science Framework from Center for Open Science, electronic notebooks which help projects organize data, software, and content together; online platforms for creating manuscripts, etc. More information about the open science collaboration and management tools are described in the 🔗Open Tools module🔗.\nNow let’s move to the tools and procedures to ensure credit and attribution for our work, and allow its use and reuse in new, powerful ways, using the internet."
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#digital-persistent-identifiers---for-objects-and-researchers",
    "href": "ethos-of-open/lesson5-how.html#digital-persistent-identifiers---for-objects-and-researchers",
    "title": "Not an afterthought",
    "section": "Digital persistent identifiers - for objects and researchers",
    "text": "Digital persistent identifiers - for objects and researchers\nA key to the 📖interoperability📖 is that each piece is assigned a “📖persistent identifier📖” and “📖metadata📖” that provides a secure path and basic information about it in such a way that they can be linked automatically (machine-readable).\nHow many times have you gone to an old link, only to find the page is no longer there? A persistent identifier is powerful because it is designed to point to the Web resource even if, or when, the URL or domain changes. One very common type of persistent identifier is a “📖digital object identifier” (DOI)📖 that is usually assigned to a digital object (e.g. document) by publishers, preprint servers, data and software repositories. This has allowed automated linking of references across publications, including to citations after a publication."
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#case-scenarios",
    "href": "ethos-of-open/lesson5-how.html#case-scenarios",
    "title": "Not an afterthought",
    "section": "Case scenarios:",
    "text": "Case scenarios:\n\nA researcher writes a script in R that they use to analyze their results and produce a bar chart. They can upload their R code to a repository, and get a DOI for their script, so others can peer-review the code if they wish.\nA member of the public attends a conference online and shares a digital poster and a short talk about their work as a citizen scientist. They deposit their poster and talk slides on to Zenodo, and can share the slides and poster using the DOI URL and receive credit for it.\nA consortium member collaboratively authors a paper summarizing the results of a workshop they attended, alongside other workshop attendees. The journal they publish in automatically assigns a DOI to the paper.\n\n\nORCID: A permanent unique identifier for you, as a scientific author\nResearchers and authors also have a digital identifier in this system: The Open Researcher and Contributor Identifier or ORCID. Thus a first step to enabling responsible Open Science is to sign up for your identifier at [ORCID.org](https://ORCID.org. This identifier will be included in your research outputs and work so that they can be linked uniquely to you (this can also happen automatically). You control your information on ORCID and what is public or private. Your ORCID can also be a way to get credit and recognition for reviews, awards, and more. Many funding agencies now integrate fully with ORCID, for example, for preparing grants and reference lists.\nOther identifiers that are regularly used include those for funding agencies–which along with the grant ID provide a connecting link back to their repositories, institutions, 📖samples📖, open reviews, and even 📖annotations on web pages📖. Identifiers for 📖research instruments📖, 📖reagents📖, and materials are under development and implementation too.\nIn most cases, the identifiers will not be managed or assigned by you. Publishers and data repositories may ask you and your co-authors to link your ORCID and provide a grant ID (if you have one!) but they will then automatically provide the digital linking and create the 📖metadata📖 record. Often, you can sign on to repositories using your ORCID, so that this is automatically linked to any work you upload.\nHaving basic metadata - remember, metadata is documentation about your data - for each object with a persistent identifier helps 📖discoverability📖. For publications and datasets, an identifier usually includes the title, authors (with their own identifiers), grants (with identifiers), journal (with its identifier as well, the ISSN), and publication date among other information. This allows search engines to discover and index the content. For data sets, leading repositories will also help ensure that information on standards, uncertainty, and calibration are included to allow appropriate reuse.\nCollectively, this system allows widespread discovery and connection of the various pieces of research–even connecting open preprints and conference presentations to later versions and publications to data sets that underlie and support them."
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#sharing-data-and-software-and-getting-cited-repositories-you-can-use",
    "href": "ethos-of-open/lesson5-how.html#sharing-data-and-software-and-getting-cited-repositories-you-can-use",
    "title": "Not an afterthought",
    "section": "Sharing data, and software, and getting cited: Repositories you can use",
    "text": "Sharing data, and software, and getting cited: Repositories you can use\nA key part of responsible Open Science, which is enabled by this system, is that research outputs – data sets, software, publications, conference reports, etc. – should go to the respective places that best manage, curate, and host that type of output. Previously, a data set may have been included as a supplement to a paper, usually a PDF file at a publisher’s site, or not included at all (“data not shown” or “data available upon request” statements were common even a few years ago but are thankfully waning).\nPublishing a data set separately from your paper, at a repository that handles that type of data well (ideally a popular “📖domain repository📖”), allows others to cite your data separately, with its own metadata and authorship and expert curation of that data. Some also allow data that have appropriate restrictions on access (such as personal medical data) to be hosted in a secure way. This allows separate credit and authorship (if appropriate) for data or software products. A publication or research project may, and often will, have multiple data sets across several leading repositories.\nIn general, domain repositories are preferred over a general repository for data, because of the 📖expert curation📖 and better metadata they can provide, but not all disciplines or types of data have appropriate repositories. In this case general repositories can be used. In some cases, you may create and deposit data in a repository throughout a project; in other cases the natural time to “publish” the data is when a paper is submitted to a journal.\nSee the 🔗Open data module🔗 for more information on sharing your data appropriately.\nOpen software is usually developed in a collaborative workspace such as GitHub. Github works with a general repository, Zenodo, to enable software versions to be assigned an identifier and metadata.\nSharing data, codes and software is a key for ensuring reproducibility of findings, improvement of code and software, for enabling other researchers to easily re-use , extend and cite that work (Gorgolewski & Poldrack, 2016). Sharing the data & materials is also a signal of valuing transparency and trust in their own research, boosts authors’ visibility and recognition (McKiernan et al., 2016).\nSee the 🔗Open source module🔗 for more information on sharing your code and software appropriately.\nCollectively, this set of identifiers, metadata, and infrastructure helps enable content and especially research data to be “findable, accessible, interoperable, and reusable” or FAIR. This is a key concept and part of responsible Open Science. For researchers it means directing research outputs to their best open science home and planning for this throughout the research process. For all these reasons, it is best to think about how to share data and software supporting a publication before submission. More about FAIR principles can be found in the 🔗Open Data module🔗, and now we will consider some foundational principles on licensing the content for reuse.\nAs a general rule, when you create something - a blog post, a scientific paper, a drawing, a data set, computer code, or any other ‘creative’ work - you automatically own the copyright for that work yourself. This means that others aren’t allowed to re-use it without your permission, even if it’s freely available on the internet. As an open scientist, you can use a 📖license📖 to grant others permission to re-use your work, and even specify conditions - perhaps you always want others to credit your work, or perhaps you don’t want your work to be used commercially.\n⚠️Caution: When you perform work for someone else, as an employee, contractor, volunteer, or a student, your contract may stipulate that the copyright for that work belongs to the institute you are working for. Before assigning a license to your work, check that you have the right to do so. Your employer, institution’s intellectual property office, and your funder may all have specific expectations around how you share your work and what license you use.\nDistributing content to the best open science home also allows each output to have the right license that allows access and reuse. Usually you would include the type of license in the metadata. When you publish a preprint or publication, or deposit a dataset, or software version at a repository, you will usually be asked about the correct license to assign to that content. Usually a repository will recommend or require a specific license to enable broad reuse. The basic standard is that leading licenses support reuse generally with attribution (citation) so that the creators of the content are recognized. Citations are supported by leading publishers.\nHere we list a general guide on the best licenses for published content, data, and software:\n\nWritten content of any kind, papers, posters, slides, images, audio files, videos, other creative works\nCreative Commons licenses are designed to allow re-use of these types of content. Authors can choose to require credit for their work (CC-BY attribution), allow or disallow commercial use and/or derivative works, and to require reciprocal sharing of works. 🔗Open Results Module for more information🔗\n\n\nData\nIncluding spreadsheets/csv/text files with experiment results, videos/audio files/images created from a study, databases of computationally processed data.\nCreative Commons Public Domain (CC0) licenses are often best for data. Whilst you may be tempted to use a creative commons attribution license (CC-BY), this can make it difficult for people who wish to reuse or integrate different data sources in the future. Visit the 🔗Open Data Module for more information🔗.\n\n\nComputer code, such as scripts written in R, Python, Matlab, SPSS\nThe Open Source Initiative has a set of licenses designed specifically for code projects, that covers both open distribution of the code itself, as well as executable versions of the program that non-programmers can run. Visit the 🔗Open Source Module for more information🔗\nOther items: Whilst this is beyond the scope of the module, this list is not exhaustive. Other types of work may require different license types. For example, what license would you use for an open hardware drone design, a 3d-printed microscope kit, or a reagent used in a laboratory? These items may have different constraints and needs.\n⚠️Caution: As a general rule, if an item does not include a license for reuse, it’s illegal to reuse even if you can see the work online. Licenses are designed to take into account the legal ins-and-outs that each type of work can encounter. Try not to use one license type for a different output - Creative Commons specifically advises not to use their licenses for computer code, for example."
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#making-your-work-useful-to-others",
    "href": "ethos-of-open/lesson5-how.html#making-your-work-useful-to-others",
    "title": "Not an afterthought",
    "section": "Making your work useful to others:",
    "text": "Making your work useful to others:\n\nSharing and publishing your manuscript:\n\nPublic repository/Preprints\nSharing drafts of research as preprints can improve citations and help establish or provide credit and a reference months before formal publication in the journals (McKiernan et al 2016) A manuscript posted by author(s) to a repository for facilitating open sharing of early work without any limitations to access is 📖Preprint📖 (Puebla et al 2022). Basic screening is carried out to the manuscript, which is usually posted on the preprint server within a few days of submission without peer review and is freely accessible online. More than 1200 journals now allow posting of preprints, and some connect directly to deposit submitted manuscripts directly (see directory here: https://v2.sherpa.ac.uk/romeo/) or allow transfer from the server to the journal. Many funding agencies now allow citations of preprints in grants. Many preprint repositories are field-specific; see a directory here: https://asapbio.org/preprint-servers. Many also will link to the published version of the manuscript once it is available.\nIn addition, many institutions have open sharing repositories, and mandates to share author-versions of published manuscripts. Many funders also have repositories for sharing manuscripts after publication or a means to connect to manuscripts on publisher platforms. Check with your institution or funder, and journal publisher for requirements.\nSome preprint repositories also accept conference presentations (e.g. posters and slide decks for talks).\n\n\nPublishing Open Science and Open Access\nWhen you publish your work in peer-reviewed journals, traditional publishing models may result in papers that are not openly available for anyone to access, and instead may require a subscription fee. Publishing in subscription journals is usually without cost, but where possible we recommend using “Open Access” publications. There are many routes to open access publishing, discussed further in the tools module, often with different trade-offs - for example, if a scientist has to pay to publish in an open access journal, fewer scientists can afford to share their work!\n\n\n\nDiscipline- and sector-specific nuances\nThe above information applies across nearly all scholarly disciplines. There are some discipline or research specific responsible Open Science steps that also apply or for which you should think and learn about:\nFor some fields of research, 📖pre-registration of hypotheses📖–as a publication–is strongly encouraged and it helps avoid bias and supports the publication of negative results. These are becoming common in behavioral and social sciences and clinical trials. We explored this previously in lesson 2.\nIf your research involves partnering with industry where some outcomes may be restricted from publication, it is best to discuss and reach agreement in advance on responsible Open Science outputs to avoid complications or misunderstanding at the time of publication. If you have one, consult your institutional legal, knowledge transfer or intellectual support office resources should be consulted to be clear that publication of relevant data and software are acknowledged and supported and that data can be placed in appropriate repositories.\n\nWorking with physical samples and tools:\nSome disciplines also require or encourage sharing of physical materials such as reagents, cell lines, animal models, and materials and have repositories for these, which will also provide appropriate licenses.\nIf you are collecting or analyzing physical or biological samples, a permanent identifier system has been developed to help you manage your work, support open science, and enable standard methods for identifying, citing, and locating physical samples and comparing analyses from different labs–the IGSN or International Generic Sample Number. Identifiers can be reserved in advance (before collecting). Additional information is in the Data module\nSome disciplines in paleontology and anthropology also require and expect open archiving of precious samples in public museums and/or other means to provide open access (digital casts).\nIf your research involves field work and sample collection, appropriate permits should be obtained including engagement with local authorities and stakeholders–including them openly in your research has many benefits, as we discussed in Lesson 3.\nWork on human data and samples, and other sensitive areas often requires initial external ethical review, e.g. in the US by an Institutional Review Board (IRB).\n\n\n\nAuthorship: recognizing the contributions and giving credit\nWorking in collaboration and with the teams of researchers oftentimes led to sour disputes on the order of the authors at the stage of the final publication. It is important to remember that practicing open science responsibly implies giving the credit to the contributors in an equitable, fair and ethical way. Here, open science calls upon the knowledge and practices of research integrity and ethics. Separate, unique citations for a variety of outputs (such as data sets, software), expanded and refined contributors roles, such as CRediT taxonomy, are crucial in recognition and giving the credit. Importantly, all involved stakeholders such as publishers, funders, regulatory bodies, and research institutions need to consider recognizing diverse contributions and especially open data in their evaluation systems.\nFor in-depth, check the COPE’s materials on authorship and contributorship."
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#summary-think-beforehand-design-for-open-science-never-as-an-afterthought.",
    "href": "ethos-of-open/lesson5-how.html#summary-think-beforehand-design-for-open-science-never-as-an-afterthought.",
    "title": "Not an afterthought",
    "section": "Summary: think beforehand, design for open science, never as an afterthought.",
    "text": "Summary: think beforehand, design for open science, never as an afterthought.\nIt is important to think about, discuss, and plan for desired outcomes and processes when you begin your research. Learn about where the best repositories are for your data; discuss credit and authorship for each separate open science output, and start using open science tools to organize your work. Reach out to repositories in your discipline and institution (usually library) for help. Indeed this information in your grants and data management plans will make you more likely to receive funding."
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#bonus-section-open-science-skills",
    "href": "ethos-of-open/lesson5-how.html#bonus-section-open-science-skills",
    "title": "Not an afterthought",
    "section": "Bonus section: Open Science Skills",
    "text": "Bonus section: Open Science Skills\nOpen science can foster a range of skills, across many domains - the figure below touches on some of the topics you may have learned about so far.\nYou may have expected to see technical/data science skills, digital content creation, research management, library and information, and publication literacy. Research integrity and ethics are often less straightforward sets of skills, in which researchers may not be trained or aware of.\nEach step of responsible Open Science involves considering and thinking about other people - collaborators, contributors, users and consumers of the research outputs. Therefore, communication and interpersonal skills, especially applied to virtual environments, are key.\nIn this module, we emphasized ethos and ethics of open science, inclusion and accessibility in participation of open science stakeholders, equity (or lack of it) in conducting and sharing science openly. responsible Open Science researchers of the 21st century need to develop their reflective practice, just like practitioners, to enable them to become aware of their own stance towards science or assumptions regarding other stakeholders, aware of the values and worldviews, and provide means to adapt the responsible Open Science practice. (Roedema et al 2022)\n\n\n\nOpen science skills diagram - visit source below to see in detail\n\n\nSource of the visual"
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#summary-of-the-module",
    "href": "ethos-of-open/lesson5-how.html#summary-of-the-module",
    "title": "Not an afterthought",
    "section": "Summary of the module",
    "text": "Summary of the module\nThis module provided a broad overview of the ethos of responsible Open Science, the imperative for scientific and societal challenges and opportunities in the 21st century, and an introduction to how you and your research team can begin to follow leading practices to enable open science. Part of the ethos is to help enable these practices within your team and with your colleagues–that is, you are encouraged and empowered to share what you have learned and help them learn about, be aware of, and practice Responsible Open Source.\nIn a larger context, many of you will be participating in scholarly efforts, including in peer review, in leadership positions as journals and societies, in organizing meeting sessions, and more. Enabling responsible Open Science is a broader cultural shift in scholarly practices worldwide. In many ways, the recognition, reward and award systems in science are not fully aligned yet with responsible Open Science as this cultural shift is ongoing. You are encouraged to leverage this learning in having conversations to develop this culture broadly.\nHere are the six key guidelines to start practicing and supporting open science responsibly:\n\nPlan for responsible Open Science from the beginning and begin discussions in your group, with colleagues, and your librarian.\nPlan for making data and code open and available in leading repositories and citing it in publications in the reference section. Cite others’ data and software that you make use of.\nLearn about and adopt open science tools\nDevelop and foster inclusive workgroups, meeting sessions, and meetings.\nLearn the routes to make your publications open and what your institution supports and funders require; preprints provide an easy and robust route\nSupport and inform your colleagues."
  },
  {
    "objectID": "ethos-of-open/lesson5-how.html#questionsreflection",
    "href": "ethos-of-open/lesson5-how.html#questionsreflection",
    "title": "Not an afterthought",
    "section": "Questions/Reflection:",
    "text": "Questions/Reflection:\n\nHow can a researcher publish in an open access journal ?\nPredatory journals are very harmful and some early career researchers may not be even familiar with these journals. Describe why they should be not included in responsible Open Science. Also discuss what are the possible ways to restrict and control these journals?\nWhy are licenses an integral part of Open Science practice ?\nCan you briefly describe the differences between licence types? When conflicts arise among co-authors about which types of licenses they should choose, how do you discuss and resolve the issue using your knowledge learned from this lesson?\nWhat are two types of permanent identifiers, and why are they useful?"
  },
  {
    "objectID": "open-software/lesson1-introduction.html#introduction",
    "href": "open-software/lesson1-introduction.html#introduction",
    "title": "Open software in the context of Open Science",
    "section": "Introduction",
    "text": "Introduction\nThe software that is created through/during research can be an important research product in and of itself. Open science principles like reproducibility, reusability, and replicability are especially important when it comes to research software. Within this module we will use the terms software and code interchangeably. We use these terms refer to any product written in a programming language, and can cover anything from a short script to a full software package with a full graphical interface."
  },
  {
    "objectID": "open-software/lesson1-introduction.html#open-science-principles-how-they-relate-to-softwarecode",
    "href": "open-software/lesson1-introduction.html#open-science-principles-how-they-relate-to-softwarecode",
    "title": "Open software in the context of Open Science",
    "section": "Open Science Principles: How they relate to software/code",
    "text": "Open Science Principles: How they relate to software/code\nReproducing findings of a published study is imperative for the scientific community. Therefore, results that are produced by a scientific software should be reproducible, i.e., users should be able to obtain > “consistent results using the same input data; computational steps, methods, and code; and conditions of analysis” 1.\nIf software/code used to make a figure or generate results is not shared along with the results/figures themselves, then it would take significant time, effort, and likely funding, for another researcher to reproduce those same results and determine they were correct.\nWe all aim to make significant contributions to our field and can do this by “standing on the shoulders of giants” (Isaac Newton). By sharing the code, trust in the work can increase, and future work can build on it without duplicating effort. Therefore, it is important for a research software to be developed in such a way that it can be understood, modified, built upon, or incorporated into other software. This is called reusability. 2\nAnother important aspect of scientific studies is replicability, i.e., studies answering the same scientific questions - but using independent data and/or methods - should find consistent results 3 4.\n\nMany communities already have a strong replication tradition, where trust in any scientific result is built when multiple codes achieve results that demonstrate consistent behaviors. By requiring multiple codes to achieve the same scientific finding, replication reduces the impact of individual code errors or numerical issues. 5\n\n\nOpen Software and Open as a Spectrum\nAs we’ve said, sharing code can increase trust and lead to better science by allowing a more thorough review process. However, the degree to which a code is shared and when that code is shared can vary. Any sharing is a step on the spectrum of what we will refer to as open software, the most open of these equates to what is known in the computer science and software development industry as open source software. Open software can be a spectrum that can be anything from sharing an executable of a code with a description of how it was used to developing the software in a public repository from the start of the project. There are also a variety of license choices that can be made under the umbrella of open software which can allow the developer/researcher to retain various levels of ownership and rights to future commercialization.\nNow, let’s take a step back and give formal definitions for some of the terms that we just used.\n\nSource Code\n\nSource code is a human-readable (vs. machine-readable) text written in a specific programming language. The goal of the source code is to set exact rules and specifications for the computer that can be translated into the machine’s language. 6\n\nOpen Source Software (OSS)\n\nAn Open Source Software is distributed with its source code without additional cost that makes it available for use, modification, and distribution with its original rights and permissions. 7\n\n\nWe should note that researchers are not always able to share their complete code, or software package (e.g., due to national security concerns, data privacy, institutional policies). Again, open software doesn’t necessarily mean open-source software and sharing to the level that is allowed by funding agencies, institutions, and security requirements is still a step in the right direction towards a world with more open science.\nFrom Openscapes:\n\nOpen is a spectrum – what you share, who you share it with, or how you share it. It’s not all-or-nothing. What: slides, tweets, blogs, forums, wikis… then also code, data, protocols Who: your self, research group, project team, institution…then also public How: internal servers, Dropbox … then also Google Drive, GitHub, data repos\n\nWe might also add here:\nWhen: at the start of your project, when it reaches its first fully usable version, at the end during publication, etc.\nBefore jumping into the next lessons, let’s have a brief overview of the core principals of open source software in general and, more importantly, in the context of research software."
  },
  {
    "objectID": "open-software/lesson1-introduction.html#core-principals-of-open-source-software-what-research-software-can-move-towards",
    "href": "open-software/lesson1-introduction.html#core-principals-of-open-source-software-what-research-software-can-move-towards",
    "title": "Open software in the context of Open Science",
    "section": "Core Principals of Open Source Software: What research software can move towards",
    "text": "Core Principals of Open Source Software: What research software can move towards\nIn the previous section, we provided a formal definition for open software and open source software. For better understanding, let’s define what these concepts are juxtaposed against: Closed Source Software\n\nClosed Source Software (CSS)\n\nClosed source software is a proprietary software that its source code is not distributed to the public. Therefore, only the original authors who created the code exclusively have rights to legally copy, modify, update, and edit the source code. Closed software imposes restrictions on what the end user can do with the application, preventing users from modifying, sharing, copying, or republishing the source code. 8\n\n\nThe major differences between CSS and OSS products are two-fold: End-users cannot modify CSS products and although, OSS products might have some restrictions on redistribution, CSS products usually are more restrictive on their terms of usage and redistribution. We can think of OSS as a form of thinking based on intellectual freedom that follows three core principles: transparency, participation, and collaboration. 9\n\nTransparency\n\nOperating in such a way that it is easy for others to see what actions are performed and implies openness, communication, and accountability. 10\n\nParticipation\n\nActively giving back and contributing to OSS through either committing time and lending skills, or monetary sponsorship. 11\n\nCollaboration\n\nCollective engagement toward making improvements and advancements through knowledge sharing and creating an inclusive environment. 12\n\n\nThe exchange of ideas and software developed by communities has driven creative, scientific, and technological advancement in nearly every aspect of our lives. Developers share insights, ideas, and code to create innovative software solutions both collectively and individually. Open source software operates with the underlying principles of peer production and mass collaboration, creating more sustainable software development for end users. 13\nNot only users can make any kind of changes to the source code, but they can repurpose it into other new software and distribute their own software. However, there are some nuances on redistribution that we will cover in Lesson 3.\nOpen source software is also sometimes conflated with the free software movement. Usually, “free software” is meant to emphasize freedom in the rights of end-users, but can sometimes be confused as meaning “free of cost”. In actuality, neither free software nor open source software denote anything about cost—both kinds of software can be legally sold or given away. Free software and open source software share common values, and the terms are sometimes combined in the popular phrase “free and open source software” (FOSS). 14\nTo support adapting OSS principals (transparency, participation, and collaboration), several new concepts have been introduced by the open source community. These are especially useful in the move to open science and has produced tools and methodologies that can be used to make research software more open:\n\nTo facilitate sharing and community engagement a central file location storage is needed for source codes which is called a Code Repository. Some examples of such repositories are GitHub, GitLab, and Bitbucket. Although, source code sharing and community engagement are their most basic capabilities, they go much beyond that and provide a wide range of tools for code testing and version control. Code testing in general refers to the process of evaluating and verifying that a software product does what it is supposed to do. The benefits of testing include preventing bugs, reducing development costs, and improving performance 15. There are various types of tests with different objectives that will be covered in more details in Lesson 5. Version control is the practice of tracking and managing changes to source code over time. It keeps track of every modification to the code in a special kind of database. If a mistake is made, developers can turn back the clock and compare earlier versions of the code to help fix the mistake while minimizing disruption to all team members Lesson 5. 16\nIn addition to sharing the source code, software executables require a storage location to facilitate software packaging (for developers) and installation process (for end-users). These types of storage locations are called Software Repositories. These repositories are usually programming language dependent, for example, PyPi and Conda for Python-based software, CRAN for R-based software, and Julia Packages for Julia-based software. However, software packaging cannot always be done using automated services such as PyPi due to complexities of the source code structure itself (e.g., intricacies of the software objectives, use of several programming languages, etc.) and/or its dependencies (other software packages that it depends on). In these situations, containerization is a viable option. Docker and Apptainer are example services for containerization."
  },
  {
    "objectID": "open-software/lesson1-introduction.html#summary",
    "href": "open-software/lesson1-introduction.html#summary",
    "title": "Open software in the context of Open Science",
    "section": "Summary",
    "text": "Summary\nHere we introduced the concept of open software, how it relates to the broader open science principles, and how sharing and openness can be a spectrum. At the most open end of this spectrum is what the computer science/software development community refers to as open source software. The core principles of open source software are introduced as a paradigm towards which research software can move towards. The tools and methodologies developed by the open source community are particularly helpful in opening research software. Next, we’ll dive into the benefits and hurdles associated with having open software."
  },
  {
    "objectID": "open-software/lesson2-pros-cons.html#introduction",
    "href": "open-software/lesson2-pros-cons.html#introduction",
    "title": "The Pros and Cons of Open Software",
    "section": "Introduction",
    "text": "Introduction\nThis lesson addresses particular benefits of open-software, presenting how you as a researcher can benefit from it, and also how can it improve your research, moving yourself and your teams towards Open Science. We will also address some common challenges - and misconceptions - of adopting open software, and how to overcome them."
  },
  {
    "objectID": "open-software/lesson2-pros-cons.html#benefits-of-open-software",
    "href": "open-software/lesson2-pros-cons.html#benefits-of-open-software",
    "title": "The Pros and Cons of Open Software",
    "section": "Benefits of open software",
    "text": "Benefits of open software\nOpen software offers a multitude of advantages to both developers and users. There are several benefits of open software are highlighted in this section.\n\nAs a developer/provider\n\nHigh Visibility: Publishing open software enables the repository to be more reachable and attainable. It can broaden the audience from a diverse group and draw more attention to the software repository.\nLong-term Sustainability: Subsequently, open software allows more people to access the repository and can cultivate more users to be involved in its development. It results in the long-term sustainability of the software. 1 Since it is unlikely to have perfect software, having a larger user base is likely to have more collaboration or feature requests that can directly contribute to some improvements in the software. “Given enough eyeballs, all bugs are shallow.” 2 Testing out software with a large base of users can easily detect the issues in the software, and they can submit bug reports or submit proposed fixes directly.\nQuality Improvement: Besides bug fixes, the contributions can also be in feature enhancement, such as submitting additional features to the software repository or proposing modified codes that increase the effectiveness of the software. As a result, open software that comes with community support will tend to have continuous improvement, unlocking the potential to create new inventions, and produce better quality software versions. By ensuring the quality of the open software, it can gain users’ trust to rely on it rather than redeveloping a software, therefore, minimizes the duplication of efforts, both within an organization and across organizations, by allowing for individual components to be shared.\nFuture Employability: As a developer or maintainer of open source software, your skills and experience are an important asset to improve your chances of getting a job. 3 Experience in developing open software is a positive portrayal of the abilities as it helps in demonstrating technical abilities. In addition, it also demonstrates the personality and work ethic in software development. If someone has experience working on complex software development and maintenance, it can make the profile outstanding, especially to companies that will take into account the contributions of the candidate to open software. The hiring manager may also view the product or shared code. Hence, open source provides visibility into both how a candidate solves problems, and how they collaborate in a team.\n\n\n\n\nAs a user 4\n\nAccessibility: Shared code certainly increases the democratization of science, it promotes more diverse and inclusive community to use the open software without a cost-prohibitive barrier.\nFlexibility: Open software provides users a certain freedom to utilize the software for any purposes as they wish. It also allows users to make changes freely on the software and customize it according to their needs or even redistribute the software based on the license that has been applied.\nKnowledge Sharing: Open software is also a great learning opportunity for the community 5, it can help to achieve knowledge sharing through the community, which in turn, increases motivation for a continued practice."
  },
  {
    "objectID": "open-software/lesson2-pros-cons.html#are-there-any-disadvantages-of-open-software---and-if-so-how-to-mitigate-them",
    "href": "open-software/lesson2-pros-cons.html#are-there-any-disadvantages-of-open-software---and-if-so-how-to-mitigate-them",
    "title": "The Pros and Cons of Open Software",
    "section": "Are there any disadvantages of open software - and if so, how to mitigate them?",
    "text": "Are there any disadvantages of open software - and if so, how to mitigate them?\nMaking a software open source and valuable to the community requires additional efforts and considerations. In this section, we will discuss responsibilities that come with this decision and provide you with guidance for maximizing the impacts of your efforts.\n\nAs a user\n\nRequire a skill set\nOpen software comes in many forms and shapes. There are open-source codes that come as packages available in a repository for a programming language or environment (e.g. PyPi for Python, CRAN for R, Conda for a variety of languages). Others are code that require installation from scratch. Even for skilled programmers, this setup can incur in costs (time and financial).\nSo, if you are familiar with a programming language that offer repositories which are easy to download from within your environment (e.g., R), you can start from there, and build up your confidence and skills.\nTo compile and generate an executable code from a repository from scratch, you will need to be able to check for the necessary computation environment, check and install dependencies, and compile the code. Programming language might be a barrier, as well as operating within a command line environment. The good news is that there are many resources to help you go through these stages. Widely used open software are usually well documented, with step-by-step instructions, and some even have a community which can offer support for installation and running their code. Sometimes, developers share alongside their open-source code an executable version for your operating system. E.g., the repository of Stock Synthesis6, a software used for stock assessment of fisheries populations, offers both the source code and compiled versions for different operational systems. So these are good choices for a beginner.\nBear repeating that while learning these skills incur a cost, by doing so you might not only gain access to a useful research tool, but might also gain experience and skills that are useful for your career.\n\n\nDepreciation\nTechnology changes fast, and software - open and closed - becomes depreciated. If you rely on a certain open-source tool for your work, you run the risk of it becoming depreciated. It can happen to projects that are not maintained, or no longer maintained, for a number of reasons.\nIf this happens to you code you use, you can offer the developer to be a contributor to their open-software and update the code yourself. This will require programming skills, but it is a viable route. You can also team up with other users for a group effort.\nIf you are choosing a tool and are not interested to fix depreciation issues in the future, aim for widely-used community open software, which are maintained by numerous people and thus, less likely to be depreciated.\n\n\nSecurity concerns\nOpen-software can be perceived as to present more vulnerabilities than proprietary software - when all software can present vulnerabilities. You should check if your institution has an open software security policy in place - if so, follow their guidelines to assure compliance and up-to-date security protocols 7. To minimize security risks, we also encourage you to download code/software from an authoritative source - such as the original project repository - rather than a third party site.\nHowever, an important benefit of open source is that you can see exactly what the code is doing and know what are the dependencies, what is useful if any of them becomes vulnerable. You don’t have the same level of transparency with a closed-source code. Open source codes also might have (some or many) eyes on them, which can result in better oversight. Widely-used open software will have a community of researchers and developers working on its code, looking closely at inputs, outputs and computer performance. But always, check with your institution about their requirements, guidelines and policies regarding open-source software.\n\n\n\nAs a developer/provider\n\nOpen Software can require extra work\nSome extra work might be required to share code that is already written to improve readability (e.g., comments, variable names, indentation) and documentation (e.g., README and code of conduct files) of your work, so others can easily understand it and use it. However - and we cannot stress this enough - open software is a journey, not a destination. How much to change and add is totally up to you. The important part is to publicly share your code.\nBy writing code that is easily readable by humans, you can make it more usable even to yourself! It will save you time when you want to re-use it years later. Moreover, the more upfront effort you put into developing an accessible code, the more others will be able to use it - which might lead to more collaborations, better feedback, and career opportunities.\nThere is also a time commitment for basic steps of creating documentation, choosing a license, getting a DOI. Our module gives you an understanding of these terms, providing you a checklist with clear steps to sharing your code. We also point you to resources to make this process smooth and save you time in decision-making.\nAfter sharing your code in a repository, you will have a reliable backup that won’t depend on your own hard drive - and you have many free options to choose from! Added benefits are that by creating a license, you are allowing others to use your work on the terms you will choose. By having a DOI, your code is a findable (by online search engines) and citable reference, and you thus, you will get credit for your work! You can also learn more about DOIs in the lesson about Licenses.\n\n\nBecoming a maintainer\nMaintaining an open software (particularly open-source) long-term can bring its special sets of challenges - from the time commitment, to the procurement of funding, to navigating requests from users. Maintaining your code after sharing it is a personal choice, and you can step out of this role at any time you chose (more about this in Lesson 5]).\n\n\nSustainability\nDespite the importance of open-software for researchers, support and incentive for open-software development and maintenance are frequently inadequate 8 9 10 1112 13. As reported by the Australian Data Commons (2022):\n\nSoftware is an often invisible part of research, produced quickly within a funding window, often struggling to be maintained beyond that. 14\n\nContributions to open software within traditional academia don’t carry the same weight as publications - software is often seem as a by-product of research, and dedicated funding is unusual 15 16 17 18 19 20. As reflected by reports and analyses from several countries, a shift in paradigms of funding and career advancement are required, along with an increase in software literacy, so open-software can be more sustainable.\nWhile this is a larger, structural issue that cannot be easily overcome by an individual, we have strength in numbers. More researchers in the open-source community, will result in more visibility of these issues, both for our institutions and funding entities. As more researchers move towards an open, collaborative framework of science, it is expected that more changes will happen to the current paradigm, allowing a fruitful future for open-software."
  },
  {
    "objectID": "open-software/lesson2-pros-cons.html#summary",
    "href": "open-software/lesson2-pros-cons.html#summary",
    "title": "The Pros and Cons of Open Software",
    "section": "Summary",
    "text": "Summary\nIn this module, you reviewed particular benefits of open software to improve: 1) visibility of your work, 2) Long-term Sustainability, 3) Quality of your software, and 4) your career prospectus. You also could explore how open-software furthers the open-science principles, increasing 1) accessibility, 2) freedom, and 3) democratization of science.\nDespite its multiple benefits, adopting and creating open-software also brings challenges. In this module, we addressed some common challenges, with some tips to overcome - perceived and real - barriers to open-software.\nLastly, we want to emphasize that adopting open-software (as a user or as a developer) on your research is a journey. As with the practice of open-science, there is a spectrum, and you make your own choices of how, what and when you are able to share, given your personal skill set, institutional policies, time and funding limitations. The most important is to take the first steps, and continue this journey together with the open-source community."
  },
  {
    "objectID": "open-software/lesson3-licensing.html#introduction",
    "href": "open-software/lesson3-licensing.html#introduction",
    "title": "Licensing, Ownership & DOIs",
    "section": "Introduction",
    "text": "Introduction\nAfter deepening your understanding of the reasons to use open-software in the context of open-science, we here address the first considerations when using an open software tool in your research. First and foremost, if you are going to be building your own code on prior work you need to choose a software that is open, i.e., that you are allowed to use, modify and redistribute. As a developer, you also need to ensure that you are sharing a product that is open - and thus, usable - to others. This is presented on the section Licenses.\nThen, we present how you get credit for your work, and how you give credit to others’ work. This is the content of the section Attribution and citation.\nAt the end of this lesson, you will be able to: Choose and abide by appropriate usage and referencing standards of open-software."
  },
  {
    "objectID": "open-software/lesson3-licensing.html#licenses",
    "href": "open-software/lesson3-licensing.html#licenses",
    "title": "Licensing, Ownership & DOIs",
    "section": "Licenses",
    "text": "Licenses\nA software license is a legal document that grants users particular rights to the use of a certain software. This license can take many forms, but in many cases they outline contractual obligations (if any exist) between the company/software developer behind the software and the end user, what the user can do with the software, who the user can distribute the software to (if any such distribution rights exist) and the length of time the user has the right to use the software.\nA user cannot (technically and ethically), use a software without a license! A user can reach out to the developer/owner to ask for permission, and go ahead if the owner/developer furnishes written permission. But, if you share your software without a license, no one can use it without your written permission!\n\nTypes of licenses\nA license can fall under several categories. License types have general definitions of what can be done with the software. By picking a type of license, or by understanding what type the license of a software you’re considering using is, you’ll be able to navigate the license process more quickly than reading each license individually and interpreting the permissions. An overview of types of licenses is given in the table below1:\n\n\n\n\n\n\n\n\n\n\nPublic domain license\nLesser general domain license\nPermissive\nCopyleft\nProprietary\n\n\n\n\nAnyone can use or modify the software.\nCan link to open source libraries and code can be licensed under any license type.\nHas some requirements for distribution and modification.\nLicensed code can be distributed or modified if all the code involved is licensed under the same license.\nSoftware cannot be copied, modified or distributed\n\n\n\nSummary of selected attributes of licenses types 2: \nSome of the common licenses used in open software are:\n\nMIT license\nApache License 2.0\nMozilla Public License 2.0\nBSD 3-Clause “New” license\nGNU General Public License (GPL)\nCommon Development and Distribution License\n\nFor more information on different types of licenses please refer to the (Open Source Initiative OSI).\n\n\nHow to choose a license\nThere are a number of steps that have to be made before choosing a particular license. Arguably one of the first decisions to be made is based upon whether you intend to use the code for commercial purposes or not, or at least foresee it as a possibility in the future. Some licenses are more favorable for commercial purposes than others, such as the General Public License, version 2.\nThe next decision that has to be made is relating to the issue of distribution. When using other software as a dependency, you should always be wary of their licenses. Some licenses enforce certain types of licenses upon redistribution. The GNU GPL, for instance, is incompatible with proprietary licenses, because it requires the combined work to be licensed under the GPL, with no additional restrictions allowed. Having a part of the work under a proprietary license is such an additional restriction, so you cannot distribute such a combination (unless the copyright owner of the GPL code gives special permission). 3\nFor licensing open software, it is always good practice to consult with the Open Source Initiative (OSI) website. They provide a list of approved licenses that guides you through this process. Remember that a first step is always to consult with your institution (if applicable). You should ensure that you are complying with any applicable local laws and any policies set by your employer and/or funding entity.\n\n\n\nschematic\n\n\n\n\nAdditional Resources\n\nChoosing a License\nTuring Way on licensing"
  },
  {
    "objectID": "open-software/lesson3-licensing.html#attribution-and-citation-katzsmithchue",
    "href": "open-software/lesson3-licensing.html#attribution-and-citation-katzsmithchue",
    "title": "Licensing, Ownership & DOIs",
    "section": "Attribution and citation [^Katz]45",
    "text": "Attribution and citation [^Katz]45\nBoth when choosing a license and publishing your software for future citation, a decision has to be made in relation to the issue of attribution, i.e., crediting a person or group of people or other entity with a particular action in relation to the software. This can be thought of as the software/code equivalent to authorship on an academic paper. It is important to consider this to avoid accusations of plagiarism or copyright infringement. There is a short discussion in the final lesson in this module regarding ethical considerations on how contributions can be considered for authorship/attribution/ownership.\nWhen deciding to cite a software or code that was used in your research you can start with the question: is this research software? Research software includes source code files, algorithms, scripts, computational workflows, and executables that were created during the research process or for a research purpose. Software components (e.g., operating systems, libraries, dependencies, packages, scripts, etc.) that are used for research but were not created during or with a clear research intent should be not be cited (e.g. Microsoft Word, Linux, Python –the language itself; specific packages might be citable in this context). This differentiation may vary between disciplines. Some examples of research software that would be cited are E3SM, SciML, and Stock Synthesis.\nThe majority of open source software licenses require some degree of attribution, and a small minority (such as the 0BSD) do not. The license will also dictate where the attribution must be displayed - some licenses will require the user to include attribution in a dedicated file such as the software license agreement.\n\nDigital Object Identifier (DOI)\nBy having a persistent identifier, a software version can be cited. A digital object identifier (DOI) is a persistent identifier or handle used to uniquely identify various objects. It is provided and standardized by the International Organization for Standardization (ISO). In contrast to dynamic web addresses such as URLs, DOIs are static, i.e., do not change over the life of a document, and point to the location of the document on the internet. You can get a DOI for your own software/code by adding it to a preservation repository.\nJust as we publish scientific findings in writing in journals to ensure its preservation over time, its supplementary material, e.g., source code and produced data, should also be stored in a permanent location. We call these preservation repositories. Some of these repositories are general-purpose such are Zenodo and Figshare, and some are more research field-oriented such as Hydroshare.\nIt is important to keep in mind that a DOI refers to a static version of your code and so, you’ll need to get a new DOI for each version you release and want cited. By using the same repository each time you need a DOI for a new version, you can be sure that when a user looks for your DOI they are directed towards the most recent version.\n\n\nCiting code without a DOI\nAs a user, if you’d like to cite a software that does not have a DOI you can use Software Heritage to create a SWH-ID which is also a citable persistent identifier, but can be created for codes that are not your own. This should only be done after ensuring a DOI is not available otherwise there can be multiple identifiers being used for the same piece of software.\n\n\nAttribution for pieces/snippets of code\nWhile DOI and SWH-ID allow citations of full pieces of software/code, there is also the case where a small code snippet or section might be copied into another code. It is common practice to take a few lines of code to solve a piece of a problem from websites such as StackExchange or Code Ranch, but there should still be an attribution if no changes are being made. This can be done effectively with a comment that includes a link to the webpage from which the code was taken (most sites have an option to create a shortened shareable link that is more code friendly).\n\n\nPublishing open software in peer-reviewed journals\nIt is also possible to publish open software or a research article detailing the inner workings of that software in peer review journals. A general example is the Journal of Open Source Software; there are also more discipline specific journals such as Astronomy and Computing and Environmental Modeling & Software. The peer review process for some of these journals may include a review of the code itself, some may be focused just on the describing journal article that accompanies it. These publications will also come with a permanent identifier as is customary with most journal articles."
  },
  {
    "objectID": "open-software/lesson3-licensing.html#external-requirements",
    "href": "open-software/lesson3-licensing.html#external-requirements",
    "title": "Licensing, Ownership & DOIs",
    "section": "External Requirements",
    "text": "External Requirements\nThere are various legal considerations to keep in mind with regard to software and code you write. For example, these may be considered intellectual property, and you may wonder who has ownership over it. Generally speaking much of this is dependent on your employment and funding situation at the time you did the work. Your institution may have claim to part or all of the work product, however it is highly variable, and your institutional offices should be contacted to understand this better.\nThere may also be other institutional, governmental, or other legal policies that may be dependent on your region. Please make sure you understand your locality’s laws and regulations regarding the sharing of research software and follow your institution and funding agency’s requirements (if any) on licensing and intellectual property.\n\nAdditional Resources\nCode publication Computational Infrastructure for Geodynamics - example of a preservation repository that provides peer review When to cite software CiteAs: a resource for finding the correct attribution of a research product"
  },
  {
    "objectID": "open-software/lesson3-licensing.html#summary",
    "href": "open-software/lesson3-licensing.html#summary",
    "title": "Licensing, Ownership & DOIs",
    "section": "Summary",
    "text": "Summary\nHere, we reviewed that a software license is a legal binding document, made between the developer and the user of a software, which outlines how that software can be used and distributed. Open software will carry licenses that follow the Open Software Initiative (OSI) definitions: allowing the software to “to be freely used, modified, and shared.” (Open Software Initiative OSI)\nWe have presented the major categories of licenses that might fall under the open-source definition, and what considerations to take when choosing a specific software and/or license for your software, i.e. 1) what is the intended use of this software?, 2) how others can reuse it? And what are the policies of my institution and local laws regarding open-software use and dissemination?\nWe have also learned about proper attribution - how to get credit for your work (DOI, archival of code, publishing options), and how to cite others work."
  },
  {
    "objectID": "open-software/lesson3-licensing.html#references",
    "href": "open-software/lesson3-licensing.html#references",
    "title": "Licensing, Ownership & DOIs",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "open-software/lesson4-code-management.html#introduction",
    "href": "open-software/lesson4-code-management.html#introduction",
    "title": "Code management/Quality",
    "section": "Introduction",
    "text": "Introduction\nWhile we maintain that sharing software at all is a great initial first step regardless of it’s state, the more the code is kept clean, maintained, and documented, the more others will be able to cite, use, and contribute to it."
  },
  {
    "objectID": "open-software/lesson4-code-management.html#what-does-it-mean-for-softwarecode-to-be-of-good-quality",
    "href": "open-software/lesson4-code-management.html#what-does-it-mean-for-softwarecode-to-be-of-good-quality",
    "title": "Code management/Quality",
    "section": "What does it mean for software/code to be of good quality?",
    "text": "What does it mean for software/code to be of good quality?\nThere are two perspectives that you can take when engaging with this lesson: a user of open software, or a developer/provider of open software. As a user, you will want to make sure that a code or software project you are considering using in your research/project is quality. As a developer/provider, you will want to make sure your project is of high enough quality that others will want to use and engage with it. When we say “quality” code, we are referring to precisely that, a software/code that a user can be confident in using.\nHere we outline some baseline expectations for open software. While there are definitely good open software projects out there that do not include all of these items (and, unfortunately, plenty of projects out there that contain many of these items but still don’t function well), this guide will assist in ensuring the software/code that you develop/use is quality.\n\nGood documentation\nGood documentation for code is possibly the most important item on this list for creating a quality code. This will help a user know what the software does and how it can be used, but also can be a real time saver for a developer when going back to look at code they haven’t looked at in a while.\n\nThe README file\nThe first stop for a user when they approach a new project should be the README file. Aptly named, this file should contain orientation information that will help a user understand the project’s purpose as well as shows examples of how it can be used, and lists most other important information the creator deems necessary. Note that there is no one agreed upon convention for the location of these documentation pieces, so we encourage exploration of the software you’re interested in. Some information we describe as in a README file may be moved into its own file in some conventions, e.g. having installation instructions in an INSTALL file, but the README is still usually the best place to start. Keeping that in mind, if you are developing a code/software for use by others, they will expect a descriptive and useful README, without one using your code may be a nonstarter for many.\nHere is an example of a README file from a NASA-funded project that shows many of the specifics we are going to discuss below including multiple installation options. As you read the suggested parts of documentation below feel free to reference this for an example.\nLet’s dive into the specifics of information you should include/find in a README file. First, a description of what the software does: it’s purpose, the problem it’s solving. You don’t need to write a whole academic paper here, a sentence or two is fine. If you do happen to have a research paper written on the topic no one would be upset if you link it here, though do be careful that any linked papers are either (a) not behind a paywall or (b) if it is behind a paywall, that the important information a user would need to use and understand your software is reiterated separately within the code documentation.\nA compatibility description is also necessary. Sometimes this is wrapped into the installation instructions and that is acceptable. Here the operating systems (e.g. Linux, Windows, macOS – and their versions) that the software/code works on with are listed. If the code runs in a browser which does it work with? There are many tools for testing the compatibility of code across operating systems and environments, we won’t get into those here as they can be specific to the coding language you’re working in.\nIf installation instructions are not in their own file, they’ll live inside the README. These should be written with very little prior knowledge expected of the user. Most people are used to downloading a software package, double-clicking on the executable, and having a setup wizard walk them through any required steps. Setups such as this are achieved through packaging. Packaging bundles all the necessary pieces for a software to run, usually including dependencies, and distributes it to the user as one “package”. Packaging software can make installation a lot simpler for users and allow it to be installed consistently that aids in reproducibility. Most open software won’t be packaged to the double-click-with-setup-wizard level and some won’t be packaged at all. They will require a bit more up front work for the user, but an advanced knowledge of installation practices shouldn’t be assumed. For example, an exact command that can be copied and pasted into the command line is a lot more helpful than something like “clone the repo” or “install using git pip”.\nUsage examples are another important part of a README document. While how to run and use the software may be obvious to the developer, many times this is not the case for the user. Simple/small usage examples are great for the README file. If there are more complex examples that require input files or that are interactive for the user and the programming language you are using supports interactive environments, such as Jupyter (for R, Python, and Julia), Pluto (for Julia), Quarto (for R, Python, and Julia), and RStudio (for R), these can be used and included in a repository and pointed to in the README. If interactive environments are not an option for the language you are using and your usage examples are necessarily complex, consider writing a standalone script and including a pointer to this with instructions on how to use and run that example script in the README.\nIf relevant, the README is also one of the places you may find descriptions of the outputs of a software/code. Both what kind of objects these may be in terms of their type (e.g. string, integer, etc.) and in their general description (e.g. a list of names, the amount of rain the model calculated, etc.).\nAs the README is the first place a user will look, this is also where you can find other notes and caveats of using the software. This should include at least something on the state of the software: is it in active development (meaning it may have some bugs and may not always work as expected), consistently maintained (meaning the software is updated when necessary–like when a dependency is updated or a bug is reported), or here for posterity purposes only (meaning the author/developer/researcher will not be working to maintain or improve this code any further)? How can you contact the developer/researcher that created this software/code? How can issue/bugs be reported (if at all)? This would also be a good place to list any known bugs/issues, so you get repeat requests.\nThe README is also a great place to acknowledge team members that worked on the code/project as well as agencies and grant numbers that funded the work.\n\n\nDependencies\nThe dependencies – the other software on which the software/code relies – should be listed somewhere in the documentation, but are not always in the same place depending on the coding language. For example, in Python software, it is common to include a file titled something like environment.yml which will list dependencies and which can be used to install them quickly and easily. Other conventions may include listing them in the README file, a README can also be used to point to an additional file that lists dependencies (such as the environment.yml or requirements.txt)\n\n\nLicense\nA license file should be included with your documentation. This is expanded upon more in another lesson in this module, but without one, the code/software is technically and ethically not allowed to be used at all by anyone other than the author/developer.\n\n\nThe CONTRIBUTING.md file\nOne of the great benefits of open software is that it enables contributions from the community. The CONTRIBUTING.md and CODE_OF_CONDUCT files in software can be referenced for information on how to do this. This is expanded upon more in a later lesson.\n\n\nDocumentation Checklist\n[ ] Description of the software and the problem it solves\n[ ] Compatibility description\n[ ] Dependencies\n[ ] Installation instructions\n[ ] Usage examples (perhaps including an interactive notebook)\n[ ] Development status of the software (under development, actively maintained, etc.)\n[ ] Contact information\n[ ] How to report issues/bugs (and a list of any known issues/limitations)\n[ ] Acknowledgments of team and funding\n[ ] License\n[ ] Contribution guidelines\n[ ] Code of conduct\nAdditionally, a GitHub template from NOAA for open software documentation can be found here.\n\n\n\nClean/readable code\nCode for software is very rarely written only for one individual. Code typically has to be read and evaluated by others. In private companies, this is usually because software is written by a group of programmers and so it is important that programmers are able to read and understand the code, both in order to improve it and to “debug” or fix it. Open software also operates similarly: there may be many programmers working and contributing to a particular project from different backgrounds and walks of life. With different programmers with different backgrounds collaborating together, it’s important that code is transparent and can be easily understood by others. This is sometimes referred to as “clean code”.\nClean code is code that is easily understood by others. Clean code has a number of advantages. One advantage is that it is easier to spot if or whether something is wrong with the code (known as “debugging”). Another advantage is that code that is “clean” is more likely to be shared than code that is not. This is fundamental to open software, which aims to be reproduced as widely as possible. There are a number of principles that should be adhered to when using clean code.\n\nCode Comments\nArguably one of the most important is that code should be commented. Comments are annotations that help other programmers reading to understand what is going on. In many languages, they are designated by the sign // or # or /* */. As a rule, more comments are better than less but this should be prefaced with the warning that comments should not explain the obvious. For example, in the language JavaScript, the following would be an inappropriate comment\nvar a = 5; //I'm assigning the value of 5 to the variable a.\nIt is inappropriate because the code is self-explanatory.\n\n\nDescriptive naming\nAnother point to bear in mind when it comes to clean code is that variables, functions, and similar entities should be given descriptive names as opposed to vague names. These are names that, when another programmer reads them, instantly gives an idea of what the variable or function is. For example, the variable name colourOfCat is a good name because it describes what it intends to do, which is to encompass the color of a cat. As a rule, the more descriptive a name for a variable, function, etc., is the better. Names for variables, functions, etc. should avoid using words that are likely to be keywords - names with reserved meanings in many languages - such as “while”, “for”, “override” and so on. Needless to say, names for variables, functions, etc. should similarly avoid giving offense and clean code should consider the sensitivities of those from different backgrounds.\nIt’s frequently the case that code may point to external files; where possible, a programmer should ensure that the external file has a descriptive filename. In addition, clean code should also conform to programming conventions. For example, it’s common in many programming languages to use camel case to describe variables, such as colourForCat rather than COLOURFORCAT, but one would do well to ascertain what a convention may be for a particular language.\n\n\nWhitespace and indentation\nLastly, clean code should contain sufficient spaces between lines of code (also known as whitespace) and sufficient indentation so that they are easily discernible. Sometimes code that does not contain sufficient lines of code can go through a process known as beautification or prettifying that helps them become more readable. Ultimately, a key test for whether code can be considered “clean” is the following: if you left the code and came back to it 2 years from now, would you be able to easily understand it?"
  },
  {
    "objectID": "open-software/lesson4-code-management.html#summary",
    "href": "open-software/lesson4-code-management.html#summary",
    "title": "Code management/Quality",
    "section": "Summary",
    "text": "Summary\nIn this lesson we go over two main topics regarding markers of quality code: (1) good, descriptive documentation and (2) clean, readable code. As a user, documentation can be the difference between spending hours or days trying to understand a code and being able to use it right out of the box. As a developer/researcher, documentation improves the reproducibility and reusability of your code and lets others know what to expect both of your code and of you yourself as a maintainer. Next, we’ll discuss maintaining quality code."
  },
  {
    "objectID": "open-software/lesson4-code-management.html#references",
    "href": "open-software/lesson4-code-management.html#references",
    "title": "Code management/Quality",
    "section": "References",
    "text": "References\n\nLee BD (2018) Ten simple rules for documenting scientific software. PLoS Comput Biol 14(12): e1006561. https://doi.org/10.1371/journal.pcbi.1006561\nAnzt H, Bach F, Druskat S et al. An environment for sustainable research software in Germany and beyond: current state, open challenges, and call for action [version 2; peer review: 2 approved] F1000Research 2021, 9:295\nMartin, R. C. (2008). Clean code: A handbook of agile software craftsmanship. Prentice Hall."
  },
  {
    "objectID": "open-software/lesson5-vesion-control.html#introduction",
    "href": "open-software/lesson5-vesion-control.html#introduction",
    "title": "Maintain good code quality",
    "section": "Introduction",
    "text": "Introduction\nWe’ve talked about markers of quality software in the prior lesson: good documentation and clean, readable code. The reality is that for most software, this is a journey, and it is going to continue to change and develop over some period of time. Here, we discuss version control, testing, and responsibilities after sharing. These topics are centered around the evolution of your code and ensuring the work you’ve done to make quality open software is able to endure."
  },
  {
    "objectID": "open-software/lesson5-vesion-control.html#version-control",
    "href": "open-software/lesson5-vesion-control.html#version-control",
    "title": "Maintain good code quality",
    "section": "Version control",
    "text": "Version control\nOpen source codes can change overtime. This brings several challenges to researchers developing and using an ever-changing software. We covered the importance of reproducibility for open-software - and open-science as a whole. Now, how can we achieve reproducibility with a changing code source? That is done by keeping track of changes to our source code, using version control.\nVersion control can be done with tools and systems designed to manage changes not only to source code, but also to documents, websites, and datasets. Google Docs, for instance, has its own complex version control. This allows you and your collaborators to have access not only to the most updated google document you all are working on, but to the complete history of changes. So, if something goes wrong in a document: a child includes a thousand smiley faces in the text, a cat walks on the keyboard and deletes an entire section - you can just revert to the earlier, error-free version.\nThis is the same for coding. For instance, you - the developer - receive a notification from a user that your code has a bug. You know that this bug was not present in the last version, so you can easily work through your history to look what recent changes might have caused a specific error, narrowing down your debugging work to specific parts of the code. So, version control allows a group of developers/users to know exactly what version of the code they are using, what changes were made and when - facilitating reproducibility. Version control also fosters collaboration, making it easier for people to work together at the same time and to merge changes from different users.\nThere are several version control systems (VCS) available. We won’t get into detail here, but some of the most popular open-source systems include git, SVN, and Mercurial. It is important to note that while some repositories have already a built-in version control, repositories and version control systems are different - e.g., git is the version control system, while Github is a hosting service for git repositories.\nIn lesson 6, we revisit version control, giving some concrete examples of how you can use it to contribute for new or existing open-source code."
  },
  {
    "objectID": "open-software/lesson5-vesion-control.html#testing",
    "href": "open-software/lesson5-vesion-control.html#testing",
    "title": "Maintain good code quality",
    "section": "Testing",
    "text": "Testing\nIn Lesson 1, we introduced the concept of code testing and its importance in software development. There are many types of testing that range from testing the smallest testable parts of a code to verifying if a code works as whole under different scenarios. Since code testing in general can be a complicated and technically involved topic, we will not go into the details of each types of testing and refer you to external sources for further reading. Instead, we focus on benefits and difficulties of testing in general, how to measure test coverage, and what to expect from a “tested” code as an end-user.\nWe recall that reproducibility in research software plays a critical role. In the context of testing, we can think of reproducibility as a test objective of which is to reproduce a specific output, i.e., results obtained from a specific version of the code that has been published in a journal. This test should include all the required inputs (configuration files, input data, etc.) so users can easily run and get the same published results.\nMore broadly, the main objective of code testing is to evaluate if a code is doing what it is supposed to do. It is important to recognize that testing a code comprehensively can be very difficult since not only we should test the code for generating expected outputs but also for failing when it should. For example, when an unacceptable input is passed, e.g., wrong type, out of range, edge cases, etc., or when if implemented the algorithm doesn’t converge for the given set of inputs. Taking into account all these scenarios can be extremely difficult and in some cases impossible. Therefore, we should manage our expectations when taking the tests as a measure of code’s quality both as a developer (e.g., realizing that the end-users might apply the code to scenarios that we don’t anticipate) and an end-user (e.g., realizing that the difficulties associated with testing and, if possible, evaluate the accuracy of outputs independently).\nFrom a developer perspective, there are also secondary benefits for testing. Whenever you make a change to a part of your code, for example to improve its performance, having tests for that portion of the code, ensures that the modified code does not change the output. Another scenario could be related to dependencies. For example, research software often depends on other software, therefore, if those dependencies release new versions, the tests help us evaluate if those new versions make any changes to outputs of our code.\nOn the other hand, as an end-user, using a code that includes tests, gives us more confidence in the state of the code. Users can check the status of tests (pass/fail) when the developers make changes, or the code has been tested for the use-case of our interest.\nNow that we have a better understanding of the testing, we can discuss measuring its effectiveness. One of the ways that we can measure the testing is through percentage coverage. There are two levels of coverage: test coverage and code coverage. Test coverage refers to the coverage of different scenarios that the code would be used in while code coverage is the percentage of lines of code that tests cover. As we discussed previously, enumerating all the different scenarios the code could be used in can be very difficult, thus, it can be difficult to quantify test coverage both from a developer and end-user perspective. However, code coverage is just a simple percentage value: how many lines of code do the tests activate vs. not. It is important to note that a high code coverage does not necessarily mean that a code has good test coverage since testing different usage scenarios can not directly be translated to lines of code.\n\nAdditional Resource\n\nIBM on Testing\nSoftware Testing\nMartin, R. C. (2008). Clean code: A handbook of agile software craftsmanship. Prentice Hall."
  },
  {
    "objectID": "open-software/lesson5-vesion-control.html#responsibilities-after-sharing",
    "href": "open-software/lesson5-vesion-control.html#responsibilities-after-sharing",
    "title": "Maintain good code quality",
    "section": "Responsibilities after Sharing",
    "text": "Responsibilities after Sharing\nAfter sharing software, there are certain steps that need to be taken in regard to maintenance of that code/software.\nFirst, you should know it is not a requirement for you to be a permanent maintainer forever, but it is your responsibility to let users know if you do or don’t intend to maintain the software/code. You can do this in your documentation where you discuss the development status of the project. This helps a user know if it will continue to be supported in the future, and make choices about if they should base ongoing work off your project. You don’t want someone to spend a huge amount of time using your work as a dependency and then have their project become unusable in the future.\nThe reality is that a developer/researcher may not have the time or continued funding to keep up with a project. In this case, perhaps consider handing ownership of the software to another researcher/developer, involved user, or entity invested in its continued use. You can either approach potential parties you think may be interested in this; or you can make your license permissive enough to allow others to create their own copies and continue your work (see more on choosing a license in this module). Depending on the license you choose, the use of your project, and if you have significant interest, you may be able to commercialize your software/code to provide funding for continued maintenance and feature requests. There is also the potential to apply for continued funding from agencies both governmental and private if your open software is widely used. If you’re a user of a software that is no longer maintained, consider contacting the owner/developer and volunteering either as a maintainer, or to take over ownership of the project (you’ll be more likely to get a positive response if you leave that choice up to the current owner).\nIf you receive requests for features and fixes, and you have indicated you intend to maintain the code, these should be responded to. Either tell the users that (a) you intend to perform their requested action or (b) you think that’s out of scope of your project. Additionally, you can invite the requester to (a) contribute to the project and add that feature/fix themselves (which you can then approve and add into your project) or (b) fork (make a copy of) the project and create the feature/fix, notifying that you will not merge changes into your (main/original) copy."
  },
  {
    "objectID": "open-software/lesson5-vesion-control.html#summary",
    "href": "open-software/lesson5-vesion-control.html#summary",
    "title": "Maintain good code quality",
    "section": "Summary",
    "text": "Summary\nHere we discuss how version control and testing can both be used to increase the reproducibility and trust a user can place in open software. These are tools that can be used whether your software is shared or not. We go over what responsibilities a developer/researcher has after sharing their code: namely to inform your potential users if you will be maintaining the software and if so, respond to requests for feature additions and bug fixes. We discuss options for allowing your code to undergo continued development even if you don’t have time/motivation/funding to continue iteration and encourage users of code that is no longer maintained to explore these options themselves by reaching out to the original developers. Furthermore, we discuss how users can become involved in existing projects in our next lesson."
  },
  {
    "objectID": "open-software/lesson6-contribution.html#introduction",
    "href": "open-software/lesson6-contribution.html#introduction",
    "title": "Contributing to existing open software",
    "section": "Introduction",
    "text": "Introduction\nIn previous lesson, we have discussed the importance of using version control and testing to maintain good quality of code. Community contributions are the primary driving force behind open software initiatives. Open software contribution not only benefits the contributor, but also help to maintain the software’s long-term viability. In this lesson, we will cover the various types of contributions that can be made, which are not limited to coding contributions; non-coders can also make significant contributions to open source software. In addition, we will cover how to use version control in open-source project contributions; some good contribution practices will be discussed in this lesson as well.\n\nBenefits of contributing to an open software\nContributing to open software provides many valuable advantages and opens doors to a number of highly lucrative and rewarding opportunities, and there are not too many other industries that can boast the massive number of global contributions like the open-source community can.\nA first advantage of contributing to open software is that it will require you to write clean, documented, structured code. In combination with the feedback you will obtain from leading developers in the field, this can help to improve your coding and communication skills.\nSecondly, contributions that you have made to open software constitute a documented and publicly available record of your work (git commits, for example, get indexed within google search). This allows you to reference to your contributions as part of a software portfolio or resume, providing a direct evidence of your work and skills.\nFinally, contribution to software by members of the community creates a unique constellation in which the contributors to the software are also its main users. Often, contributions to open software stem from users who wish to improve or change the software for their own use and adapt the software problem constellations in the software’s field of use. This direct feedback loop between user and developer allows for a fast development cycle and makes open software more flexible to changes in needs and requirements than software products that are maintained by a company.\n\n\nTypes of contribution to an open software 1\nThere are several types of contributing to open software. Not all of them require writing actual code.\nAdd new features. The most obvious case for contributing to open software is enhancing its usability by adding new features. Make sure to open a new issue first.\nFix bugs/issues. Alternatively, you can reply to an already opened issue by fixing it. Make sure to reference the issue when creating a pull request/ request for reviewing your fix.\nReport issues/ suggestions about improving code. Reporting an issue is a valuable contribution even if you don’t know how to fix it. For example, you might be using a different browser in which the software has not been tested yet, have discovered a particularly uninformative error message, be colorblind or be otherwise able to feed a valuable user experience back to the developers that can help to improve the overall usability of the software.\nImproving and contributing to documentation. Contributing to documentation constitutes a great starting point to contributing to open source software and is often overlooked in its importance. Writing documentations allows you to familiarize yourself with the use of the software, while helping to teach others.\nCreate tutorials, use cases or visuals. Another way to contribute is to make your experience and use of the software publicly available. For example, you could create a tutorial based on your use of the software, summarize a use case or provide a summary of your use in a graphic. This part of contribution is particularly appealing as it does not create much extra work to just publish what you have used the software for.\nImprove layout, automatization, structure of code. Apart from creating new code, a good way to contribute to open source software can also be to improve, restructure or automatize existing code. This is called refactoring and helps to make the software project more effective and stable.\nOrganize/attend a meetup/community building. Another way to contribute to open source software is via community building. Many software products and toolboxes have a lively community of users that meet on a regular basis in person and online to discuss and improve the software and its use. Participating or even organizing such a meetup can be a good way to improve your knowledge of the software, get to know its community and contribute to open source projects\nCode review. Pull requests or other requests to integrate new contributions into the main code base usually require a review of the contribution by at least one other user. In the git version control system, code review entails writing a short summary about the quality of the code, making suggestions about improvements and then approve or reject the request.\n\n\nHow to contribute? 2\nBefore you contribute to an open source project, there are several resources that you can check in order to get a feel for the community, the general environment the software lives in and the contribution and maintenance process. Below some examples of essential files 3 that you might find in a repository and that might be worth looking at.\n\nThe README.md file gives first information/summary about the project. Here you might also find installation instructions, software and operating system requirements or a reference to published papers on the software.\nThe CONTRIBUTING.md file gives information about how to contribute to the project. It explains in more detail how the contribution process works and what type of contributions are needed. While not every project has a CONTRIBUTING.md file, the existence of one is a clear indicator that contributions are welcomed.\n\nThe LICENSE file contains the legal aspects and boundaries of contributions. It specifies in which ways the code can be altered and how to proceed with altered code. While alterations to code just for your private use are usually always possible, the license file comes into play in case you intend to publish or commercialize and alteration to the software.\nThe CODE_OF_CONDUCT file: The code of conduct sets ground rules for participants’ behavior associated and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.\n\n\nContributing via a version control system\nCongratulations! You have decided to contribute to an open source repository. However, to protect the code in the original repository, you usually don’t have rights to commit directly into that repository.\nHence, as a user, the next step on your way to a contribution is to create a fork (a copy of the original repository into your own account). In contrast to the original repository, you will be owner of the fork, and thus you will have writing rights.\nYou can also clone this fork onto your local machine. Then there will be three copies of the repository: The original upstream repository, the fork in your (online) account, called origin in git, and the local clone.\nAlternatively, as a developer, you can also create a new git repository from scratch (use git init here). This will make you the owner of the repository and give you writing rights directly.\nYou can now make changes to your local clone, your local initiated repository or to your online repository, each of them also being called your respective working directory. Changes to the working directory will be tracked in a staging area, from which you can and commit them using the command git commit -m message. If you committed to you local clone or initiated local repository, you need to push them to the origin repository (your online fork) first, if you want to make use of them online.\nFrom there, you can create a pull request to an upstream repository. The owner of upstream repository will then review your changes and approve them or request changes.\n\n\nSimple version control workflow\nWe have again summarized those steps in a checklist for you. We present here a simple definition of the workflow with common terms you will encounter, and offer some suggestions for a more in-depth lesson. Software Carpentry can be a great place to start!\n[ ] Create Repository\n\nDeveloper: creates a new repository from scratch. Our tip: just go for it. You can create your repository with one file, or an entire existing open software.\nUser: will create a copy (clone or fork) of an existing repository.\n\n[ ] Make changes\n\nYou can make any changes you want to your copy, but no one will see your changes until you commit (i.e., submit them).\n\n[ ] Publish your changes\n\nIf you are like your changes and additions, commit. This will update your local repository.\nSo far, only your local repository has changed. To update your remote repository, push your modifications.\n\n[ ] Get changes from others\n\nWhile you were working on your copy, other users might have changed the remote repository. To keep your local repository updated, you need to retrieve, or pull the latest changes.\n\n[ ] Keep track of changes\n\nTo check what is different in your copy since the last commit, you can check the status of your repository.\n\n\n\n\nremote\n\n\nAs a last note, version control is a good practice for coding, so use it even if you are not sharing it immediately. You can use version control with your codes privately on your computer, or use the private mode on hosting services (e.g., GitHub and GitLab). And, once you are ready, you are one step ahead to share your code.\n\nFurther Resources\n\nSoftware Carpentry Version Control with Git\nThe Turing Way, Version Control\nFAIR Use a publicly accessible repository with version control\n\n\n\n\nTypes of Commits\nA sustainable open software usually depends on active contribution from the community through commits access to the repository. In software version control, a commit is an operation which sends the latest changes of the source code to the repository 4. In general, commit operation can be classified into 3 categories 5 : Core, External, and Mutant.\n\nCore Commit refer to any commits that directly associated with the main repository. The Core Committer usually refers to the individual who has write access to the repository of software, and responsible for reviewing pull requests\nExternal Commit is the contributions that go back into the upstream repository through patches or pull requests, and it need permission from Core Committer.\nMutant Commit is a modification to the code-base of a project which is not incorporated back into the upstream repository. This situation happen due to the changes request rejected by the Core Committer or the committer intend to personal use only.\n\n\n\nBranching and Merging\nIn software version control or software configuration management, branching is the process of object duplication from the original work under version control. 6 In this context, the duplicated objects are known as branch. A branch is a version of the repository that deviate from the main working project, and it is independent line of the development process.\nBranching allows parallel development works including bug fixes, feature addition, and safely experiment on the same software while retaining the original source code. The subsections from the main project allow development teams working on the branch independently and free to make any changes without impacting on each other.\nEvery repository has a default branch, which is the first main branch, and it sometimes called parent branch or upstream branch, whereas the child branches are the branches from a parent. We can create many branches from the existing branch. A branch also acts a pointer to one of the commits in the repository. The HEAD is a special pointer that simply points to the latest checked out branch or commit. For example, the default branch named as master, and this master points to the most recent commit called bug-fix, remember that pointer is movable when there is new commit.\nUpon completion, the branches can be reassembled to the mainline and become new version of the software release. The process of integrate changes into the upstream repository is called merging. If you have no permission to commit directly into the upstream repository, create a pull request from the branch into main is necessary. It is a good practice of software development etiquette by ensure the branch is stable before merging them into main branch. Once the merged completed, the local branch can be safely deleted. On the other hand, a branch that not intended to be merged is known as a fork.\nIn summary, branching and merging is typical process that allows development team to work on shared codebase and manage the software effectively.\n\n\nMerge conflicts\n\nDefinition\nThe merge conflicts occur when the version control systems unable to automatically resolve the differences in codes between two commits. It requires manual changes and decision to incorporate in the final merge.\nHere is an example to explain the scenario, both developer A and B make changes on code file in different branch, they make changes on the same line of codes. During process of merging these two branches, it will cause merge conflict as it has competing or ambiguity changes.\n\n\nHow to resolve\nIn order to resolve the merge conflict, we must find out where is the conflict occur, identify the affected code file and specific lines that causing error, make necessary correction and then make a new commit before merging these branches again. Make sure latest changes are made on the file that we want to keep.\n\n\nHow to avoid\nThere are few ways to avoid merge conflict, the simplest way is make sure changes are made on different lines, or different files, to ensure not introduce any ambiguity lines. Secondly, make sure the local branch or the branch that currently working on is updated before make any changes.\n\n\n\n\nRecommended Practices\nHere are some recommended practices [^deepsource]7 for version control.\n\nAdhere to templates when opening an issue\nIt is a good practice for version control to check on the documentation in open software repository if the repository consists of CONTRIBUTING.md file. This file usually is in the root directory which describing how others can contribute to the project.\nMake clean, single-purpose commits\nIt is better to commit the changes with single purpose instead of commit combined changes at single time. For example, we prefer push the changes for bug fixing and feature adding in different commits.\nWrite meaningful commit messages\nIt is always best and easy practice to commit the changes with descriptive commit messages. A good commit message gives reviewer a clear and insightful description about what has been changed.\nCommit early, commit often\nOther than single-purpose commits, commit early is also one of the good practice. Commit the work more often and in small chunk will help the repository keep updating and avoid conflicts.\nDon’t alter published history\nIt is strongly not recommend altering the published history. As some version control tools allows to rewrite branch history, but it might cause unnecessarily confusing.\nDon’t commit generated files\nOnly commit the files that have been generated manually is also a good practice. The files that can be re-generated usually do not work with line-based difference tracking.\nRefer to issue when creating a pull request\nIf the intention of your pull request is to fix an issue in the software, it is highly recommended using a supported keyword in the pull request’s description or in a commit message. 8 Linking a pull request to an issue is certainly helpful for showing the status of fixing is in progress.\nAssign reviewers\nAssign reviewers to validate the commit before merging definitely is a good practice in contribution as it help to avoid unnecessary conflict and quality assurance.\n\n\n\nNaming Etiquette\nDeprecated terms. 9 The computer industry’s use of the terms master and slave caught everyone’s attention in the summer of 2020. Amid the many protests and the growing social unrest, these harmful and antiquated terms were no longer considered appropriate.\n“Both Conservancy and the Git project are aware that the initial branch name, ‘master,’ is offensive to some people, and we empathize with those hurt by the use of that term,” said the Software Freedom Conservancy.\nThe name master for a new repository is outdated and has been replaced by main.\nAmbiguous terms While git is the most common version control system, terms may vary between git and its alternatives.\n\n\nEthical considerations\nThe ability of anyone from the public to contribute to an open source software project creates an interesting ethical and legal situation regarding the software’s ownership. It should be clear that contributions such as fixing a typo in the documentation does not create the right to claim for (partial) ownership of the software, but the lines for more substantial contributions tend to blur fast and are often up for discussion. In general, the answer to when a contribution has altered a software enough to justify a partial transfer of ownership has to be determined on a case to case basis. Often, this process requires considering the license and contributing agreements. For example, while many repositories state for example in their contributing file that contributing includes a loss of ownership and rights of the code to the owner of the main repository, other repositories acknowledge already minor contributions, for example by assigning rights to the repository or adding the contributor’s name to a an acknowledgment file."
  },
  {
    "objectID": "open-software/lesson6-contribution.html#summary",
    "href": "open-software/lesson6-contribution.html#summary",
    "title": "Contributing to existing open software",
    "section": "Summary",
    "text": "Summary\nTo summarize, contributing to open software delivers multiple benefits to the community while also assisting in the product’s maintenance. Contributing to an open source project can help you enhance your technical abilities and get a better reputation. If you are a coder, you may typically contribute by reporting issues, resolving bugs, and creating new features. Aside from that, you can help by producing documentation, increasing the repository’s visibility, or refactoring it. Both coders and non-coders have an equal opportunity to contribute to open source software. We explained how to use the basic version control workflow, which begins with creating a repository, then making changes, publishing changes, and pulling modifications if any exist, and finally keeping track of the changes. In general, commit operations are classified as Core, External, or Mutant. Branching and merging are both important steps in version control, and merge conflicts should be avoided. We also talked about creating a list of best practices to which you can refer before contributing. Nonetheless, there are some ethical issues to keep in mind while contributing to open source software."
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#learning-objectives",
    "href": "open-data/Lesson2-Benefits.html#learning-objectives",
    "title": "Benefits of Open Data",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nCommunicate the benefits and challenges of Open data and it’s effects on science"
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#introduction",
    "href": "open-data/Lesson2-Benefits.html#introduction",
    "title": "Benefits of Open Data",
    "section": "Introduction",
    "text": "Introduction\nIn this lesson, we’ll discuss the benefits of open data and in particular its direct effect in advancing Open Science. We will also discuss details of how Open Data can impact the response of science in global emergencies, and how Open Data facilitates multidisciplinary work."
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#open-data-for-the-greater-good",
    "href": "open-data/Lesson2-Benefits.html#open-data-for-the-greater-good",
    "title": "Benefits of Open Data",
    "section": "Open Data for the greater good",
    "text": "Open Data for the greater good\nAs we mentioned earlier, data plays a significant role in our day-to-day lives. Open Data, in particular, has played a key role. If you pause and think about it, you may realize that Open Data is not only common in our society, but you might have benefited from it and used it yourself.\nHere, are some notable examples of Open Data that has positively impacted society at large:\nEach country or territory often provides open access to a variety of socioeconomic information about the population, community, and business in its jurisdiction. These data are often called census survey data which may include the aggregated statistics of gender, race, ethnicity, education, income, and health data of a community. These data are often used to understand the composition of a local neighborhood and are critical to inform decisions on resource allocation to ensure the quality of life for the community.\nThe changing climate poses a significant risk to our daily lives and has been responsible for intensifying drought, increasing flooding, and devastating fire incidents worldwide. Open data is therefore critical in providing life-saving information to adapt to the changing climate and help assess the climate risks of the place where we live. Government agencies (e.g., National Oceanic Atmospheric Administration in the U.S., UK Met Office, European Centre for Medium-Range Weather Forecasts) have been providing public access to long-term weather and climate information for decades. A more recent initiative stems from organizations developing value-added open data products to advise society on the risk of changing climate. One recent example is the flood and fire risk in the United States developed by a non-profit organization First Street Foundation"
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#open-data-for-better-open-science",
    "href": "open-data/Lesson2-Benefits.html#open-data-for-better-open-science",
    "title": "Benefits of Open Data",
    "section": "Open Data for better Open Science",
    "text": "Open Data for better Open Science\nScientific discovery and innovation stand to gain a tremendous amount from Open Data. This impact stems directly from the multiple inputs and methods developed for investigating problems. Specifically, three core components of Open Data drive this diverse scientific innovation and provide enormous societal and scientific benefits:\n\nValidation:\nOpen Data that is easily accessible by other researchers allows for scrutiny, which helps discover mistakes more quickly and ingrains confidence that the research was conducted with sound and ethical principles and methods. Evidence-based progress is important in providing confidence in the scientific results and is important for the insights drawn to inform future research.\nData that has been reviewed, maintained and scrutinized by many, as well as informed by diverse consultation, drives robust and thorough scientific pursuits.\nThis validation process is a key component of reproducibility, which is important in building on prior research. Reproducibility is the cornerstone of pushing science forward, as it is the very baseline to check results and expand upon them by introducing new experiments and questions.\n\n\nTransparency:\nBuilding on the idea of validation and scrutinization, transparency facilitates this process. It allows for early engagement with the data and ensures the data was collected with sound and ethical principles (these will be elaborated upon in lessons 3 (Responsible Open Data) & 4 (The CARE and FAIR principles).\nThis transparency allows for early intervention if there are unexpected harms. This is where the idea of multiple perspectives becomes important again. Collaboration:\nOpen datasets are made available to all (see section Inclusivity in lesson 1) - which means new, robust insights are gathered at a faster pace as mistakes can be caught more easily, expensive data collection doesn’t need to be repeated, and researchers build upon the work of their peers. For example, the first image of a black hole; Scientists recently produced the first image of a black hole in our galaxy. This achievement was only possible through open collaboration and sharing of telescope data by different observatories distributed across different parts of the world [1].\nThe data isn’t limited to those within a specific field nor exclusive to those with institutional access. Importantly, this means the data can be shared with non-traditional academic researchers such as nurses, social workers, agronomists, journalists and other communities. This allows for researchers to also derive insights from varying perspectives.\nThe scope of research can be easily expanded to derive more holistic insights. For example, the Coupled Model Intercomparison Project (CMIP) that started in 1995 paved the way to understand how climate change was impacting our daily lives by investigating factors such as malaria distribution in Africa, infrastructure and urban design as well the implications of climate change on the risk of epilepsy [2, 3].\nCollating similar data sets and performing meta-analyses on those data sets can provide a substantially improved signal that would not be possible in any one of these data sets. Additionally, this facilitates convergence across scientific disciplines, increasing the value of the research."
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#open-data-to-support-policy-change",
    "href": "open-data/Lesson2-Benefits.html#open-data-to-support-policy-change",
    "title": "Benefits of Open Data",
    "section": "Open Data to support policy change",
    "text": "Open Data to support policy change\nOpen data can lead to policy change which directly impacts the lives of communities, such as those destined to suffer first from the slow changes to the Arctic. A study, taking advantage of the OpenStreetMap data [4], helped map projected changes in the Arctic. These mappings in turn helped emphasize the need for adaptation-based policies at community and regional levels to avoid stagnation of change in the light of a sudden and dramatically worse situation fueled by climate change."
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#open-data-in-face-of-global-emergencies",
    "href": "open-data/Lesson2-Benefits.html#open-data-in-face-of-global-emergencies",
    "title": "Benefits of Open Data",
    "section": "Open Data in face of global emergencies",
    "text": "Open Data in face of global emergencies\nThe COVID-19 pandemic demonstrated to the world, in real-time, how the collective movement of researchers sharing their data (such as sharing of coronavirus genome data [5]) can lead to an unprecedented number of discoveries in a relatively short amount of time. This directly impacted radical vaccine development efforts and the timely control of the COVID-19 infection [6]. These insights will continue to pay off, with this research spurring future developments.\nData sharing has many benefits and can aid access to knowledge. However, it is also important to bear in mind where the data has come from, who should have a say in its interpretation and use, and how the data can be shared responsibly, more on that in lessons 3 & 4."
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#open-data-and-public-engagement-citizen-science",
    "href": "open-data/Lesson2-Benefits.html#open-data-and-public-engagement-citizen-science",
    "title": "Benefits of Open Data",
    "section": "Open Data and public engagement (citizen science)",
    "text": "Open Data and public engagement (citizen science)\nA citizen scientist is a citizen or amateur scientist that will collaborate with professional researchers to help gather data on a broader spatial and temporal scale than the researchers might be able to achieve on their own [7, 8]. This outsourcing of responsibility helps members of the public engage in scientific pursuits that ultimately benefit them and allow research to be conducted on a grander scale than that might be possible with only professional researchers. Citizen science is gaining popularity, with increasing recognition as a valuable contribution to scientific advancements [9].\nFor example, volunteer citizen scientists in Beirut were recruited from 50 villages to help test water quality [10]. These volunteers were trained to be able to conduct the tests and in turn, not only was the data collected to inform the scientific advancements, the citizen scientists had the opportunity to learn to better manage their water resources and were able to improve conditions, creating a mutually beneficial interaction."
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#open-data-and-decolonisation-of-knowledge",
    "href": "open-data/Lesson2-Benefits.html#open-data-and-decolonisation-of-knowledge",
    "title": "Benefits of Open Data",
    "section": "Open Data and decolonisation of knowledge",
    "text": "Open Data and decolonisation of knowledge\nFree distribution of knowledge gives rise to increased participation in science. Open Data is central to fostering science that is inclusive and diverse, with direct and relevant benefits to impacted individuals and communities. This fostering is particularly important in the mission towards the decolonisation of knowledge [11].\nIn a world where knowledge can be a commodity, with currency in the form of published papers and hoarded datasets, exclusion from research can limit progress and negatively impact a community’s progress in a world driven by a knowledge-based economy.\nOpen Data, and its positive side effect of decolonisation of knowledge, promotes and benefits from diverse perspectives through purposeful inclusion of African, Latin American and other underrepresented Low and Middle Income Countries. This inclusion allows a dramatic change in who has access to work with and reuse data.\nIt can also become a powerful tool in the fight for visibility and credit. By fostering a global research culture of transparency and validation, where the work of underrepresented groups is celebrated and compensated, such as giving credit or much needed vaccines in exchange for the world-class genome sequencing in Africa, we will create a sustainable model that ensures under-represented countries are able to keep contributing towards a global revolution for example against infectious disease. It also gives marginalized groups such as women, under-represented communities, indigenous scholars, non-Anglophone scholars, as well as scholars from less-advantaged countries a voice in how the global and nuanced narrative of science is developed. This broad scale participation and inclusion shows respect to the involved people and communities and helps raise the profile of the research through considerate inclusion.\nHaving said that, Open Data has been demonstrated to further marginalize or exploit small-scale and community driven initiatives, such as in the case of African researchers neither receiving due credit nor compensation for their genome sequencing during the COVID-19 pandemic [12]. This is further explored in the next section as we introduce ways of mitigating harms that could happen via unthoughtful and irresponsible sharing of data."
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#summary",
    "href": "open-data/Lesson2-Benefits.html#summary",
    "title": "Benefits of Open Data",
    "section": "Summary",
    "text": "Summary\nOpen Data which is purposefully inclusive and open to scrutiny, benefits scientific innovation by allowing for a more diverse and robust scientific process that draws on multiple perspectives. This also allows for the early identification of mistaken insights as well as early intervention for unforeseen harms to impacted communities.\nOpen Data allows non-traditional researchers to contribute to scientific development and bring their unique insights to the table. With these benefits in mind, we should always bear in mind that Open Data requires careful consideration of the possible downsides of making data open without due credit and consultation with potentially vulnerable and/or marginalized communities. The next lesson discusses important considerations for the responsible management, collection and use of open data by all stakeholders."
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#assessment",
    "href": "open-data/Lesson2-Benefits.html#assessment",
    "title": "Benefits of Open Data",
    "section": "Assessment",
    "text": "Assessment\nCan you think of any examples where opening data might help you answer a question, or a question that will impact your community?"
  },
  {
    "objectID": "open-data/Lesson2-Benefits.html#references",
    "href": "open-data/Lesson2-Benefits.html#references",
    "title": "Benefits of Open Data",
    "section": "References",
    "text": "References\n\nhttps://eventhorizontelescope.org/\nhttps://oceanrep.geomar.de/id/eprint/12875/1/CMIP.pdf\nhttps://doi.org/10.1002/epi4.12359\nhttps://www.openstreetmap.org/#map=5/54.910/-3.432\nhttps://www.nature.com/articles/d41586-021-00305-7#:~:text=Other%20researchers%20say%20that%20restrictions,while%20protecting%20data%20providers\nhttps://www.nature.com/articles/d41586-020-01246-3\nhttps://www.oed.com/view/Entry/33513?redirectedFrom=citizen+scientist#eid316597459\nhttps://en.unesco.org/science-sustainable-future/open-science/recommendation\nhttps://ecsa.citizen-science.net/\nhttps://www.idrc.ca/en/book/contextualizing-openness-situating-open-science\nhttps://zenodo.org/record/3946773#.YsFyqHbMJPb\nhttps://www.nature.com/articles/d41586-021-01194-6"
  },
  {
    "objectID": "open-data/Lesson3-Responsible.html#learning-objectives",
    "href": "open-data/Lesson3-Responsible.html#learning-objectives",
    "title": "Responsible Open Data",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nRecognize open data that is created responsibly\nAppreciate how to use data responsibly"
  },
  {
    "objectID": "open-data/Lesson3-Responsible.html#introduction",
    "href": "open-data/Lesson3-Responsible.html#introduction",
    "title": "Responsible Open Data",
    "section": "Introduction",
    "text": "Introduction\nData is a precious resource that should be shared whenever possible. As demonstrated in the previous lesson, dramatic improvements can arise from Open Data and the decolonisation of knowledge by ensuring sure data is open and available to all.\nWhile Open Data benefits science in wonderful ways and already provides enormous benefits to society, the misuse and inconsiderate sharing of data can have far-reaching harmful effects. There may be also cases where the research data should not be collected nor shared publicly out of respect for the legal frameworks and communities needs. Understanding these potential harms requires reflection on the part of the research team and consultation with people and communities impacted by the research.\nIn this lesson, we introduce the concept of Responsible Open Data. These are points for consideration when thinking about making data open and managing it once it is open, as well as elaborating on ways for providing impacted communities the opportunity to drive the scientific narrative and the direct impact on their lives. In the next lesson, we will discuss a framework for actively engaging in and actioning these considerations in your research (CARE principles in lesson 4 - CARE and FAIR principles)."
  },
  {
    "objectID": "open-data/Lesson3-Responsible.html#empowering-individuals-and-communities-through-open-data",
    "href": "open-data/Lesson3-Responsible.html#empowering-individuals-and-communities-through-open-data",
    "title": "Responsible Open Data",
    "section": "Empowering Individuals and Communities through Open Data",
    "text": "Empowering Individuals and Communities through Open Data\nThe needs of marginalized and underrepresented communities can and have been ignored with respect to Open Data. Communities that are the participants, or the main drivers of some types of data collection tend to be invisible when it comes to publishing as credit is taken by the bigger academic or institutional researchers.\nSome of the notable factors that contribute to the exploitation of marginalized and underrepresented communities, oftentimes leading to disastrous outcomes including inappropriate use and sharing of data, include:\n\nLack of protective frameworks:\nThere are instances where it might not be appropriate to share data openly. For example, there are legal frameworks on a regional, national and international level to take into account; however, these might not always be sufficient to protect contributors and communities from exploitation. It is also important to note that there may be instances where no such frameworks exist, and people as contributors to the content of the data might be open for exploitation. In any case, whether a framework exists or not, careful, frequent, and ongoing communication and direct involvement of communities/contributors in any data decisions is needed, or a blanket ban should be assumed where consultation is not feasible.\n\n\nLack of proper informed consent:\nInformed consent is an essential step in ethical research practices and is a responsibility for researchers to fulfill before the research takes place. Informed consent allows participants to participate fully, with a complete understanding of the research, without coercion or undue influence. This consent can be withdrawn at any time, without consequence [1]. While an exceptionally important component of science and open science in general, the exact requirements for obtaining informed consent are highly discipline specific and understanding these nuances are beyond the scope of this work.\nWith this in mind, it is important to understand that even if one has obtained true informed consent, it is not a once-off action. It requires consultation and education. This is important in the context of data being put online for use and reuse - especially seeing as research and its impact changes over time, and as such, communities could be opened up to unexpected harms in the future. Therefore measures need to be in place so that this consent can be withdrawn or altered without consequence to the communities at risk. This understanding needs to be ensured, as a lack of understanding can be demonstrated in the open data 1000 Human Genomes consortium’s consent form [2]: the consent form has a passage most don’t catch, but open themselves to biocolonialism by agreeing to have their blood samples used for an unlimited supply of DNA.\n\n\nLack of equitable participation:\nOpen Data that is shared with due consideration and consultation allows impacted communities to take charge and guide research in a way that best suits their narrative, values and needs. It allows more autonomy in these communities to further their scientific development and to contribute to the larger field of open science."
  },
  {
    "objectID": "open-data/Lesson3-Responsible.html#managing-research-data-responsibly",
    "href": "open-data/Lesson3-Responsible.html#managing-research-data-responsibly",
    "title": "Responsible Open Data",
    "section": "Managing Research Data responsibly",
    "text": "Managing Research Data responsibly\nMany research disciplines work with personal data that can be used to identify an individual (see [3]). This type of data cannot be shared easily, as data should be anonymized before doing so, and this is increasingly difficult in the current rapid state of development. New technical progressions may make it easier to recombine datasets and re-identify individuals. Some individuals or communities are more susceptible to exploitation, as described earlier.\nThe accidental detrimental effects of Open Data may extend beyond individuals and affect others; i.e., endangered species or natural resources that should be protected [4], for example; the local extinction of Goniurosaurus luii (Chinese cave geckos) in Vietnam was attributed to poaching activities which occurred shortly after data related to their discovery was published, this, in turn promoted a call for scrutinizing Open Data sharing practices in the field of biodiversity [5].\nAdditionally, research can be carried out in collaboration with industry, generating commercially sensitive data, which may place restrictions on what can be shared. Research can be used for harmful purposes (see Ethos, lesson 2) or pose a risk to (inter)national security.\nThere are several tools available that will help making decisions about what you can share publicly:\n\nCARE and FAIR principles (lesson 4)\n(inter)national laws that apply to data sharing (lesson 6 - Sharing Open Data)\nGuidelines/policies set up by your discipline or research institute (lesson 6 - Sharing Open Data)\nLicense restrictions (lesson 6 - Sharing Open Data)"
  },
  {
    "objectID": "open-data/Lesson3-Responsible.html#summary",
    "href": "open-data/Lesson3-Responsible.html#summary",
    "title": "Responsible Open Data",
    "section": "Summary",
    "text": "Summary\nIn summary, you may not always be able to share the research data openly and there may be other responsibilities that are associated with managing the data if it has been made open. In such instances, the focus is placed on controlled and limited access with reuse in mind.\nThe CARE principles, presented in the next lesson provide a framework for responsibly collecting data with all stakeholders in mind. The FAIR (Findable, Accessible, Interoperable, Reusable) principles, also described in the next lesson, provide guidelines for this and allow you to share part of the data without necessarily disclosing all the data."
  },
  {
    "objectID": "open-data/Lesson3-Responsible.html#assessment",
    "href": "open-data/Lesson3-Responsible.html#assessment",
    "title": "Responsible Open Data",
    "section": "Assessment",
    "text": "Assessment\n\nCan you think of a specific example in which releasing data could lead to harm? Which people and/or communities might you consult to determine this and discuss remedies?\nExample of how one can re-identify a person from shared data?"
  },
  {
    "objectID": "open-data/Lesson3-Responsible.html#references",
    "href": "open-data/Lesson3-Responsible.html#references",
    "title": "Responsible Open Data",
    "section": "References",
    "text": "References\n\nhttps://researchsupport.admin.ox.ac.uk/governance/ethics/resources/consent#:~:text=Informed%20consent%20is%20one%20of,before%20they%20enter%20the%20research.\nhttps://www.internationalgenome.org/sites/1000genomes.org/files/docs/Informed%20Consent%20Form%20Template.pdf\nhttps://the-turing-way.netlify.app/reproducible-research/rdm/rdm-personal.html\nhttps://doi.org/10.1038/s41559-018-0608-1\nhttps://doi.org/10.1126/science.aan1362"
  },
  {
    "objectID": "open-data/Lesson4-CARE&FAIR.html#learning-objectives",
    "href": "open-data/Lesson4-CARE&FAIR.html#learning-objectives",
    "title": "CARE & FAIR Principles",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nRecognise the relationship between FAIR, CARE and Open Data"
  },
  {
    "objectID": "open-data/Lesson4-CARE&FAIR.html#introduction",
    "href": "open-data/Lesson4-CARE&FAIR.html#introduction",
    "title": "CARE & FAIR Principles",
    "section": "Introduction",
    "text": "Introduction\nIn the previous lesson on Responsible Open Data, we acknowledged that you may not always be able to share the research data openly. This lesson will introduce you to two sets of principles that provide a framework for responsible open data. The CARE principles may help you to responsibly collect and share data. If you are able to make (part of) the data openly available, it is helpful to do this in a manner that facilitates reuse by yourself and others. The FAIR principles provide guidelines for this, and allow you to share part of the data without necessarily disclosing all the data. After this lesson, you’ll be able to understand the relationship between FAIR, CARE and Open Data."
  },
  {
    "objectID": "open-data/Lesson4-CARE&FAIR.html#care-principles-of-indigenous-data-sovereignty",
    "href": "open-data/Lesson4-CARE&FAIR.html#care-principles-of-indigenous-data-sovereignty",
    "title": "CARE & FAIR Principles",
    "section": "CARE Principles of Indigenous Data Sovereignty",
    "text": "CARE Principles of Indigenous Data Sovereignty\nThe CARE Principles of Indigenous Data Sovereignty apply whenever you’re collecting data with or that belong to a particular community. The CARE principles are people– and purpose-oriented, and are originally set up to use data in a way that advances data governance and self-determination among Indigenous Peoples [1]. The principles are applicable to any research that involves communities or local stakeholders and cover:\n\nCollective Benefit: data must facilitate collective benefit to achieve inclusive development and innovation, improve governance and citizen engagement, and realize equitable outcomes.\nAuthority to control: Recognition of the rights of (Indigenous) communities to govern data\nResponsibility: nurture respectful relationships with the communities from whom the data originate\nEthics requires representation and participation of Indigenous Peoples, who must be the ones to assess benefits, harms, and potential future uses based on community values and ethics.\n\nThe Global Indigenous Data Alliance has made further resources available and translated the CARE principles in other languages [2]. The genomic research community has also worked on a framework for enhancing ethical genomic research with Indigenous communities [3].\nIndigenous scientists have already written extensively of the harms visited upon indigenous communities through promises of medical benefits that have never materialized and sharing of genomic data without tribal consent [4, 5, 6]. Whenever you are handling data that belongs to an indigenous or other under-served community, the CARE principles are more important than the benefits of Open Data. Developments are currently underway to provide practical guidelines or ways to assess whether the CARE principles have been followed throughout the research process.\nThe CARE principles are complementary to the FAIR principles which were developed to facilitate data sharing practices."
  },
  {
    "objectID": "open-data/Lesson4-CARE&FAIR.html#fair-findable-accessible-interoperable-reusable",
    "href": "open-data/Lesson4-CARE&FAIR.html#fair-findable-accessible-interoperable-reusable",
    "title": "CARE & FAIR Principles",
    "section": "FAIR (Findable, Accessible, Interoperable, Reusable)",
    "text": "FAIR (Findable, Accessible, Interoperable, Reusable)\nThe FAIR principles for scientific data management and stewardship are guidelines to improve the Findability, Accessibility, Interoperability and Reusability of digital assets [7]. A dataset that is FAIR is not necessarily Open. The phrase “as open as possible, as closed as necessary” [8] is often used to describe the interaction between the principles. Thus a dataset describing fishery locations might not be open (due to the harm caused by illegal fishing), but could be FAIR with a rich metadata record available and an identifying persistent ID. Datasets can be FAIR, but closed, because of personal data or because they fall under other ethical precepts that would mean opening them would be harmful (Lesson 3 - Responsible Data).\nThe FAIR Data Principles emphasize both human and machine readability and machine-actionability for data as research becomes more dependent on computation and automation [9]. For example a PDF version of a spreadsheet is human readable, but it is not easily used by machines. A better format for both humans and machines would be a structured data format like CSV or XML.\n\nFAIR principles explained\n\nFindable: It is important that data is not only open but also Findable, by you and others in your field. If people from your community of practice can not find it, it will not be used frequently and its value will decline over time. Depositing your data in repositories will preserve it over time (see Lesson 6, Sharing Open Data for more on repositories) and assign datasets with a persistent identifier (PID). Sharing data using a data repository will ensure that data are uniquely identifiable, and searchable. Another aspect that helps with searchability is having robust documentation (sometimes called data dictionaries/codebooks, metadata or a README file). Images, large files and binary data are examples of data that can not be searched by machines or humans. Providing metadata that is searchable is particularly important in these cases [10].\nAccessible: Once someone has found your data, they should be able to access the data using standardized mechanisms (e.g. https). Your data should be accessible (both retrievable and understandable) for both humans and machines. In other words, specify what the users need to do to access this data, and ideally, a machine can automatically translate those requirements and act on it (such as two factor authentication or request access from the author). Accessible does not equate to open. If the full content can not be made openly available, the metadata can be made openly available [10].\nInteroperable: During reuse, data may need to be integrated with other data, allowing machines and humans to interpret and use the data in different settings. Metadata must be detailed enough for data to be understood, especially by those who do not own or create the data in the first place. Keep in mind that people can have a hard time interpreting another person - some words can be different in spoken and formal languages; things get lost in translation, and many different terms can describe the same object. The same word can even have different meanings across various disciplines. The use of controlled terminologies, vocabularies, and ontologies for interoperability helps ameliorate otherwise substantial barriers to interoperability [10].\nReusable: To be reusable, data and collections should have a clear usage license and provide accurate information on provenance. Provenance metadata provides context and details on the history of the source and its authenticity. Credit attribution (citation) is another important aspect to consider with regard to (re)usability and “paying it forward” to the researcher who released their data [10], more on that in lesson 6 (Sharing Open Data)."
  },
  {
    "objectID": "open-data/Lesson4-CARE&FAIR.html#summary",
    "href": "open-data/Lesson4-CARE&FAIR.html#summary",
    "title": "CARE & FAIR Principles",
    "section": "Summary",
    "text": "Summary\n\nFAIR in short: Make your data as FAIR as possible by:**\n\nDepositing your data in a repository that can:\nAssign a PID\nMake sure the metadata will always be available even if the data isn’t\nUsing a standard data format for your domain\nAssign an appropriate license to your dataset\nDescribe your data as richly as possible\nFAIR is not FAIR without due CARE\n\nIt is easier to adhere to the CARE and FAIR principles when you plan for this at the start of your research, the topic of the next lesson."
  },
  {
    "objectID": "open-data/Lesson4-CARE&FAIR.html#assesment",
    "href": "open-data/Lesson4-CARE&FAIR.html#assesment",
    "title": "CARE & FAIR Principles",
    "section": "Assesment",
    "text": "Assesment\n\nConsider a dataset that you contributed to. Have you followed the CARE/FAIR principles? Which of the principles can you incorporate in your workflow?\nWhen you reviewed datasets generated and shared by other researchers, were they following the CARE/FAIR principles? What did they do well and where could they improve?\n\nWant to do a more extensive assessment on your knowledge of the FAIR principles? Beginners can use FAIR-Aware, and if you’re already more familiar you can try the ARDC self assessment tool."
  },
  {
    "objectID": "open-data/Lesson4-CARE&FAIR.html#references",
    "href": "open-data/Lesson4-CARE&FAIR.html#references",
    "title": "CARE & FAIR Principles",
    "section": "References",
    "text": "References\n\nhttp://doi.org/10.5334/dsj-2020-043\nhttps://www.gida-global.org/care\nhttps://doi.org/10.1038/s41467-018-05188-3\nhttps://www.nature.com/articles/s41576-019-0161-z\nhttps://doi.org/10.1080/15265161.2021.1891347\nhttps://doi.org/10.1038/d41586-021-00758-w\nhttps://doi.org/10.1038/sdata.2016.18\nhttps://ec.europa.eu/research/participants/data/ref/h2020/grants_manual/hi/oa_pilot/h2020-hi-oa-data-mgt_en.pdf\nhttps://www.go-fair.org/fair-principles/\nhttps://doi.org/10.5281/zenodo.6532282"
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#learning-objectives",
    "href": "open-data/Lesson5-Planning.html#learning-objectives",
    "title": "Planning for Open Data",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand what the data life cycle is and how that affects the outlook on research.\nUnderstand what a Data Managment Plan (DMP) and metadata are.\nHave an initial grounding on what communities to contact for support in this area."
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#introduction",
    "href": "open-data/Lesson5-Planning.html#introduction",
    "title": "Planning for Open Data",
    "section": "Introduction",
    "text": "Introduction\nIn the previous lessons it has been shown that effective open data needs to be managed. As we have seen this is not trivial and requires work and preparation. Correspondingly, there can be cost implications for your institutions to do this. Rather than facing these issues on an ad hoc basis, one should plan and prepare what you will need to do before you generate the data. With this in mind, we will\n\ndiscuss the data life cycle which places a focus on the reuse of data as it is generated.\nIntroduce the concept of a data management plan, where one documents the steps that will be carried out to ensure that your data can be shared in an appropriate fashion.\nIntroduce the concept of metadata, namely documenting your data which is essential if another researcher is to make use of your data.\nFinally, who to contact in terms of advice and support."
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#planning",
    "href": "open-data/Lesson5-Planning.html#planning",
    "title": "Planning for Open Data",
    "section": "Planning",
    "text": "Planning\n\nThe data life cycle\nWith a focus on generating papers, a researcher implicitly ended up with the following research workflow model in mind of how they worked with their data. It’s important to note here that because the focus is on the paper, there’s no thought to how the data changes at different stages of the process, or thought to how the data should be managed after a paper is published. Usually the data were included as part of the paper as a supplementary file.\nThis can be summarized in the following image.\n\n\n\n\n\nLinear workflow focussed on publications\n\n\nFigure 5.1: Linear workflow model\nOn the other hand, if one thinks of open data that can be FAIR (and thus reused) then this model emerges. In particular that Data needs to be available beyond the publication of a paper. Data no longer has to be associated with one paper. Data can be reanalysed. More data, from different sources or the same lab, can be added in at any time, including later. Instead of the process being a linear progression, with a start and a finish, the process for data becomes more complex and there is cycle. These ideas were put together in the DCC Curation Lifecycle model [1]. The original life cycle is complicated but a summary of the life-cycle is listed below\n\n\n\n\n\nThe DataOne Data life cycle\n\n\nFigure 5.2: A summary of the data life cycle (reproduced from https://old.dataone.org/data-life-cycle)\nHere the focus is very much moved away from the idea of research -> publication and instead is on the data itself as a first class research output.\nLet’s look at these individual steps\n\nPlan: a description of the data that will be compiled, how the data will be managed and made accessible throughout its lifetime.\nCollect: this corresponds to the data gathering step (illustrated in Figure 5.1). It can include both primary (raw) and processed data.\nAssure: the quality of the data is assured through checks and inspections.\nDescribe: data is accurately and thoroughly described through documentation (e.g. metadata).\nPreserve: these are the steps necessary to make sure that the data will be accessible going forward so in particular ensuring that the data is stored in a fashion that others can use it (in particular storing at a data repository). Ideally this should be done in a fashion that matches the CARE and FAIR principles (lesson 4). This may also include the step of removing data that may not be of use to future researchers. For example, high resolution images may no longer be themselves useful if in the analysis step one has extracted the features of interest from them. Not storing the high resolution image and simply storing the feature data would provide a considerable saving of storage.\nDiscover: here other researchers can extract either the entirety or some subset of the data for their own purposes.\nIntegrate: data from disparate sources are combined to form one homogeneous set of data that can be readily analyzed (this could include this one data set being analyzed).\nAnalyze: corresponds to the data analysis step as illustrated in Figure 5.1. There are a variety of different interpretations of the data life-cycle (see the reading list for this lesson) with varying degrees of complexity. It’s also important to note that this is an idealization of what goes in general. Nonetheless, it is important to think of all these steps as an ongoing, interactive process that requires thorough planning and continued consideration and to recognize that they are non-trivial to do."
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#data-management-plans-dmp",
    "href": "open-data/Lesson5-Planning.html#data-management-plans-dmp",
    "title": "Planning for Open Data",
    "section": "Data Management Plans (DMP)",
    "text": "Data Management Plans (DMP)\nSeeing as the above steps are not trivial before one begins to gather, collate or generate a data set it is useful to plan out what you will do with the data. This is referred to as a Data Management Plan or DMP for short.\nA DMP means that you can think ahead of any particular issues that might crop up in terms of handling the data, such as the potential cost of storage, whether data needs to be anonymised and so on.\nA detailed description of what one should put into a DMP is described here [3]. As outlined in this document from the UKRI [4], the central funder for the UK, these can include answering questions such as\n\nWhat type of data will be generated or preserved? This could include data formats, rough estimates of the amount of data to be stored during a research project and similarly what will be preserved beyond the lifetime of the project?\nWhat type of metadata will be used and preserved. It is worth noting that one of the more detailed aspects of the FAIR principles is to keep the metadata of the data set available even if the original data set no longer exists.\nWhere should the data be preserved? i.e. what repository will be used (repositories are discussed in the next lesson). How long should it be stored? (five years? ten years?) More concretely, data regulations can require that certain data be kept in certain ways for at least a certain amount of time. This will vary depending on the type of data (e.g. medical records, population statistics). It is advised that these expiration dates are explored in the literature, and/or policy guidelines.\n\nHow will any private data be stored so that it is kept securely?\n\nDMPs are not meant to be exhaustive documents! Typically they are 1-2 pages of A4 and often are less than a few thousand words. The important point is that they sketch out what a researcher or research team plans to do with their data well before they are gathered and can identify any steps that need to be taken rather than facing a major challenge now.\nDMPs are increasingly used by funders and their institutions as a means to have researchers map out what they will do with their data in a research proposal. Research proposals often require DMPs, and hence DMPs are often the ‘sharp end of the stick’ for researchers with respect to Open Science [5]. A good DMP is a criterion for assessment in grant applications and hence doing a good DMP will help your grant be funded."
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#documenting-your-data-metadata",
    "href": "open-data/Lesson5-Planning.html#documenting-your-data-metadata",
    "title": "Planning for Open Data",
    "section": "Documenting your Data (Metadata)",
    "text": "Documenting your Data (Metadata)\nAs discussed in the previous lessons, the FAIR principles emphasize the importance of metadata, namely documenting your data. Metadata is described in more detail here [6].\nA perennial question is what type of metadata and description of the data should be provided for a data set. If you are dealing with electronic data should one provide metadata for a whole set of files, an individual file … each individual bit?\nThe simplest rule of thumb is if there aren’t any guidelines for your type of data or domain repositories, then try and provide enough documentation about your data that you would ask for if you were downloading this data yourself.\nFor example if this was data taken from a field trip where location is important then you might want to include longitudinal and latitudinal coordinates. If it’s data from a wet lab then it might include parameters you normally include in the materials and methods section of a paper. If it’s data from purely computational work you may want to list the software run and the parameters used.\nData repositories will be discussed in the next lesson. Domain specific repositories will often give more precise requirements on metadata (another reason to use them).\nIf there are no guidelines then a simple README file attached with the data is a start (for an example see here) - though it’s important to note that ideally one should use metadata schema which is described in much more detail here as FAIR data should be machine-actionable [7] [8]."
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#help",
    "href": "open-data/Lesson5-Planning.html#help",
    "title": "Planning for Open Data",
    "section": "Help",
    "text": "Help\nMuch of the ins and outs of dealing with Open Data, or more particularly Open Data that follows good practice such as the FAIR principles, can be technical and lies beyond the domain of knowledge of researchers. How does one navigate this landscape?\nThis can be summarized in the following diagram -\n\n\n\n\n\nFigure 5.3 Diagram pointing to four possible sources of informaiton a researcher can approach.\n\n\nFigure 5.3 Sources of information and support on Open Data that a researcher could access.\n\nResearch communities (international and national)\nIndividual research disciplines may already have put together materials and have advice on how to implement Open Science in their discipline. For example FAIRsharing is a educational and information resource on data and metadata standards [9]. The Research Data Alliance have a variety of different interest and working groups in data sharing in specific disciplines. Scientific Societies and Publishers can also provide advice [10] [11].\n\n\nOpen Science related communities\nThere are a number of communities that are focussed on Open Science activities. ReproducibiliTea is a grass-roots journal club initiative that is based in over 100 institutions and is a forum to discuss reproducibility, closely allied to Open Science [12]. The FAIRdata forum allows you to browse materials and raise questions that are related to FAIR [13]. Correspondingly the PID forum allows you to ask questions on PIDs in general [14]. A list of Open Science communities is provided in the next module (Open Tools).\n\n\nTools and resources\nFinally, there are a range of different tools to help you. For example, DMPtool and DMPonline allow you to build your own DMPs [15] [16]. See the module Open Tools for more details. There are a variety of different catalogs out there one can use to search for materials in this area. Shanahan, Hoebelheinrich and Whyte (2021) have a table of catalogs to search for materials [17].\n\n\nLocal library or IT services\nThe long term vision is that Higher Education Institutions (HEIs) or Research Performing Organisations (RPOs) will employ data professionals to advise and support researchers [18]. These individuals have a variety of possible job titles such as Data Librarian, Data Steward, Data Curator and so on. These individuals would advise on aspects on how to make your data adhere to the CARE and FAIR principles, providing appropriate metadata and so on. Some HEIs/RPOs have already made Open Science (or Open Research) policy statements and may not yet have an infrastructure to help but will be interested in supporting you. In some countries there has been progress in this area but it is very early days. Nonetheless, it is worth contacting your University library as they may be able to advise you even on relatively small questions or requests."
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#summary",
    "href": "open-data/Lesson5-Planning.html#summary",
    "title": "Planning for Open Data",
    "section": "Summary",
    "text": "Summary\nMaking data open is not trivial. It is not simply a matter of placing a data set onto a cloud drive. Nonetheless, if it is done correctly then the open data is available for reuse. Reuse can be a completely different research team or it could be the same research team that need to carry after a member of the team responsible for the data has moved on. This means one has to think of the data as part of life-cycle and that it is important to make plans (a Data Management Plan) prior to creating the data to ensure that it is stored appropriately. Part of making your data FAIR is provide metadata that describes the data that you are depositing. Finally, do not feel that you have to do all this from scratch. There are a variety of different avenues that you can approach, either on an online basis or sometimes on your own campus."
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#assessment",
    "href": "open-data/Lesson5-Planning.html#assessment",
    "title": "Planning for Open Data",
    "section": "Assessment",
    "text": "Assessment\nThink about the data sets that were described in lesson 1 as examples of good data.\n\nCan you identify what were the above steps with that data?\n\nThink now about a data set in your own discipline.\n\nWhat would be the steps that you would need to take with that data to match up with the data life cycle?"
  },
  {
    "objectID": "open-data/Lesson5-Planning.html#references",
    "href": "open-data/Lesson5-Planning.html#references",
    "title": "Planning for Open Data",
    "section": "References",
    "text": "References\n\nHiggins, S. ,”The DCC Curation Lifecycle model”, Intl. J. Digital Curation, 3 (1), 2008, DOI 10.2218/ijdc.v3i1.48\nhttps://old.dataone.org/data-life-cycle\nhttps://the-turing-way.netlify.app/reproducible-research/rdm/rdm-dmp.html\nhttps://www.ukri.org/councils/stfc/guidance-for-applicants/what-to-include-in-your-proposal/data-management-plan/\nhttps://dmptool.org/public_templates\nhttps://the-turing-way.netlify.app/reproducible-research/rdm/rdm-metadata.html\nhttps://cornell.app.box.com/v/ReadmeTemplate\nhttps://www.dcc.ac.uk/guidance/standards\nhttps://fairsharing.org/\nhttps://www.rd-alliance.org/\nhttps://www.rd-alliance.org/groups\nhttps://reproducibilitea.org/\nhttps://fairdataforum.org/\nhttps://pidforum.org/\nhttps://dmptool.org/quick_start_guide\nhttps://dmponline.dcc.ac.uk/\nShanahan, H., Hoebelheinrich, N., & Whyte, A. (2021). Progress toward a comprehensive teaching approach to the FAIR data principles. Patterns, 2(10), 100324. https://doi.org/10.1016/j.patter.2021.100324\nPlomp, E., Dintzner, N., Teperek, M. & Dunning, A., (2019). “Cultural obstacles to research data management and sharing at TU Delft”, Insights, 32(1), http://doi.org/10.1629/uksg.484"
  },
  {
    "objectID": "open-data/contributors.html",
    "href": "open-data/contributors.html",
    "title": "OpenSciency Open Data: Authors",
    "section": "",
    "text": "Jannatul Ferdish\nhttps://github.com/Jannatul-Ferdush\nSiobhan Hall\nhttps://github.com/smhall97\nhttps://twitter.com/smhall97\nPauline Karega\nhttps://orcid.org/0000-0001-7974-048X\nhttps://github.com/karegapauline\nhttps://twitter.com/KaregaP\nSteven Klusza\nhttps://github.com/smklusza\nAndrea Medina-Smith\nhttps://orcid.org/0000-0002-1217-701X\nhttps://github.com/andreamedinasmith\nEsther Plomp\nhttps://orcid.org/0000-0003-3625-1357\nhttps://github.com/EstherPlomp\nhttps://twitter.com/PhDToothFAIRy\nYuhan (Douglas) Rao\nhttps://orcid.org/0000-0001-6850-3403\nhttps://github.com/geo-yrao\nhttps://twitter.com/douglas_rao\nHugh Shanahan\nhttps://orcid.org/0000-0003-1374-6015\nhttp://www.shanahanlab.org/"
  },
  {
    "objectID": "open-tools-resources/lesson1-intro-open-science-tools.html#introduction-to-open-science-tools.",
    "href": "open-tools-resources/lesson1-intro-open-science-tools.html#introduction-to-open-science-tools.",
    "title": "Open Science tools",
    "section": "Introduction to Open Science tools.",
    "text": "Introduction to Open Science tools.\n(What are Open Science tools? Why use Open Science tools? How do Open Science tools fit into the research lifecycle?)\nThis lesson is the first of OpenCore Module 5: Open Science Tools and Resources. This Module provides a collection of tools that are available to increase the visibility and discoverability of your project. It complements the previous OpenCore Modules (Ethos of Open Science, Open Data, Open Software, and Open Results) by enhancing the practical implementation of the Open Science concepts explained previously. While earlier modules focused on the concepts, advantages, and disadvantages of responsible Open Science practices, this module will focus more on the practical applications of responsible Open Science practices. We focus on a few key tools, and highlight how they fit across the research lifecycle.\nIn this first lesson, you will be introduced to the _What _and the Why of Open Science tools. First, we provide a definition of Open Science tools. Second, we discuss the differences between ‘open’ and ‘closed’ tools and highlight the advantages of using open tools. Third, we elaborate on the research lifecycle, and show how Open Science tools fit into a researcher’s project workflow."
  },
  {
    "objectID": "open-tools-resources/lesson1-intro-open-science-tools.html#what-do-we-mean-by-open-science-tools",
    "href": "open-tools-resources/lesson1-intro-open-science-tools.html#what-do-we-mean-by-open-science-tools",
    "title": "Open Science tools",
    "section": "What do we mean by “Open Science tools”?",
    "text": "What do we mean by “Open Science tools”?\nWe use the word “tools” to cover any type of resource or instrument that can be used to support your research. In this sense, tools can be a collection of useful resources that you might consult during your research, a software that you could use to create and manage your data, or even a human infrastructure, such as a community network that you could join to get more guidance and support on specific matters.\nIn this context, Open Science tools are any tools that enable and facilitate openness in research, and support responsible Open Science practices. It is important to note that Open Science tools are very often open source and/or free, but not necessarily."
  },
  {
    "objectID": "open-tools-resources/lesson1-intro-open-science-tools.html#whats-the-difference-between-open-tools-and-closed-tools-why-use-open-science-tools",
    "href": "open-tools-resources/lesson1-intro-open-science-tools.html#whats-the-difference-between-open-tools-and-closed-tools-why-use-open-science-tools",
    "title": "Open Science tools",
    "section": "What’s the difference between ‘open’ tools and ‘closed’ tools? Why use Open Science tools?",
    "text": "What’s the difference between ‘open’ tools and ‘closed’ tools? Why use Open Science tools?\nOne can intuitively grasp the difference between open and closed in relation to the “tools”, thinking of openness in terms of exchange with the environment. One should bear in mind that it is not a black and white separation, but rather a spectrum of options.\nWhen speaking of useful resources that you can re-use - such as text, visuals, audio, video - it is important to pay attention to the license on the possibilities and conditions for re-use. Lack of indication of a license leads to impossibility to re-use the material. As indicated in 🔗 Module 1 Ethos of Open Science, Lesson 5🔗, Creative Commons licenses is one of the most common set of open licenses given to written content of any kind, allowing re-use and requiring attribution, with a spectrum of openness, from least to most open (or CC0, equivalent to public domain).\nSoftware can be proprietary (“closed”) or open source. It is called open source when the original source code is made freely available and may be redistributed and modified. Generally, software has a separate set of licenses designed specifically for code projects that covers both the open distribution of the code itself as well as executable versions of the program which non-programmers can run. More information and details on open software can be found in the 🔗Open Software Module🔗.\nHuman infrastructure refers to a network of relationships between stakeholders interested in the conduct and outcomes of responsible Open Science (more on those stakeholders can be found in 🔗Module 1, Lesson 3🔗). Communities – or groups of people who share a geographical location, affiliation, common interest, or practice – play a key role in the human infrastructure aspect of open science. As everything else, communities can vary in their degree of openness. A community can take the form of a mailing list, conference, meet-up or messaging app as a way to stay in touch. In that case, being open would imply that anyone could join the community and be welcomed to speak, decisions would be made transparent, and communications are largely public. On the other hand, a closed community implies that membership is restricted by invitation and/or a fee, resources and communications are not public, and decision processes are not necessarily transparent. More ideas on how to increase participation of stakeholders and how to build and lead inclusive communities can be found in 🔗Module 1, Lesson 3🔗 and 🔗this module, Lesson 4🔗.\n\nActivity/exercise\nNow let’s practice by looking at some typical case studies and solutions, reflecting on the benefits and obstacles of open and closed tools.\nCase study #1: Closed vs open resources\nCase study #2: Closed vs open software\nYou are a researcher who has been using a proprietary MATLAB platform to analyze data and create models. You are getting a new job, at a different institution. Unfortunately, the new workplace does not have a license for MATLAB, therefore you cannot access your own code and data, stored in the proprietary file formats, and moreover, cannot continue your routine workflow with analysis. What are your options now?\n\nYou can purchase individual license for this proprietary software, or persuade the institute to purchase a group or campus-wide license\nYou could consider using open source alternatives for programming and numerical computing, such as GNU Octave, Sage, or even Python programming language and its scientific packages. It would not only save you money now, but provide the continuity of the tool - if you move again, to a different institution.\n\nCase study #3: Closed vs open communities\n\nExample:\n\nOpen science tools provide numerous benefits, many of which have been discussed in the previous modules. For example, they can help you collaborate openly and share easily; organize and manage your work; track how your work is treated and shared; and follow leading responsible Open Science practices.\nOpen Science practices enable easier access to existing tools and resources that promote collaboration between professionals with similar interests and research objects. For example, someone in Asia wanting to study Central African rainforest species could visit an online species database made available by other scientists. Despite their physical distance, many reasons lead to inequality in access to scientific resources, from institutional barriers to paid content.\nThere are efficient and coordinated ways to share resources in general. One of them is using 📖version control 📖, which is a system to keep track of any changes made to one or more files over time. That also serves as a backup for your work.You might have already done that – for example, if you ever used Google Docs. It stores a version of your work as you type it, and you can invite other users to work collaboratively in the same document, keeping record of all changes made by all users.\nOne broadly used tool for version control is Git. It enables version control either online or on the user’s machine [see https://git-scm.com/]. Related services include GitHub, Gitlab, and Bitbucket. Information is stored in online repositories where people can clone, edit, and review each other’s content.\nAnother way to share your work is by using standardized 📖workflows📖. A standardized workflow is typically a sequence of steps commonly used for a given purpose, such as accessing and manipulating genomic data. A good open science practice, then, is to share those workflows in platforms such as https://galaxyproject.org/ – which allows any user to replay those steps right there for free, quickly and easily. That and other similar services enable you to show a step-by-step overview of what other researchers did, build on their work, and share your new ideas.\nIncluding 📖metadata📖, the data that describes your data, can significantly enhance the findability of your research object. Some examples of metadata are the keywords associated with a publication, the time range and instrument name of a given observational data set, and the ORCID number for a given person. Metadata is a tool that search interfaces use to more quickly find a resource. In fact, Google uses a metadata language called ‘Schema.org’ to build its search algorithm (see https://schema.org/ for more information).\nMany research fields have their own metadata standards (e.g. SPASE for space physics: https://spase-group.org/data/), but remember that each website you use has something similar behind that magnifying glass button. Taking the extra time to include some basic descriptors for your research object can make your contribution to your research field much more findable. The same way finding someone else’s work on the Internet might help you, making your own work more discoverable is a great contribution to Open Science!\nNext, we’ll highlight how open science tools and resources fit in the research lifecycle."
  },
  {
    "objectID": "open-tools-resources/lesson1-intro-open-science-tools.html#how-do-open-science-tools-fit-into-the-research-lifecycle",
    "href": "open-tools-resources/lesson1-intro-open-science-tools.html#how-do-open-science-tools-fit-into-the-research-lifecycle",
    "title": "Open Science tools",
    "section": "How do Open Science tools fit into the research lifecycle?",
    "text": "How do Open Science tools fit into the research lifecycle?\nThe complex nature of research in the modern scientific community – involving multiple stages, steps, contributors, and stakeholders in the process – benefits from certain frameworks and definitions to structure, organize, and somewhat standardize the research process for the sake of responsible and reproducible practices.\nThe 🔗Open Results🔗 module introduced you to the definitions and nine stages of the research lifecycle and workflow. Let’s define these terms again.\n\nResearch framework\nResearch workflow\nResearch lifecycle\n\nThere is quite some theory behind the models for research frameworks, lifecycles, and workflows (REF), including linear, circular, multi-loop, and multi-step flows. For the sake of clarity and pragmatism of mapping the Open Science tools used within the research lifecycle, we will consider a concise 6-stage spiraling model for the research workflow, covering discovery, analysis, and writing as well as publication, outreach, and assessment (see Fig.)\n\nRef:https://figshare.com/articles/presentation/Of_Shapes_and_Style_visualising_innovations_in_scholarly_communication/3468641\nMost steps of the research workflow are supported by online applications (Kramer and Bosman, 2016). These digital (Open Science) tools have actually influenced the way in which we perform and share research, opening it up to a global audience.\nOpen Science tools can be used for\n\nDiscovery: Tools for finding content to use in your research\nAnalysis: Tools to process your research output, e.g. tools for data analysis and visualization\nWriting: Tools to produce content, such as Data Management Plans, presentations, and pre-prints\nPublications: Tools to use for sharing and/or archiving research\nOutreach: Tools to promote your research\n\nThe usage of such tools by researchers across different disciplines has been surveyed and reviewed in several efforts (Kramer and Bosman, 2016, Bezuidenhout and Havemann, 2021). Numerous digital tools have been mapped on the “discovery, analysis and writing, publication, outreach, and assessment” stages of the research lifecycle (see Fig). As we saw in the previous section, all tools have varying degrees of openness. Purposefully choosing tools to use at each stage to increase transparency, findability, and reproducibility, you are able to construct and define your research workflow in alignment with responsible Open Science practices. As was discussed in Module 1, Ethos of Open Science, open should not be a thoughtless default or afterthought, but included into the design and inception of the research project. Your choice of Open Science tools can be individual, but most often it would benefit from group discussions within your research team, institution, and communities of practice.\n\nNote: the concepts of workflow and lifecycle are widely used and applied to parts of the research, e.g. data. Data workflow, data lifecycle are discussed in depth in 🔗Lesson X of the Module Open Data🔗."
  },
  {
    "objectID": "open-tools-resources/lesson1-intro-open-science-tools.html#how-do-open-science-tools-address-responsible-practices",
    "href": "open-tools-resources/lesson1-intro-open-science-tools.html#how-do-open-science-tools-address-responsible-practices",
    "title": "Open Science tools",
    "section": "How do Open Science tools address responsible practices?",
    "text": "How do Open Science tools address responsible practices?\nThe 🔗Open Data and Open Results🔗Modules introduced the concept of FAIR principles and discussed how their application according to best practices can increase the visibility and uptake of our research.\nLet’s refresh the terms:\n\nFAIR Data Principles - Findable, Accessible, Interoperable, & Reusable. Wilkinson et al. (2016) provided FAIR Guiding Principles for scientific data management and stewardship; Hong et al. (2022) establish FAIR principles for research software.\nCARE Principles - Collective Benefit, Authority to Control, Responsibility, & Ethics. Carroll et al. (2020) established the CARE Principles for Indigenous Data Governance, complementing the FAIR data principles.\n\n\nBest practices to implement these principles include describing data using metadata standards and controlled vocabularies, assigning licenses, and uploading data to repositories that allow for creation of “📖persistent identifiers📖”. Examples of useful Open Science tools include:\n\nData Management Plan (DMP) tool, which allows you to create and share your data management plans to meet funder requirements and as a best practice for managing your data (link to website, to Lessons)\nData Repositories, which assign persistent identifiers to your data (example or link)\nTools for integration research management with DMPtool and repositories (example or link)\nCommunities - national and international, discipline-specific, or open science-centered - can be of incredible value in curating resources and building communities of practice for researchers and other stakeholders in adopting FAIR principles. Examples include the FAIR Data Forum https://fairdataforum.org/ and the Research Data Alliance (RDA) https://www.rd-alliance.org/\n\nWorking within the ethos of the FAIR and CARE principles can help to ensure that research is accessible, inclusive, ethical, and responsible. More about FAIR principles and practical steps to make your data FAIR can be found here: https://www.go-fair.org/fair-principles/"
  },
  {
    "objectID": "open-tools-resources/lesson1-intro-open-science-tools.html#self-assessment-questions-for-reflection",
    "href": "open-tools-resources/lesson1-intro-open-science-tools.html#self-assessment-questions-for-reflection",
    "title": "Open Science tools",
    "section": "Self-Assessment: Questions for reflection:",
    "text": "Self-Assessment: Questions for reflection:\n\nAssessment of your (open science) tools and resources\n\nMost probably you are already using some tools and resources, even if you are new to open science practices. Here we invite you make a preliminary revision of them:\n\nThink of all the tools and resources you use in your study/research/work and rely on - resources (content with text/media), software and communities. Think of all stages of your research - discovery, analysis, writing, publication, outreach and assessment.\nTools have varying degrees of openness, dictated by various factors. Imagine (or draw) the scale from 0 to 10, where 0 stands for completely closed and 10 for completely open.\nFor which of the tools (from categories of resources, software and communities) place it on the scale on a number that reflects the degree of openness.\nHow many tools do fall towards the lower part of the scale (0 to 4)? Take a moment to reflect if these tools are in line with your actual preference, goals and necessities in the long-term run.\nPerform a quick search using search engine or this open dataset of Open Science tools (https://kumu.io/access2perspectives/dost#dataset) for more open alternatives (e.g. free, open source) and jot them down “for your information”.\n\nIn the next lessons we will introduce you to various tools, which you may not have heard yet. Stay tuned!"
  },
  {
    "objectID": "open-tools-resources/lesson2-tools-across-research-lifecycle.html#open-science-tools-across-the-research-lifecycle",
    "href": "open-tools-resources/lesson2-tools-across-research-lifecycle.html#open-science-tools-across-the-research-lifecycle",
    "title": "Open Science tools across the research lifecycle",
    "section": "Open Science Tools across the Research Lifecycle",
    "text": "Open Science Tools across the Research Lifecycle\nIn the first lesson, we briefly defined Open Science tools, distinguished open from closed tools, and highlighted the advantages of Open Science tools. We also gave a brief introduction to the Research Lifecycle, and discussed how open tools fit in this workflow. In this second lesson, we’ll highlight a few key tools for each aspect of the research lifecycle.\nIn this module, we’ll focus on the following elements of the project workflow rather than distinct research stages, because many tools support more than one stage. We will cover tools specifically for protocols; data; code; results; and authoring. We’ll only highlight a few tools; more tools and resources are currently available than we could possibly list (see Figure below).\n\nRef: http://46eybw2v1nh52oe80d3bi91u-wpengine.netdna-ssl.com/wp-content/uploads/2021/12/Data-and-AI-Landscape-2021-v3-small.jpg\n\nOpen Science tools for protocols\nIn the last decades, we have seen an avalanche of development of the tools for management of research projects and laboratories, which address the ever-increasing need for speed, innovation, and transparency. Such tools are developed to support collaboration, ensure data integrity, automate processes, create workflows and increase productivity.\nSome research groups have been adapting commonly used project management tools for their own team needs, such as Trello, a cloud-based online tool. Such software facilitates sharing materials within the group and managing projects and tasks, while allowing space for some customization.\nPlatforms and tools, which are finely tuned to meet researchers’ needs (and frustrations), have appeared as well, often founded by scientists - for scientists. To give you a few examples, let’s turn to experimental science. A commonly used term and research output is📖 protocol📖.\nProtocol can be defined as “A predefined written procedural method in the design and implementation of experiments. Protocols are written whenever it is desirable to standardize a laboratory method to ensure successful replication of results by others in the same laboratory or by other laboratories.” (REF According to the University of Delaware (USA) Research Guide for Biological Sciences)\nIn a broader sense, protocol also comprises documented computational workflows, operational procedures with step-by-step instructions, or even safety checklists.\nProtocols.io (https://www.protocols.io/) is an online and secure platform for scientists affiliated with academia, industry and non-profit organizations and agencies. It allows them to create, manage, exchange, improve, and share research methods and protocols across different disciplines. This resource is useful for improving collaboration and recordkeeping, increasing team productivity, and even facilitating teaching, especially in the life sciences. In its free version, protocols.io supports publicly shared protocols, while paid plans enable private sharing, e.g. for industry.\nSome of the tools are specifically designed for open science with an open by design idea straight from the beginning, and aim to support the research lifecycle at all stages, and allow for integration with other open science tools.\nMost prominent one includes Open Science Framework (OSF), developed by Center for Open Science (link). OSF is a free and open source project management tool that supports researchers throughout their entire project lifecycle through open, centralized workflows. It captures different aspects and products of the research lifecycle, including developing a research idea, designing a study, storing and analyzing collected data, and writing and publishing reports or papers.”\nOSF is designed to be a collaborative platform where users can share research objects from several phases of a project. It serves as support for a broad and diverse audience, including researchers that might not have been able to access so many resources due to historic socioeconomic disadvantages. OSF also contains other tools in its own platform:\n“While there are many features built into the OSF, the platform also allows third-party add-ons or integrations that strengthen the functionality and collaborative nature of the OSF. These add-ons fall into two categories: citation management integrations and storage integrations. Mendeley and Zotero can be integrated to support citation management, while Amazon S3, Box, Dataverse, Dropbox, figshare, GitHub, and oneCloud can be integrated to support storage. The OSF provides unlimited storage for projects, but individual files are limited to 5 gigabytes (GB) each.”\n(maybe a note on preregistration offered by OSF, which can be powerful)"
  },
  {
    "objectID": "open-tools-resources/lesson2-tools-across-research-lifecycle.html#open-science-tools-for-data",
    "href": "open-tools-resources/lesson2-tools-across-research-lifecycle.html#open-science-tools-for-data",
    "title": "Open Science tools across the research lifecycle",
    "section": "Open Science tools for data",
    "text": "Open Science tools for data\n“Research data means any information, facts or observations that have been collected, recorded or used during the research process for the purpose of substantiating research findings. Research data may exist in digital, analogue or combined forms and such data may be numerical, descriptive or visual, raw or processed, analyzed or unanalyzed, experimental, observational or machine generated. Examples of research data include: documents, spreadsheets, audio and video recordings, transcripts, databases, images, field notebooks, diaries, process journals, artworks, compositions, laboratory notebooks, algorithms, scripts, survey responses and questionnaires.” Ref: https://policy.unimelb.edu.au/MPF1242#section-5\nData is the one type of research object that is universal. Sharing your datasets publicly allows other researchers (and you!) direct access to the data to allow further study.\n\nTools for Data Management Plans\nEvery major research foundation and federal government agency now requires scientists to file a data management plan (DMP) along with their proposed research plan. Data as research in its whole, and as other elements (code, publication) have their own lifecycle and workflow, which needs to be in the plan. DMPs are a critical aspect of Open Science and they help keep other researchers informed and on track throughout the data management lifecycle. DMPs that are successful typically include a clear terminology about FAIR and CARE and how they will and are applied.\nThe data management lifecycle is typically circular. Research data are valuable and reusable long after the project’s financial support ends. Data reuse can extend beyond our own lifetimes. Therefore, when designing a project or supporting an existing corpus of data, we need to remain cognizant of what happens to the data after our own research interaction ends.\nThere are a few Open Science resources available to get you started and to keep you on track. The DMPTool https://dmptool.org/ in the US helps researchers by using a template which lists each funder’s requirements for specific directorate requests for proposals (RFP). The DMPTool also publishes other open DMP from funded projects which can be used for improving your own DMP. The Research Data Management Organizer (RDMO) enables German institutions as well as researchers to plan and carry out their management of research data. ARGOS is used to plan Research Data Management activities of European and nationally funded projects (e.g. Horizon Europe, CHIST-ERA, the Portuguese Foundation for Science and Technology - FCT). ARGOS produces and publishes FAIR and machine actionable DMPs that contain links to other outputs, e.g. publications-data-software, and minimizes the effort to create DMPs from scratch by introducing automations in the writing process. OpenAIRE provides a guide on how to create DMP."
  },
  {
    "objectID": "open-tools-resources/lesson2-tools-across-research-lifecycle.html#sharing-data-with-your-research-team",
    "href": "open-tools-resources/lesson2-tools-across-research-lifecycle.html#sharing-data-with-your-research-team",
    "title": "Open Science tools across the research lifecycle",
    "section": "Sharing data with your (research) team",
    "text": "Sharing data with your (research) team\n\nData repositories\nOriginally data repositories appeared in different disciplines of research around the needs of research communities and dataset types, such as Protein Data Dank (PDB) https://www.rcsb.org/ for 3D structures of proteins and nucleic acids, or Genbank - NIH genetic sequence database, containing annotated publicly available nucleic acid sequences. Another example is a public repository of microscopy bio-image datasets from published studies, The Image Data Resource (IDR) (ref). _The Electron Microscopy Public Image Archive (_EMPIAR) https://www.ebi.ac.uk/empiar/, is a public resource for raw cryo-EM images. OpenNeuro https://openneuro.org/ is a open platform for validating and sharing brain imaging data. These tools enable easy access, search, and analysis of these annotated datasets.\nAs noted in Lesson 2, open science tools such as data repositories should ensure the guidelines for FAIR data, mainly attribution of persistent identifies (e.g. DOI), metadata annotation, machine-readability.\nData repositories that include FAIR principles and work across borders and disciplines include Zenodo (https://zenodo.org/), funded by the European OpenAire project and hosted by CERN. It is probably one of the most known and widely used, as it has an easy interface, support of community curation, and allows depositing diverse types of research outputs - from datasets and reports to publications, software, multimedia content.\nThe main drawback for this choice is that Zenodo is relatively lacking in documentation and metadata; a dataset stored on this site is not as easily findable or visible to the community compared to storing the data at a domain-specific repository (e.g. EarthData: https://www.earthdata.nasa.gov/, BCO-DMO for marine ecosystem research data, or Environmental Data Initiative for environmental or ecological data), or a cross-domain repository (e.g. DataOne: https://www.dataone.org/).\nNoted exceptions to this rule include communities hosted on Zenodo that curate their materials to enhance findability (e.g. Open Science Community Saudi Arabia (OSCSA): https://zenodo.org/communities/1231231664/?page=1&size=20, Turing Way community: https://zenodo.org/communities/the-turing-way/?page=1&size=20). More on the role and power of communities will be covered in Lesson X (communities).\nAnother example of a non-profit data repository is Dataverse https://dataverse.org/, hosted by Harvard University. The Dataverse Project is an open source online application to share, preserve, cite, explore, and analyze research data, available to researchers of all disciplines worldwide for free.\nThe Dryad Digital Repository https://datadryad.org/ is a curated online resource that makes research data discoverable, freely reusable, and citable. Unlike previously mentioned tools, it operates on a membership scheme for organizations such as research institutions and publishers.\nDatacite https://datacite.org/ is another global non-profit organization that provides DOIs for research data and other research outputs, on a membership basis.\nData services and resources for supporting research require robust infrastructure which relies on collaboration. Some examples of initiatives on the infrastructures of data services include The EUDAT Collaborative Data Infrastructure (or EUDAT CDI) https://www.eudat.eu/, sustained a network of more than 20 European research organizations,\nPrivate companies as well host and maintain online tools for sharing research data and files. Figshare https://figshare.com/ is one of the examples of a free and open access service, giving a DOI for all types of files and recently developing a restricted publishing model to accommodate intellectual property (IP) rights requirements. It allows sharing the outputs only within a customized Figshare group (could be your research team) or with users in a specific IP range. Additional advances include integration with code repositories, such as GitHub, GitLab, and Bitbucket.\nGitHub https://github.com/, owned by Microsoft, is often the default data repository for coders. It allows collaborative work, version control, project management, and is widely used by researchers for uploading datasets, files, notes, hosting simple static webpages to showcase their achievements. Github does not give you a DOI, but allows you to state the license for re-use and ways to cite your work.\nMuch more research data repositories could be found in the publicly open Registry of Research Data Repositories https://www.re3data.org/. OpenAire-hosted search engine https://explore.openaire.eu/search/find/dataproviders provides a powerful search function of data and repositories, with country, type, thematic and others filters, and enables downloading of the data.\nCaution: Amount of data, repositories and different policies can be overwhelming. When in doubt, which repository is for you, make sure you consult librarians, data managers and/or data stewards in your institution, or check within your discipline-specific or other community of practice.\n\n\nOpen Science tools for code\nIf your project involves coding, such as custom analysis code, you can share it or collaborate using tools such as Jupyter Notebooks. These notebooks can be shared with a variety of permissions on JupyterLab, Google Colab, and similar websites. For a more permanent solution, you can use containerized environments to share the entire analysis environment, which includes the installed software packages, the data used, all custom analysis and plotting routines, and even the publication draft. A few examples of containerized environment services are DeepNote and Binder (DeepNote: https://deepnote.com/, Binder: https://mybinder.org/).\n\n\nCollaborative development tools\n\nCode repositories\n\nGithub\nGitLab\nBitBucket\nSourceForge\n\n\n\n\nOpen Science tools for results\n\nVisual tools for graphs, dataviz, sharing\n\n\n\nOpen Science tools for authoring\n\nCollaborative writing tools\nOne of the commonly used processes in research is creation and editing of documents, such as meeting notes, conference abstracts, manuscripts, checklists etc.\nCollaborative editing process has become really easy with online tools like Google Docs, Bit AI and others, because of their easy interface and version history. However, these tools are proprietary, so not fully open.\nOpen-source, web-based collaborative tools for editing include tools such as Etherpad https://etherpad.org/, HackMD https://hackmd.io/ and HedgeDoc https://hedgedoc.org/ (formerly known as CodiMD). These editors use a Markdown language, lightweight markup language, for creating formatted text for the web. It has a simple syntax, and therefore allows more users to be engaged and focus on content, including graphics, tables, lists. Moreover, Markdown is useful when creating documentation in GitHub, as we discussed in the previous sections, commonly used data and code repository and collaboration space.\nLaTex / TeX markup language provides a steeper learning curve, but allows much more nuanced features for scientific and technical documentation, such as formatting of books, articles, mathematical formulas etc. Collaborative online tool utilizing LaTex is called Overleaf https://overleaf.com/, and it is widely used in the research community to share and edit LaTex files.\n\n\nReference management tools\nAt the Discovery and Publication stages of the research lifecycle reference management tools are particularly useful to search for publications, collect and organize them, annotate, cite, and share. Such tools should facilitate your research workflow by easy addition/import of references, bibliography construction, adaptation to various citation styles requested by different journals/publishing houses.\n_EndNote _is a citation manager tool owned by Clarivate Analytics. However, it is proprietary software and not free for researchers (closed tool), so it is beyond our interest.\nMendeley https://www.mendeley.com/ - now owned by publisher Elsevier, is a free software with very similar functionality.\nZotero https://www.zotero.org/ is an open-source and independent organization-hosted online tool.\nBoth Zotero and Mendeley tools allow easy addition of the publication from the browser or file upload, offer compatibility with major editing tools (like Microsoft Word, OpenOffice, LaTex but not fully with Markdown-based online tools). Important feature of reference management tools is groups and collections of articles (libraries), which can be shared and therefore, provide capabilities of social networking and communication among researchers (community of practice).\n\n\nPublishing Open Science and Open Access\n📖Open Acess📖 is a set of principles and practices that make research publications freely available to anyone. Here we will focus on open access implementations both in the peer-reviewed journal publications and preprints uploaded on repositories.\nWhen the data, workflows, or any results of your investigation are ready to be shared as publications, they can be uploaded to certain open websites. Many scientific journals and websites require payment for accessing materials, but a growing number now offer open access publications where the author is charged an additional fee (e.g. AGU publications: https://www.agu.org/Publish-with-AGU/Publish/Open-Access).\nWe discourage publishing in a journal that is not open access because it prevents researchers from marginalized groups from participating in knowledge sharing. In the case of open science platforms, one can usually share research objects for free (e.g. Zenodo: https://zenodo.org/ and FigShare: https://figshare.com/). Example research objects include executable notebooks, software packages, pre-prints, figures, presentations, and datasets.\nJournals usually provide peer review for submitted manuscripts, and after acceptance and publication, there are few options to ensure an open access to the article. It is important to carefully choose the journals with suitable open access publishing models.\nHere we list different types of Open Access (OA) publishing models, how to find out which type of Open Access model journals use and where publishing costs are associated.\n\nClosed Access/Subscription Journal: This is a traditional publication, where the reader (or their institution’s library) pays a subscription fee for a year’s access to the journal contents. The Subscription can be physical and/or digital. Many journals have reduced the print copies; some are digital only and some can be print and digital, both. Subscription can also be pay-per-article instead of complete journal contents subscription.\nGold OA: This form of Open Access requires Article Processing Charge (APC), which may be paid by author(s) or a funding body. The final published version or record is immediately freely available & accessible in the journal by the publisher. The article is freely accessible under a Creative Commons license.\nGreen OA: There is an embargo period set by the journal’s publisher such as 6, 12 or 24 months. The version of the manuscript is freely available in a repository. No charges are paid.\nDelayed Open Access: In the subscription journals, the publisher provides free access to online articles at the expiry of a set embargo period.\nHybrid: In the subscription journals, author(s) have an option to make their article Open Access but it has significantly higher open access publication fee in comparison to GOLD OA journals; other articles remain toll access (articles behind paywall).\nGratis OA: Publisher(s) optionally offering articles free to read at no charge to the author. This form of OA may be temporary and may be done for promotional purposes.\nLibre OA: Publisher(s) offering articles free to read and permission to re-use, share under Creative Commons licenses.\nDiamond OA: The journals/publishers charge no fee/Article Processing Charge (APC) by author(s) to publish. The readers are also free to access and read the articles. Hence, publishers charging no fee are normally funded by external sources like learned societies, funding associations, government grants, academic institutions.\n\nCaution: There are also predatory journals and publishers, who advertise open access but are but are not part of responsible open science.\n\nOpen access doesn’t guarantee journal quality\nOpen access doesn’t imply that author(s) can pay to publish without any editorial and/or scientific review.\nOpen access does not always require payment from author(s).\n\nPlease see COPE discussion document on Predatory Publishing and refer to leading indexing databases such as Clarivate Journal master list, Scopus Journal search, DOAJ, Sherpa Romeo.\nDirectory of Open Access Booksprovides access to scholarly peer reviewed open access books.\nMany journals with Closed Access/Subscription model provide you permission to publish manuscripts on repositories, even before submitting to the journal. Such manuscripts without peer review are called 📖preprints📖. Journals usually state the policies on their websites in regards to preprints.\nSpeaking of open science tools, Sherpa Romeo platform https://v2.sherpa.ac.uk/romeo/ is a valuable online resource that aggregates publisher open access policies from around the world and provides summaries of publisher copyright and open access archiving policies in one place.\nArXiv is one of the oldest preprint repositories (since 1991), used by physicists and mathematicians. Nowadays, there are numerous preprint repositories, each for every discipline and community. Non-exhaustive list include severs of ChemRxiv – a preprint repository for papers in chemistry, BioRxiv – for preprints of research in biology and life sciences, MedRxiv – in health sciences, PsyArXiv – in psychology, SocArXiv - in social sciences, engrXiv - in engineering.\nLocal open access knowledge and dissemination is maintained and enhanced by communities servers like AfricArXiv, a community-led digital archive for African research and - the most recent - Jxiv, Japan-specific preprint repository.\nMany of country- and discipline-specific smaller “Rxivs” are run by volunteers around the world, but the servers are hosted online by the non-profit Center for Open Science. Substantial costs pose the question of sustainability of maintaining the repository, and some of the repositories like IndiaRxiv closed down but were able to relaunch.\nPreprints concept and infrastructure allow researchers to disseminate their results months to years ahead of final traditional journal publication. This definitely accelerates progress of science, which is crucial during societal challenges like e.g. COVID-2019 pandemics. However, lack of peer review is reducing the impact of the publication in terms of its rigor and credibility.\nHere we will cover some of the key tools that use community/crowd to evaluate and curate the preprints by providing transparent feedback and peer review.\n\nF1000Research https://f1000research.com/ has been the first open research publishing platform allowing for rapid publication of research articles and other outputs with transparent peer review, without editorial bias.\nPREreview https://prereview.org/ is a platform encouraging early career researchers to provide peer review to preprints, with a mission to increase equity and transparency in scholarly communications.\nASAPbio https://asapbio.org/ stands for Accelerating Science and Publication in biology. It is a major crowd-sourced peer review by scientists in the life science discipline.\nT_he PubPeer _https://pubpeer.com/ is an online platform for post-publication peer review, “online journal club”, as the founders name themselves.\nSciety https://sciety.org/ is an online platform for public evaluation of preprints, and allows self-organization of peer review groups.\n\nCase study: SciPost https://scipost.org/ is a scientific publication portal managed by the SciPost Foundation, in the hands of the academicof academic community, by scientists. It is 100% online, offers global, open access and free research publications. As of 2022, it hosts around 10 journals in disciplines of Physics, Chemistry, Astronomy and some others. Submissions can be made directly or via preprint from well establish preprint repository arXiv. The peer review is provided by professional scientists (=with PhD and beyond) - anyone could register and serve, the reviews and author responses are published as well. Unlike most publishing houses, it is entirely not-for-profit, not charging any subscription fees to its readers, not charging any publication fees to its authors. The business model is based on the sponsorship from research institutions and foundations, and all agreements and subsidy amounts are openly shared on the website. Does it seem too idealistic?\nQuestion for reflection:\n\nWhat are the limiting factors to developing and maintaining Open Science tools?\nWhat are the advantages and disadvantages for working with Open Science tools?\nWhat are your next 3 simple steps you could take to increase the openness of the research tools in your practice?\nWhat is the future of scholarly communications that embraces responsible Open Science practices? Check the Ethos Module, if necessary.\nHow does the publication workflow should look to provide the robust, rapid and transparent communication of research results - to the peers, wide scientific community, public, policymakers?"
  },
  {
    "objectID": "open-tools-resources/lesson3-tools-for-reproducibility.html#open-science-tools-for-reproducibility",
    "href": "open-tools-resources/lesson3-tools-for-reproducibility.html#open-science-tools-for-reproducibility",
    "title": "Open Science tools for reproducibility",
    "section": "Open Science tools for reproducibility",
    "text": "Open Science tools for reproducibility\nSEE CONTENT OF THIS LESSON AT https://tyson-swetnam.github.io/TOPS-OC5-tools/lesson3.html\nThis lesson is the third of the OpenCore Open Science Tools and Resources Modules. In this lesson, we take a deep dive into a few available tools for (computational) reproducibility. First, we define reproducibility. Then, …"
  },
  {
    "objectID": "open-tools-resources/lesson3-tools-for-reproducibility.html#what-is-reproducibility",
    "href": "open-tools-resources/lesson3-tools-for-reproducibility.html#what-is-reproducibility",
    "title": "Open Science tools for reproducibility",
    "section": "What is reproducibility?",
    "text": "What is reproducibility?\nReproducibility  - the National Academies Report 2019** **defined reproducibility as:\n\nReproducibility means computational reproducibility—obtaining consistent computational results using the same input data, computational steps, methods, code, and conditions of analysis\nReplicability means obtaining consistent results across studies aimed at answering the same scientific question, each of which has obtained its own data.\n\nIn practice, reproducibility is taken further by an additional step. The goal of reproducibility is not only reproducing the same result given by using the same steps, such as re-executing a notebook in a containerized environment, but also allowing a given user to copy the environment and build upon the new technology and result by editing the environment to apply to a similar problem (e.g., a shareable, copyable executable paper). This small additional step gives others the ability to directly build upon previous work and get more science out of the same amount of funding.\n\nCheck out resources for:\n\nComputational notebooks\nJupyter Notebooks\nR Markdown\nBinder\nQuarto\n\nNote: As you might have noticed, a lot of Open science tools require intermediate to advanced skills in data and information literacy and coding, especially if handling coding - intensive research projects. One of the best ways to learn these skills is through engaging with the respective communities, which often provide training and mentoring."
  },
  {
    "objectID": "open-tools-resources/lesson3-tools-for-reproducibility.html#self-assessment-questions-reproducibility",
    "href": "open-tools-resources/lesson3-tools-for-reproducibility.html#self-assessment-questions-reproducibility",
    "title": "Open Science tools for reproducibility",
    "section": "Self Assessment Questions: Reproducibility",
    "text": "Self Assessment Questions: Reproducibility\nScenario 1: You stumble upon a research paper published a few years ago which used LANDSAT data and techniques similar to a project idea you want to apply for another area of interest. When you read the methods section of the paper, you find they published their derived data set in an international data repository (Dryad), but their algorithm code to generate the processed data from LANDSAT Real-Time (raw) data are not provided, only the description of the technique which they used is given in their Methods section and the mathematical equations for calculating their new index are in the Supplementary Materials.\nQuestion S1-1: From the hypothetical Scenario above, when there is access to the raw data, results data, and some written methods are provided, does the research paper meet the definition of being “reproducible”?\nAnswer S1-1: No, the paper fails to provide a necessary level of detail to allow a different team, with a different experimental setup to obtain the same results exactly. The paper may support some aspects of “Replicability”, but only if someone is able to write their own code using the provided methods. With the same raw data product you could test your code and compare your results data to their results data. This would not be easy and is prohibitive."
  }
]